{"pages":[{"title":"About Me","text":"欢迎来访鸭！( *・ω・)✄╰ひ╯ 博主邮箱：1253703632@qq.com","link":"/about/index.html"}],"posts":[{"title":"用到的opencv接口记录","text":"[TOC] 一、基本操作1. 遍历像素12345678for (int i = 0; i &lt; rows; i++){ for (int j = 0; j &lt; cols; j++) { int index = i*cols + j; image.ptr&lt;uchar&gt;(i)[j] = 255; }} 2. 显示图像并且保持图像比例1234namedWindow(\"window\", WINDOW_NORMAL | WINDOW_KEEPRATIO);imshow(\"window\", image);waitKey();destroyAllWindows();","link":"/2020/07/08/2DImage/opencv_interface/"},{"title":"2DImage","text":"一、特征检测与图像匹配 【图像特征 OPENCV】SIFT，SURF，ORB，Harris，FAST，量化匹配度 （openCV 三）特征检测（SIFT/SURF/HARRIS/ORB/FAST/BRIEF）","link":"/2019/06/16/2DImage/2DImage/"},{"title":"三维局部特征+hough投票","text":"本文是柯师兄的论文“基于双目视觉的散乱堆放工件拾取系统” 流程： 法线和曲率计算：normal-estimation 基于区域生长法对工件堆点云的分割点云分割方法有很多种：比如欧式聚类法，区域生长法 文中用的是区域生长法 基于ISS算法的工件关键点提取关键点：下采样点，ISS，Harris，SIFT 关键点：可以稳定描述，并有较强区分性的点作为关键点。 下采样的方法最快，获取点云的数量可由栅格决定（栅格下采样） ISS算法方法次之，但关键点能稳定提取 Harris和SIFT速度比较慢，特别是Harris算子，提取的关键点数较少。 ISS(Instrinsic Shape Signatures)： 在点云中每个点建立一个独立坐标系，z轴是曲面在该点的法线方向，通过某种方法确定x轴和y轴，通过三个轴线上的特征向量建立具有区分性形状描述的特征点。 对计算出来的协方差矩阵的三个特征值做比较，两个比值分别小于两个阈值，则认为该点是特征点。 基于SHOT算法的关键点特征描述从模型库和场景点云中提取出来的关键点，必须通过配对才能就估计场景中的工件的位姿，配对需要提取关键点高度区分的特征描述，当两点描述几乎一致，这两点配对成功。 描述子：FPFH，SHOT 两者的描述能力都较强，Shot的计算速度比FPFH快十倍。 Hough粗位姿估计粗定位的方法： SAC-IA :“Aligning Point Cloud Views using Persistent Feature Histograms” RANSAC: “Pose Estimation using Local Structure-Specific Shape and Appearance Context” Hough（用时较短）:“Object Recognition in 3D Scenes with Occlusions and Clutter by Hough Voting” 霍夫变换可以进行多目标识别，在霍夫参数空间中，如果有多个极值存在，则表明场景有多个目标。 霍夫变换HT霍夫变换原本是一种流行的计算机图形处理技术，通常用于直线检测，后来被改进用于圆和椭圆的检测。它的原理关键是使用投票的方法对参数空间进行投票。将参数空间分成若干个区间，每个区间设置一个箱子，当在图像空间中检测某些特征，由这些特征估算出的参数，并在参数空间中相应的箱子投票加一，如此遍历所有特征，得到参数空间中票数最高的箱子，其对应的区间即为所求参数。 将旋转平移作为参数空间，旋转有三个变量,平移也有三个变量,一共有六个参数，意味着参数空间计算量巨大而且占用大量内存。 步骤：每个特征点与其相对于模型质心的相对位置相关联，使得每个对应的场景特征可以在三维Hough空间中进行投票，为当前场景中可能存在的质心位置积累证据。 ICP精确位姿估计和匹配度计算略","link":"/2019/08/11/6DPose/localFeaturesHough/"},{"title":"SFM","text":"SLAM和SfM视觉SLAM中大量使用了SfM中的方法，如特征点跟踪、捆集优化(Bundle Adjustment)等，以至于许多研究者把它们视为同一个研究领域。然而，尽管方法上很相似，SLAM和SfM的侧重点是不同的。SLAM的应用场合主要在机器人和VR/AR，计算资源有限，需要很强的实时性，故侧重点在于，如何在有限的资源里快速地对相机进行定位。而SfM方法通常是离线的，可以调用大量计算资源进行长时间的计算，侧重于重建出更精确、美观的场景。 SFM开源项目 https://github.com/mapillary/OpenSfM https://github.com/snavely/bundler_sfm https://github.com/colmap/colmap https://github.com/openMVG/openMVG 博文 关于三维重建的一些东西-VisualSFM+PMVS +MeshLab= PhotoScan SFM与MVS的区别 SFM中我们用来做重建的点是由特征匹配提供的！这些匹配点天生不密集！ 而MVS则几乎对照片中的每个像素点都进行匹配，几乎重建每一个像素点的三维坐标，这样得到的点的密集程度可以较接近图像为我们展示出的清晰度。 其实现的理论依据在于，多视图照片间，对于拍摄到的相同的三维几何结构部分，存在极线几何约束。 描述这种几何约束： 想象，对于在两张图片中的同一个点。现在回到拍摄照片的那一刻，在三维世界中，存在一条光线从照片上这一点，同时穿过拍摄这张照片的相机的成像中心点，最后会到达空间中一个三维点，这个三维点同时也会在另一张照片中以同样的方式投影。 这个过程这样看来，很普通，就如同普通的相机投影而已。但是因为两张图片的原因，他们之间存在联系，这种联系的证明超过了能力范围，但是我们只需要知道，此种情况下，两张照片天然存在了一种约束 从图像到网格 深度学习DeepSFM：通过深度BA进行SFM(运动推断结构) 《DeepSFM: Structure From Motion Via Deep Bundle Adjustment》 DeepSFM性能优于BANet、LS-Net和COLMAP等网络","link":"/2019/07/01/CV-Source/SFM/"},{"title":"books/videos/blogs/acticles","text":"好博客 需要掌握的知识和技能 Books 视频 好文 好博客 白巧克力亦唯心—SLAM 点云学习历史文章大汇总—PCL slamCN—SLAM clipp_Huang—三维重构 需要掌握的知识和技能 参考1：So you want to be a self-driving car engineer? 中文：如何成为一名合格的自动驾驶工程师 以下是一些对自动驾驶行业工程师非常重要的能力（并不完全，也不是按优先顺序排列）， 定位技术 SLAM 计算机视觉 软件架构 概率论，统计学 机器学习，深度学习 数据库技术：relational and NoSQL 传感器技术：摄像头，雷达，超声波 车辆动力学 高清地图 仿真，计算机图形学 实时处理，并行运算，优化技术 功能安全，ISO26262 构建系统 软件测试，测试驱动开发 汽车背景 视频 泡泡机器人 第十三课：CUDA代码优化-张也冬 第十四课：KinectFusion 和 ElasticFusion 三维重建方法-付兴银 第三十八课：Structure Light Based 3D Surface Imaging-卢彦斌 第九十九课：RGBD Direct 方法原理介绍 –闫志鑫 BooksA.SLAM与机器人 《视觉SLAM十四讲从理论到实践》，高翔 SLAM，移动机器人界中的神作 github 视频 《机器人学中的状态估计》，Timothy D. Barfoot 神作！在了解了基本位姿估计任务，跑过一些简单例程后，比如成功运行位姿估计算法后（ICP算法，NDT算法等）可以尝试去看这本书，里面的理论深刻，应用广泛，是一本不可多得的好书，它告诉你如何在现实世界中对旋转或其他变量进行估计。 《概率机器人》 B.视觉 《计算机视觉算法与应用》 《计算机视觉中的多视图几何》 C.编程 《GPU高性能编程CUDA实战》 GPU编程的入门级好书 github 博客 剑指Offer 了解一些算法和数据结构 D.深度学习 《神经网络和深度学习》,Michael Nielsen 深度学习上手好书 《统计学习方法》又称统计机器学习，李航 《解析深度学习》卷积神经网络原理视觉实践 好文 一位合格的博士生需要有哪些条件和素质？ 重磅！三维视觉、SLAM方向全球顶尖实验室汇总","link":"/2019/06/15/CV-Source/books/"},{"title":"CV-Source","text":"CV学习资源（三维与二维） study-source-CVer-CV-学习资源 1.paper switch code 和 cv state-of-the-arthttps://paperswithcode.com/sota 2.人脸识别https://github.com/ChanChiChoi/awesome-Face_Recognition 3.CV2019 https://github.com/amusi/CVPR2019-Code https://github.com/extreme-assistant/cvpr2019 4.3D深度学习1.3D-Machine-Learning3D-Machine-Learning Datasets 3D Pose Estimation Courses Single Object Classification Multiple Objects Detection Scene/Object Semantic Segmentation 3D Geometry Synthesis/Reconstruction Texture/Material Analysis and Synthesis Style Learning and Transfer Scene Synthesis/Reconstruction Scene Understanding 2.A Tutorial on 3D Deep LearningA Tutorial on 3D Deep Learning 3.3D Convolutional Neural Networks — A Reading List3D Convolutional Neural Networks — A Reading List 5.移动机器人1.MRPT github:The MRPT project tutorial:https://www.mrpt.org/tutorials/","link":"/2019/05/24/CV-Source/CV-Source/"},{"title":"SLAM_tutorial","text":"SLAM技术分类 SLAM资源 技术分类slamCN 基于这两种传感器有激光SLAM和视觉SLAM。 视觉传感器 稀疏法(特征点): ORB-SLAM(单目，双目，RGBD)[1](ORB-SLAM: a Versatile and Accurate Monocular SLAM System中文翻译)[2] PTAM(单目)[3] MonoSLAM(单目)[4] 半稠密法: LSD-SLAM(单目，双目，RGBD)[5] DSO(单目)[6] SVO(单目, 仅VO)[7]详细安装使用说明 稠密法: DTAM(RGBD): Paper: [8] Open source code:[9] Elastic Fusion(RGBD): Open source code:[10] Kintinous(RGBD):Open source code: [11] DVO: Open source code: [12] RGBD-SLAM-V2: Open source code: [13] RTAB-MAP: Code: [14] MLM:(单目) paper:[15] Demo Video:[16] 其他 ScaViSLAM: Open source code [17] 激光传感器 Hector SLAM[18] Gmapping [19] tinySLAM（基于蒙特卡洛定位算法的简单SLAM实现） [svn co https://svn.openslam.org/data/svn/tinyslam] SLAM资源ORB-SLAM-bydianyunpcl","link":"/2019/07/01/CV-Source/SLAM/"},{"title":"HashMap","text":"什么是HashMap？ unordered_map unordered_map是非线程安全的，应该如何处理多线程情况 CPU多线程 1. TBB中的concurrent_hash_map GPU多线程 2.CUDA","link":"/2021/04/09/DaNAlgorithm/HashMap/"},{"title":"生成随机数","text":"打乱数组中的内容 参考1 参考2 目前我用到的是std::shuffle_order_engine.功能是打乱数组中的内容 random功能主要由两个部分组成：generators和distribution(不一定用分布) generators a.Pseudo-random（伪随机数） number engines (templates) linear_congruential_engine mersenne_twister_engine subtract_with_carry_engine b. Engine adaptors independent_bits_engine shuffle_order_engine c. 伪随机数引擎(实例化) default_random_engine minstd_rand minstd_rand0 mt19937 mt19937_64 ranlux24_base ranlux48_base ranlux24 ranlux48 knuth_b d.随机数生成器 random_device distributions Uniform: uniform_int_distribution uniform_real_distributionRelated to Bernoulli (yes/no) trials: bernoulli_distribution binomial_distribution geometric_distribution negative_binomial_distributionRate-based distributions: poisson_distribution exponential_distribution gamma_distribution weibull_distribution extreme_value_distributionRelated to Normal distribution: normal_distribution lognormal_distribution chi_squared_distribution cauchy_distribution fisher_f_distribution student_t_distributionPiecewise distributions: discrete_distribution piecewise_constant_distribution piecewise_linear_distribution 实例1： 1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;random&gt;#include &lt;functional&gt;#include &lt;chrono&gt; // std::chrono::system_clock//refernce:http://www.cplusplus.com/reference/random/int main(_In_ int _Argc, _In_reads_(_Argc) _Pre_z_ char ** _Argv, _In_z_ char ** _Env){ //该seed使得每次运行的结果都不同 //用时间作为seed或者随机数生成器作为seed unsigned seed = std::chrono::system_clock::now().time_since_epoch().count(); std::default_random_engine generator(seed); std::uniform_int_distribution&lt;int&gt; distribution(1, 6); // generates number in the range 1..6 for (size_t i = 0; i &lt; 10; i++) { int dice_roll = distribution(generator); std::cout &lt;&lt; dice_roll &lt;&lt; \" \"; } std::cout &lt;&lt; std::endl; //为了重复使用将两着绑定在一起 auto dice = std::bind(distribution, generator); for (size_t i = 0; i &lt; 10; i++) { int wisdom = dice() + dice() + dice(); std::cout &lt;&lt; wisdom &lt;&lt; \" \"; } getchar(); return 0;} 输出： 3 1 3 6 5 2 6 6 1 29 8 11 13 9 12 12 9 5 9 实例2：（使用Engine adaptors：shuffle打乱vector顺序） 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt; // std::move_backward#include &lt;random&gt; // std::default_random_engine#include &lt;chrono&gt; // std::chrono::system_clockint main(int argc, char* argv[]){ std::vector&lt;int&gt; v; for (int i = 0; i &lt; 10; ++i) { v.push_back(i); } // obtain a time-based seed: //unsigned seed = std::chrono::system_clock::now().time_since_epoch().count(); //std::shuffle(v.begin(), v.end(), std::default_random_engine(seed)); //或者用随机数生成器 std::random_device rand_dev; std::shuffle(v.begin(), v.end(), std::default_random_engine(rand_dev())); for (auto&amp; it : v) { std::cout &lt;&lt; it &lt;&lt; \" \"; } std::cout &lt;&lt; \"\\n\"; getchar(); return 0;} 输出： 9 1 4 6 2 7 0 5 3 8","link":"/2019/12/16/DaNAlgorithm/Generate_Random_NUM/"},{"title":"","text":"一、Eigen的坑参考 YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES 错误原因：两个向量表达式类型不兼容（相同的固定大小或动态大小） 二、Eigen的使用不同大小之间的Vector赋值","link":"/2021/03/19/Eigen/Eigen/"},{"title":"Deeplearning Note1","text":"花书学习笔记1 矩阵对角化以及SVD分解一、矩阵对角化推导：A对角矩阵：对角元素不为0，其他元素都为0 P单位正交矩阵：$\\vec q_1,\\vec q_2,\\vec q_3,\\dots,$ 代码：二、SVD分解推导：代码：","link":"/2020/04/11/MAD_Learning/DNote1/"},{"title":"PointCloud Segmentation","text":"实时稀疏点云分割笔记 源码：https://github.com/PRBonn/depth_clustering 笔记TODO","link":"/2021/05/26/MobileRobot/segmentation/"},{"title":"学习OpenGL基本知识","text":"OpenGL基本知识 LearnOpenGL-CN 核心模式与立即渲染模式状态机OpenGL自身是一个巨大的状态机(State Machine)：一系列的变量描述OpenGL此刻应当如何运行。OpenGL的状态通常被称为OpenGL上下文(Context)。我们通常使用如下途径去更改OpenGL状态：设置选项，操作缓冲。最后，我们使用当前OpenGL上下文来渲染。 假设当我们想告诉OpenGL去画线段而不是三角形的时候，我们通过改变一些上下文变量来改变OpenGL状态，从而告诉OpenGL如何去绘图。一旦我们改变了OpenGL的状态为绘制线段，下一个绘制命令就会画出线段而不是三角形。 当使用OpenGL的时候，我们会遇到一些状态设置函数(State-changing Function)，这类函数将会改变上下文。以及状态应用函数(State-using Function)，这类函数会根据当前OpenGL的状态执行一些操作。只要你记住OpenGL本质上是个大状态机，就能更容易理解它的大部分特性。 对象OpenGL库是用C语言写的，同时也支持多种语言的派生，但其内核仍是一个C库。由于C的一些语言结构不易被翻译到其它的高级语言，因此OpenGL开发的时候引入了一些抽象层。“对象(Object)”就是其中一个。 在OpenGL中一个对象是指一些选项的集合，它代表OpenGL状态的一个子集。比如，我们可以用一个对象来代表绘图窗口的设置，之后我们就可以设置它的大小、支持的颜色位数等等。可以把对象看做一个C风格的结构体(Struct)： 12345struct object_name { GLfloat option1; GLuint option2; GLchar[] name;}; 当我们使用一个对象时，通常看起来像如下一样（把OpenGL上下文看作一个大的结构体）： 1234567891011121314151617// OpenGL的状态struct OpenGL_Context { ... object* object_Window_Target; ... };// 创建对象GLuint objectId = 0;glGenObject(1, &amp;objectId);// 绑定对象至上下文glBindObject(GL_WINDOW_TARGET, objectId);// 设置当前绑定到 GL_WINDOW_TARGET 的对象的一些选项glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800);glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);// 将上下文对象设回默认glBindObject(GL_WINDOW_TARGET, 0); 这一小段代码展现了你以后使用OpenGL时常见的工作流。我们首先创建一个对象，然后用一个id保存它的引用（实际数据被储存在后台）。然后我们将对象绑定至上下文的目标位置（例子中窗口对象目标的位置被定义成GL_WINDOW_TARGET）。接下来我们设置窗口的选项。最后我们将目标位置的对象id设回0，解绑这个对象。设置的选项将被保存在objectId所引用的对象中，一旦我们重新绑定这个对象到GL_WINDOW_TARGET位置，这些选项就会重新生效。 如果你希望静态链接GLEW，必须在包含GLEW头文件之前定义预处理器宏GLEW_STATIC： 12#define GLEW_STATIC#include &lt;GL/glew.h&gt; 如果你希望动态链接，那么你可以省略这个宏。但是记住使用动态链接的话你需要拷贝一份.DLL文件到你的应用程序目录。 渲染在OpenGL中，任何事物都在3D空间中，而屏幕和窗口却是2D像素数组，这导致OpenGL的大部分工作都是关于把3D坐标转变为适应你屏幕的2D像素。3D坐标转为2D坐标的处理过程是由OpenGL的图形渲染管线（Graphics Pipeline，大多译为管线，实际上指的是一堆原始图形数据途经一个输送管道，期间经过各种变化处理最终出现在屏幕的过程）管理的。图形渲染管线可以被划分为两个主要部分： 第一部分把你的3D坐标转换为2D坐标， 第二部分是把2D坐标转变为实际的有颜色的像素。 一个顶点(Vertex)是一个3D坐标的数据的集合。而顶点数据是用顶点属性(Vertex Attribute)表示的 图形渲染管线的第一个部分是顶点着色器(Vertex Shader)，它把一个单独的顶点作为输入。顶点着色器主要的目的是把3D坐标转为另一种3D坐标（后面会解释），同时顶点着色器允许我们对顶点属性进行一些基本处理。 图元装配(Primitive Assembly)阶段将顶点着色器输出的所有顶点作为输入（如果是GL_POINTS，那么就是一个顶点），并所有的点装配成指定图元的形状；本节例子中是一个三角形。 图元装配阶段的输出会传递给几何着色器(Geometry Shader)。几何着色器把图元形式的一系列顶点的集合作为输入，它可以通过产生新顶点构造出新的（或是其它的）图元来生成其他形状。例子中，它生成了另一个三角形。 几何着色器的输出会被传入光栅化阶段(Rasterization Stage)，这里它会把图元映射为最终屏幕上相应的像素，生成供片段着色器(Fragment Shader)使用的片段(Fragment)。在片段着色器运行之前会执行裁切(Clipping)。裁切会丢弃超出你的视图以外的所有像素，用来提升执行效率。 OpenGL有很多缓冲对象类型，顶点缓冲对象的缓冲类型是GL_ARRAY_BUFFER。OpenGL允许我们同时绑定多个缓冲，只要它们是不同的缓冲类型。我们可以使用glBindBuffer函数把新创建的缓冲绑定到GL_ARRAY_BUFFER目标上： 1glBindBuffer(GL_ARRAY_BUFFER, VBO); 顶点着色器","link":"/2021/04/03/OPENGL/LearnOpenGL/"},{"title":"从官网学习GLFW","text":"从官网学习GLFW Getting Start123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138#include &lt;glad/gl.h&gt;#define GLFW_INCLUDE_NONE#include &lt;GLFW/glfw3.h&gt; #include \"linmath.h\" #include &lt;stdlib.h&gt;#include &lt;stdio.h&gt; static const struct{ float x, y; float r, g, b;} vertices[3] ={ { -0.6f, -0.4f, 1.f, 0.f, 0.f }, { 0.6f, -0.4f, 0.f, 1.f, 0.f }, { 0.f, 0.6f, 0.f, 0.f, 1.f }}; static const char* vertex_shader_text =\"#version 110\\n\"\"uniform mat4 MVP;\\n\"\"attribute vec3 vCol;\\n\"\"attribute vec2 vPos;\\n\"\"varying vec3 color;\\n\"\"void main()\\n\"\"{\\n\"\" gl_Position = MVP * vec4(vPos, 0.0, 1.0);\\n\"\" color = vCol;\\n\"\"}\\n\"; static const char* fragment_shader_text =\"#version 110\\n\"\"varying vec3 color;\\n\"\"void main()\\n\"\"{\\n\"\" gl_FragColor = vec4(color, 1.0);\\n\"\"}\\n\"; static void error_callback(int error, const char* description){ fprintf(stderr, \"Error: %s\\n\", description);} static void key_callback(GLFWwindow* window, int key, int scancode, int action, int mods){ if (key == GLFW_KEY_ESCAPE &amp;&amp; action == GLFW_PRESS) glfwSetWindowShouldClose(window, GLFW_TRUE);} int main(void){ GLFWwindow* window; GLuint vertex_buffer, vertex_shader, fragment_shader, program; GLint mvp_location, vpos_location, vcol_location; glfwSetErrorCallback(error_callback); if (!glfwInit()) exit(EXIT_FAILURE); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 2); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 0); window = glfwCreateWindow(640, 480, \"Simple example\", NULL, NULL); if (!window) { glfwTerminate(); exit(EXIT_FAILURE); } glfwSetKeyCallback(window, key_callback); glfwMakeContextCurrent(window); gladLoadGL(glfwGetProcAddress); glfwSwapInterval(1); // NOTE: OpenGL error checks have been omitted for brevity glGenBuffers(1, &amp;vertex_buffer); glBindBuffer(GL_ARRAY_BUFFER, vertex_buffer); glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); vertex_shader = glCreateShader(GL_VERTEX_SHADER); glShaderSource(vertex_shader, 1, &amp;vertex_shader_text, NULL); glCompileShader(vertex_shader); fragment_shader = glCreateShader(GL_FRAGMENT_SHADER); glShaderSource(fragment_shader, 1, &amp;fragment_shader_text, NULL); glCompileShader(fragment_shader); program = glCreateProgram(); glAttachShader(program, vertex_shader); glAttachShader(program, fragment_shader); glLinkProgram(program); mvp_location = glGetUniformLocation(program, \"MVP\"); vpos_location = glGetAttribLocation(program, \"vPos\"); vcol_location = glGetAttribLocation(program, \"vCol\"); glEnableVertexAttribArray(vpos_location); glVertexAttribPointer(vpos_location, 2, GL_FLOAT, GL_FALSE, sizeof(vertices[0]), (void*) 0); glEnableVertexAttribArray(vcol_location); glVertexAttribPointer(vcol_location, 3, GL_FLOAT, GL_FALSE, sizeof(vertices[0]), (void*) (sizeof(float) * 2)); while (!glfwWindowShouldClose(window)) { float ratio; int width, height; mat4x4 m, p, mvp; glfwGetFramebufferSize(window, &amp;width, &amp;height); ratio = width / (float) height; glViewport(0, 0, width, height); glClear(GL_COLOR_BUFFER_BIT); mat4x4_identity(m); mat4x4_rotate_Z(m, m, (float) glfwGetTime()); mat4x4_ortho(p, -ratio, ratio, -1.f, 1.f, 1.f, -1.f); mat4x4_mul(mvp, p, m); glUseProgram(program); glUniformMatrix4fv(mvp_location, 1, GL_FALSE, (const GLfloat*) mvp); glDrawArrays(GL_TRIANGLES, 0, 3); glfwSwapBuffers(window); glfwPollEvents(); } glfwDestroyWindow(window); glfwTerminate(); exit(EXIT_SUCCESS);} Introduction to the APIWindow guideContext guideMonitor guideInput guide","link":"/2021/03/31/OPENGL/LearnGLFW/"},{"title":"OpenGL遇到的问题","text":"显示问题 OpenGL画点，为什么点的坐标值超出[-1,1]范围就显示不了？？？ 如何使用GLSL 其他显示问题 一、显示问题1. OpenGL画点，为什么点的坐标值超出[-1,1]范围就显示不了？？？https://ask.csdn.net/questions/259655 1.OpenGL工作在一个叫做NDC（Normalized Device Coordinates）的坐标系统下，在这个坐标系统中，x、y和z的值全部都坐落在[-1, +1]范围内，超出这个范围的点会被OpenGL忽略。因为我们直接使用OpenGL的NDC坐标系统，所以顶点坐标的值在-1到+1之间。 2.设置投影模式，这样坐标就可以是超过-1到1了。Opengl的坐标是可以无限大的，通过设定视场大小来确定显示的范围，只有在视场范围内的坐标才能被看见，在视场之外的看不到。视场是可以用函数设定的。具体你要看看投影模式怎么回事。我很久没弄opengl了，具体也不太了解。 2. 如何使用GLSL三大着色器：顶点、几何、片段 OpenGL顶点着色器、编译着色器、片段着色器 boid.vert.glsl 12345678910#version 330in vec4 Position;in vec4 Velocity;out vec4 vFragColorVs;void main() { vFragColorVs = Velocity; gl_Position = Position;} 使用in 关键字，在顶点着色器中声明所有的输入顶点属性。GLSL有一个向量数据类型，包含1到4个float分量。由于每个顶点都有一个3D坐标，我们就创建一个vec3输入变量aPos。为了设置顶点着色器的输出，我们必须把位置数据赋值给预定义的gl_Position，它在幕后的vec4.在main函数最后，我们将gl_Position设置的值会成为该顶点着色器的输出 boid.geom.glsl 12345678910#version 330in vec4 vFragColor;out vec4 fragColor;void main() { fragColor.r = abs(vFragColor.r); fragColor.g = abs(vFragColor.g); fragColor.b = abs(vFragColor.b);} boid.frag.glsl 123456789101112131415161718#version 330uniform mat4 u_projMatrix;layout(points) in;layout(points) out;layout(max_vertices = 1) out;in vec4 vFragColorVs[];out vec4 vFragColor;void main() { vec3 Position = gl_in[0].gl_Position.xyz; vFragColor = vFragColorVs[0]; gl_Position = u_projMatrix * vec4(Position, 1.0); EmitVertex(); EndPrimitive();} 3.其他显示问题glDrawElements 原型： 1void glDrawElements(GLenum mode,GLsizei count,GLenum type,const GLvoid *indices); mode:接受的值和在glBegin()中接受的值一样，可以是GL_POLYGON、GL_TRIANGLES、GL_TRIANGLE_STRIP、GL_LINE_STRIP等。 count：组合几何图形的元素的个数，一般是点的个数。 type:indeices数组的数据类型，既然是索引，一般是整型的。 indices:索引数组","link":"/2021/04/03/OPENGL/OpenGLFQA/"},{"title":"about-Descriptors","text":"图：使用手持式扫描仪收集的数据，利用采样点与其FPFH特征描述的SAC-IA配准（粗配准） 介绍： 在三维物体识别（3D object recognition），三维形状检测（3D shape retrieval），三维曲面配准（3D surface registration）的过程中局部特征作可以作为两个三维物体（曲面）共同部分的桥梁，将两个不完全相同的点云（曲面）通过共同部分连接在一起。 基于局部特征的算法通常涉及两个主要阶段: 关键点检测和特征描述。 1.在关键点检测阶段，首先识别具有丰富信息内容的关键点及其相关尺度的确定 2.而在特征描述阶段，提取关键点（一般是关键点，有的情况采样点作为关键点也适用）周围的几何信息存储在高维向量，即为feature descriptor。 之后的工作：像曲面配准的一种方法就是利用descriptors进行粗配准，通过特征描述符来计算对应源曲面的关键点与感兴趣曲面关键点之间的对应关系来获得位姿变换T。 下面介绍特征描述符 ​ 我们构造了大量的三维局部特征描述符来编码局部曲面的信息。在这些方法中，许多算法使用直方图来表示局部表面的不同特征。具体地说，它们通过将几何或拓扑测量值(如点编号)按照特定领域(如点坐标、几何属性)累积成直方图来描述局部表面。我们将这些算法分为基于描述符的“空间分布直方图”和“几何属性直方图”。 1.Spatial Distribution Histogram based Descriptors Spin Image (SI) 3D Shape Context (3DSC) Unique Shape Context (USC) Rotational Projection Statistics (RoPS) Tri-Spin-Image (TriSI) 2.Geometric Attribute Histogram based Descriptors Local Surface Patch (LSP) THRIFT Point Feature Histogram (PFH) Fast Point Feature Histogram (FPFH) Signature of Histogram of Orientations (SHOT) A.*“A Comprehensive Performance Evaluation of 3D Local Feature* Descriptors ” 论文中比较了10种常用的局部特征描述符在三维物体中的应用。 对这几种局部特征描述子进行了全面的性能评估。 文章中 使用了Precision-recall curve来评估descriptors的描述性（Descriptiveness）。 使用添加三种不同noise，gaussian noise，shot noise和decimation；使用多种的网格分辨率；对Keypoint Localization Error；添加Occlusion and Clutter等来检测descriptors的鲁棒性（Rubustness）。 通过多源收集的数据来测试descriptors的Scalability。 Combination with 3D Keypoint Detectors。 通过计算每个场景中生成1000个descriptors（每个descriptors考虑102～105个点）所用的时间。评估Efficiency。 由于组合实在太多了，如果想改进描述子，了解各个因素对descriptors的性能影响的话，查看详细结果请看论文。如果只是用的话，可以只了解下列结果就可以了。 论文总结： 对于对时间条件苛刻且点的数据量少的应用程序(例如实时系统)，FPFH是最佳选择。这是因为FPFH描述符具有合理的描述性、计算效率(对于特性生成和匹配)和轻量级(对于特性存储)。它在特征匹配精度和计算效率之间提供了良好的平衡。 对于对时间条件苛刻且点的数据量大多的应用程序，SHOT在描述性和计算效率方面都有很好的表现。 对于存储空间苛刻的应用程序（例如嵌入式设备），FPFH是最好的选择。这是因为它对特征存储的内存要求很低。Rops也可以被考虑，因为它以稍高的存储需求为代价实现了更好的描述性能。对于需要高配准准确率(或识别率)的场景，与其他描述符相比，RoPS具有更高的鉴别能力，因此强烈推荐使用。 如果数据集的特征(如噪声水平、分辨率)未知，则RoPS是最佳选择，因为它在所有类型的数据集上都能持续产生良好的结果。RoPS描述符在不同数据集之间实现了非常稳定的性能。 结合三维关键点检测方法(相对于均匀采样或随机选取关键点)，可以显著提高所选描述符的特征匹配性能。当ISS-BR（关键点）与这些选择的描述符组合时，始终获得最佳性能。 由于scalability和descriptiveness综合，TriSI是大型数据集上应用程序的最佳选择。 请注意，尽管这些描述符在高分辨率数据集(使用昂贵的扫描仪收集)中表现良好，但在低成本低分辨率传感器(如Kinect和Dense Stereo)的数据下，**它们的性能都相当弱。因此，研究方向应是设计适合低分辨率和高噪声数据的描述符，或设计高分辨率和低成本RGBD相机。哈哈。。。** B.**PCL中的PFH和FPFH** C.直方图可视化 一个直方图可视化模块（pclhistogramvisualizer）的二维图； D.描述符之间匹配 在计算了点云中的每个关键点的本地描述符之后，我们必须匹配它们，找到与存储在对象数据库（模型点云）中的对应项。为此，可以使用k-d树之类的搜索结构来执行最近邻居搜索，检索描述符之间的欧式距离(还可以选择强制最大距离值作为阈值)。场景中的每个描述符都应该与数据库中每个模型的描述符相匹配。 链接 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;pcl/io/pcd_io.h&gt;#include &lt;pcl/features/normal_3d.h&gt;#include &lt;pcl/features/shot.h&gt;#include &lt;iostream&gt;intmain(int argc, char** argv){ // Object for storing the SHOT descriptors for the scene. pcl::PointCloud&lt;pcl::SHOT352&gt;::Ptr sceneDescriptors(new pcl::PointCloud&lt;pcl::SHOT352&gt;()); // Object for storing the SHOT descriptors for the model. pcl::PointCloud&lt;pcl::SHOT352&gt;::Ptr modelDescriptors(new pcl::PointCloud&lt;pcl::SHOT352&gt;()); // Read the already computed descriptors from disk. if (pcl::io::loadPCDFile&lt;pcl::SHOT352&gt;(argv[1], *sceneDescriptors) != 0) { return -1; } if (pcl::io::loadPCDFile&lt;pcl::SHOT352&gt;(argv[2], *modelDescriptors) != 0) { return -1; } // A kd-tree object that uses the FLANN library for fast search of nearest neighbors. pcl::KdTreeFLANN&lt;pcl::SHOT352&gt; matching; matching.setInputCloud(modelDescriptors); // A Correspondence object stores the indices of the query and the match, // and the distance/weight. pcl::CorrespondencesPtr correspondences(new pcl::Correspondences()); // Check every descriptor computed for the scene. for (size_t i = 0; i &lt; sceneDescriptors-&gt;size(); ++i) { std::vector&lt;int&gt; neighbors(1); std::vector&lt;float&gt; squaredDistances(1); // Ignore NaNs. if (pcl_isfinite(sceneDescriptors-&gt;at(i).descriptor[0])) { // Find the nearest neighbor (in descriptor space)... int neighborCount = matching.nearestKSearch(sceneDescriptors-&gt;at(i), 1, neighbors, squaredDistances); // ...and add a new correspondence if the distance is less than a threshold // (SHOT distances are between 0 and 1, other descriptors use different metrics). if (neighborCount == 1 &amp;&amp; squaredDistances[0] &lt; 0.25f) { pcl::Correspondence correspondence(neighbors[0], static_cast&lt;int&gt;(i), squaredDistances[0]); correspondences-&gt;push_back(correspondence); } } } std::cout &lt;&lt; \"Found \" &lt;&lt; correspondences-&gt;size() &lt;&lt; \" correspondences.\" &lt;&lt; std::endl;}","link":"/2019/07/13/PCL/about-Descriptors/"},{"title":"about-Keypoints","text":"（TODO）","link":"/2019/05/24/PCL/about-Keypoints/"},{"title":"config-PCL-qt-cuda","text":"配置PCL+QT+CUDA 回复：从源码开始编译pcl 获得文档 参考博客 1.http://pointclouds.org/documentation/tutorials/compiling_pcl_windows.php#compiling-pcl-windows 2. https://blog.csdn.net/artista/article/details/50897833 可以忽略网址 步骤 环境： Vs2013 win10 安装了pcl-all-in-one1.8**版本的预编译包（主要用到里面的编译好的第三方库，那么就不用自己来编译第三方库了）** 1． 第一步：安装cuda最新版本（v9.1） 一步一步安装就好了 2． 第二步：下载pcl-master https://github.com/PointCloudLibrary/pcl 3． 第三步：以管理员身份运行cmake（不知是否必要） 4.第四步：设置一些cmake找不到的变量 1.EIGEN_INCLUDE_DIR D:/pcl/3rdParty/Eigen/eigen3 Configure 2.Boost_INCLUDE_DIR D:/pcl/3rdParty/Boost/include/boost-1_59 CONFIGURE 5. 全部勾选上 出现错误 CMake Error at C:/ProgramFiles/CMake/share/cmake-3.11/Modules/FindBoost.cmake:2044 (message):Unable to find the requested Boost libraries. Boost version: 1.59.0 Boost include path: D:/pcl/3rdParty/Boost/include/boost-1_59 Could not find the following static Boost libraries: boost_filesystemboost_threadboost_date_timeboost_iostreamsboost_chronoboost_system Some (but not all) of the required Boost libraries were found. You mayneed to install these additional Boost libraries. Alternatively, setBOOST_LIBRARYDIR to the directory containing Boost libraries or BOOST_ROOTto the location of Boost.Call Stack (most recent call first):cmake/pcl_find_boost.cmake:41 (find_package)CMakeLists.txt:419 (include) ! 手动将boost库一个一个添加进去 因为预编译的第三方库没有分好类 我手动分类又添加了两个路径 CMake Error at C:/ProgramFiles/CMake/share/cmake-3.11/Modules/FindPackageHandleStandardArgs.cmake:137(message):Could NOT find Gtest (missing: GTEST_INCLUDE_DIR GTEST_SRC_DIR)Call Stack (most recent call first):C:/ProgramFiles/CMake/share/cmake-3.11/Modules/FindPackageHandleStandardArgs.cmake:378(_FPHSA_FAILURE_MESSAGE)cmake/Modules/FindGtest.cmake:35 (find_package_handle_standard_args)test/CMakeLists.txt:11 (find_package) 取消掉globaltest Cmake成功 打开vs2013工程再编译一下 Debug x64 1.All-build 重新生成 除了（example_nurbs_viewer_surface失败其他都成功了） 就不管那个了，因为主要用到gpu和cuda 2.INSTALL重新生成 —————– Releasex64 进行同样的操作 ———————————————————–**解析————————————————————** 1.Cmake**中CMAKE_INSTALL_PREFIX C:/Program Files/PCL** 放了编译出来的库（当前环境下（vs2013）可以用的东西（动态库，可执行文件，静态库）） 动态库放在了bin里面 静态库放在了lib里面 2.whereto build the binaries**：D:/pcl-master/build** 存放的是cmake出来的文件（工程文件）即：构建样例工程及源码的文件 ​ （完）","link":"/2019/05/24/PCL/config-PCL-qt-cuda/"},{"title":"how-to-start-PCL","text":"如何开始学习PCL点云库 写下博主学习点云的过程中的心得（后面链接提供参考资料） 建议： 首先推荐不要自己编译源码，建议安装all-in-one能够满足大部分人的需求。 其次先实现基本功能再配置QT，可能qvtk插件会有点麻烦 配置教程 如有需要再安装cuda 资源： 学习资源 a.最好就是直接看官网文档 http://pointclouds.org/documentation/ http://docs.pointclouds.org/trunk/ b.微信公众号：点云PCL c.微信公众号：泡泡机器人SLAM，里面做slam关于点云的也是比较多的。 d.书《点云库PCL从入门到精通》 遇到问题 a.首先想着自己解决，在pcl邮件记录里面有很多别人遇到过的问题，可以先找一下有没有相似的再问别人。pcl-mailing-list：http://www.pcl-users.org/ b.加两个比较活跃的PCL点云库群： 点云库PCL旗舰群512254255、 dianyunPCL微信公众号群327490147 群里面有很多活跃的人，有问题问大神。 数据集 a.Stanford PCD Data里面有许多测试用的点云，典型的兔子bunny。 b.kitti，用于点云配准的遥感激光（车载或机载的）点云数据集。 c.室内物体rgbd数据集 d.SIXD Challenge 2017数据集 e.点云深度学习数据集：3D-Machine-Learning ShapeNet; ShapeNetSem; ModelNet; 对应的imageNet中每一类的图像PASCAL3D+; 大型三维仿真数据集ABC dataset; 佐治亚理工大型几何模型数据集 用得最多的处理点云的必备软件（好用又开源） a.cloudcompare非常好用，可以进行点云查看，配准，剪裁，格式转换等 b.meshlab，可以对网格点云等进行处理，集成了大部分重建，分割等算法 一些知识点： 两种数据结构：kdtree和octree kdtree： kdtree原理 KD Tree的原理及Python实现 kd是k维的意思，在点云中k=3。 octree： kdtree和octree都是两种计算机数据结构。可以简单理解为建立这些数据结构是为了方便我们进行三维空间检索。 kdtree用来组织表示k维空间中点的集合， 1.PCL中kdtree库提供了kdtree数据结构。基于FLANN（快速近邻算法）进行快速近邻查询即帮助你找到最近的几个点。有了近邻点的信息可以计算特征描述子（feature descriptor）用于描述该点的特征，建立kdtree可以简单理解为通过kdtree帮助你找到每个点的邻居，具体描述请看文档。 2.PCL中octree可以理解为：通过循环递归划分空间为八个子立方体来进行空间细分，octree的编码知道每个点云所在的octree空间，递归的次数越多就使得划分的空间越细。同样的，octree也可以像kdtree一样进行FLANN，邻域检索，邻域的特征提取，计算描述符等。另外还有一些相应的空间处理算法比如：压缩，空间变化检测。 通过空间变化检测来提取两个点云的差异非常好用。 kdtree和octree具体内容会有相关的详细文档，放在百度云。 随机采样一致性算法RANSAC RANSAC是一种随机参数估计算法。RANSAC从样本中随机抽选出一个样本子集，使用最小方差估计算法对这个自己计算模型参数。 PCL中利用RANSAC实现了随机采样一致性及其范化估计算法。 用不同的估计算法和不同的几何模型结合来估算点云中隐藏的具体几何模型的系数。 实例：用平面模型对常见的室内点云进行平面分割提取，比如墙，地板，桌面等，或者用圆柱体分割出一个圆柱体的杯子。 关键点与特征描述符 在另外的文章会给出 点云精确配准 在另外的文章会给出 点云分割 点云分割是根据空间，几何和纹理等特征对点云进行划分。 点云分割可以划分为下面几种： a.基于模型分割 b.平面滤波 c.法线估计 d.区域成长法 e.欧式聚类 曲面处理与重建 pcl里面有很多曲面重建的算法，也可以通过先前提到的meshlab软件先进行可行性验证，再去编写代码。 我举一些曲面处理与曲面重建的算法出来，给大家参考一下。 使用双边滤波（Bilateral Filtering）进行上采样 使用移动最小二乘法（Moving Least Squares）进行上采样 使用Poisson算法进行表面重建 曲面重建还有多的其他算法，具体可以参照pcl官网的例程或者查看pcl的类定义来获取具体信息。 未完待续","link":"/2019/05/24/PCL/how-to-start-PCL/"},{"title":"表面法线估计","text":"计算点云表面法线 reference 平面的法向量是垂直于它的单位向量，而在曲面一个点上的法向量被定义为垂直于与曲面相切的平面的向量。 1.数学原理：主成份分析法（PCA）PCA和SVD区别和联系 检测点法向量的计算主要有根据“曲面网格”的求解方法和根据“周围邻域点的分布”求解方法。 法向量所在的轴线上是邻域分布最分散的方向，设距离检测点的半径为r的邻域内N个点，所以有邻域点p_j与查询点p_i之间的协方差矩阵为 计算C的特征值和特征向量，特征值按降序排列，对应的特征向量为， 值最大，代表邻域点主要集中在其对应的特征向量上，其值最小，代表邻域点在对应的特征向量上分布最分散，故特征向量代表法向量。（特征值最小的分类为法向量方向） 曲率计算如下： pcl函数： pcl::NormalEstimationOMP&lt;PointType, NormalType&gt; norm_est; 但是你只需要知道它是用最近邻(最接近我们计算法线的点)来求出切平面和法向量。 2.在PCL中： 自定义搜索半径，以查询点为中心，考虑设定半径为球体内的点 以该点为中心;计算将使用所有位于其中的相邻点 设定视点(默认情况下，输出法线是无方向的;假设所有的矢量都必须指向摄像机——否则它们就属于传感器无法看到的表面——它们都可以相应地重新定向)。 3.计算与显示法线代码1.无序点云 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;pcl/io/pcd_io.h&gt;#include &lt;pcl/features/normal_3d.h&gt;#include &lt;boost/thread/thread.hpp&gt;#include &lt;pcl/visualization/pcl_visualizer.h&gt;intmain(int argc, char** argv){ // Object for storing the point cloud. pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;); // Object for storing the normals. pcl::PointCloud&lt;pcl::Normal&gt;::Ptr normals(new pcl::PointCloud&lt;pcl::Normal&gt;); // Read a PCD file from disk. if (pcl::io::loadPCDFile&lt;pcl::PointXYZ&gt;(argv[1], *cloud) != 0) { return -1; } // Object for normal estimation. pcl::NormalEstimation&lt;pcl::PointXYZ, pcl::Normal&gt; normalEstimation; normalEstimation.setInputCloud(cloud); // For every point, use all neighbors in a radius of 3cm. normalEstimation.setRadiusSearch(0.03); // A kd-tree is a data structure that makes searches efficient. More about it later. // The normal estimation object will use it to find nearest neighbors. pcl::search::KdTree&lt;pcl::PointXYZ&gt;::Ptr kdtree(new pcl::search::KdTree&lt;pcl::PointXYZ&gt;); normalEstimation.setSearchMethod(kdtree); // Calculate the normals. normalEstimation.compute(*normals); // Visualize them. boost::shared_ptr&lt;pcl::visualization::PCLVisualizer&gt; viewer(new pcl::visualization::PCLVisualizer(\"Normals\")); viewer-&gt;addPointCloud&lt;pcl::PointXYZ&gt;(cloud, \"cloud\"); // Display one normal out of 20, as a line of length 3cm. //每20个法线显示一个法线，长度为3CM viewer-&gt;addPointCloudNormals&lt;pcl::PointXYZ, pcl::Normal&gt;(cloud, normals, 20, 0.03, \"normals\"); while (!viewer-&gt;wasStopped()) { viewer-&gt;spinOnce(100); boost::this_thread::sleep(boost::posix_time::microseconds(100000)); }} 2.有序点云使用积分图像来计算法线（Integral images） 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;pcl/io/pcd_io.h&gt;#include &lt;pcl/features/integral_image_normal.h&gt;#include &lt;boost/thread/thread.hpp&gt;#include &lt;pcl/visualization/pcl_visualizer.h&gt;intmain(int argc, char** argv){ // Object for storing the point cloud. pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;); // Object for storing the normals. pcl::PointCloud&lt;pcl::Normal&gt;::Ptr normals(new pcl::PointCloud&lt;pcl::Normal&gt;); // Read a PCD file from disk. if (pcl::io::loadPCDFile&lt;pcl::PointXYZ&gt;(argv[1], *cloud) != 0) { return -1; } // Object for normal estimation. pcl::IntegralImageNormalEstimation&lt;pcl::PointXYZ, pcl::Normal&gt; normalEstimation; normalEstimation.setInputCloud(cloud); // Other estimation methods: COVARIANCE_MATRIX, AVERAGE_DEPTH_CHANGE, SIMPLE_3D_GRADIENT. // They determine the smoothness of the result, and the running time. normalEstimation.setNormalEstimationMethod(normalEstimation.AVERAGE_3D_GRADIENT); // Depth threshold for computing object borders based on depth changes, in meters. normalEstimation.setMaxDepthChangeFactor(0.02f); // Factor that influences the size of the area used to smooth the normals. normalEstimation.setNormalSmoothingSize(10.0f); // Calculate the normals. normalEstimation.compute(*normals); // Visualize them. boost::shared_ptr&lt;pcl::visualization::PCLVisualizer&gt; viewer(new pcl::visualization::PCLVisualizer(\"Normals\")); viewer-&gt;addPointCloud&lt;pcl::PointXYZ&gt;(cloud, \"cloud\"); // Display one normal out of 20, as a line of length 3cm. viewer-&gt;addPointCloudNormals&lt;pcl::PointXYZ, pcl::Normal&gt;(cloud, normals, 20, 0.03, \"normals\"); while (!viewer-&gt;wasStopped()) { viewer-&gt;spinOnce(100); boost::this_thread::sleep(boost::posix_time::microseconds(100000)); }}","link":"/2019/05/24/PCL/normalestimation/"},{"title":"区域生长法分割","text":"1.原理：区域生长法： 通过曲率和法向量的夹角作为阈值来分割点云，同一区域内的点云趋于同一平面上，曲率不大，对比于欧式聚类分割法，区域生长法可以分割出曲率不连续（即曲率变换较大）但点云连续的区域。 步骤： PCL中的类pcl::RegionGrowing用来实现点云的区域生长分割。区域生长分割是基于点云法线的分割算法，算法的主要思路如下： 点云中有未标记点，按照点的曲率值对点进行排序，找到最小曲率值点，并把它添加到种子点集； 对于每个种子点，算法都会发现周边的所有近邻点。 1）计算每个近邻点与当前种子点的法线角度差(reg.setSmoothnessThreshold)，如果差值小于设置的阈值，则该近邻点被重点考虑，进行第二步测试； 2）该近邻点通过了法线角度差检验，如果它的曲率小于我们设定的阈值(reg.setCurvatureThreshold)，这个点就被添加到种子点集，即属于当前平面。 通过两次检验的点，被从原始点云去除。 设置最小点簇的点数min（reg.setMinClusterSize），最大点簇为max（reg.setMaxClusterSize）。 重复1-3步，算法会生成点数在min和max的所有平面，并对不同平面标记不同颜色加以区分。 直到算法在剩余点中生成的点簇不能满足min，算法停止工作。 2.在PCL中：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;pcl/point_types.h&gt;#include &lt;pcl/io/pcd_io.h&gt;#include &lt;pcl/search/search.h&gt;#include &lt;pcl/search/kdtree.h&gt;#include &lt;pcl/features/normal_3d.h&gt;#include &lt;pcl/visualization/cloud_viewer.h&gt;#include &lt;pcl/filters/passthrough.h&gt;#include &lt;pcl/segmentation/region_growing.h&gt;intmain (int argc, char** argv){ pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud (new pcl::PointCloud&lt;pcl::PointXYZ&gt;); if ( pcl::io::loadPCDFile &lt;pcl::PointXYZ&gt; (\"region_growing_tutorial.pcd\", *cloud) == -1) { std::cout &lt;&lt; \"Cloud reading failed.\" &lt;&lt; std::endl; return (-1); } pcl::search::Search&lt;pcl::PointXYZ&gt;::Ptr tree = boost::shared_ptr&lt;pcl::search::Search&lt;pcl::PointXYZ&gt; &gt; (new pcl::search::KdTree&lt;pcl::PointXYZ&gt;); pcl::PointCloud &lt;pcl::Normal&gt;::Ptr normals (new pcl::PointCloud &lt;pcl::Normal&gt;); pcl::NormalEstimation&lt;pcl::PointXYZ, pcl::Normal&gt; normal_estimator; normal_estimator.setSearchMethod (tree); normal_estimator.setInputCloud (cloud); normal_estimator.setKSearch (50); normal_estimator.compute (*normals); pcl::IndicesPtr indices (new std::vector &lt;int&gt;); pcl::PassThrough&lt;pcl::PointXYZ&gt; pass; pass.setInputCloud (cloud); pass.setFilterFieldName (\"z\"); pass.setFilterLimits (0.0, 1.0); pass.filter (*indices); pcl::RegionGrowing&lt;pcl::PointXYZ, pcl::Normal&gt; reg; reg.setMinClusterSize (50); reg.setMaxClusterSize (1000000); reg.setSearchMethod (tree); reg.setNumberOfNeighbours (30); reg.setInputCloud (cloud); //reg.setIndices (indices); reg.setInputNormals (normals); reg.setSmoothnessThreshold (3.0 / 180.0 * M_PI); reg.setCurvatureThreshold (1.0); std::vector &lt;pcl::PointIndices&gt; clusters; reg.extract (clusters); std::cout &lt;&lt; \"Number of clusters is equal to \" &lt;&lt; clusters.size () &lt;&lt; std::endl; std::cout &lt;&lt; \"First cluster has \" &lt;&lt; clusters[0].indices.size () &lt;&lt; \" points.\" &lt;&lt; endl; std::cout &lt;&lt; \"These are the indices of the points of the initial\" &lt;&lt; std::endl &lt;&lt; \"cloud that belong to the first cluster:\" &lt;&lt; std::endl; int counter = 0; while (counter &lt; clusters[0].indices.size ()) { std::cout &lt;&lt; clusters[0].indices[counter] &lt;&lt; \", \"; counter++; if (counter % 10 == 0) std::cout &lt;&lt; std::endl; } std::cout &lt;&lt; std::endl; pcl::PointCloud &lt;pcl::PointXYZRGB&gt;::Ptr colored_cloud = reg.getColoredCloud (); pcl::visualization::CloudViewer viewer (\"Cluster viewer\"); viewer.showCloud(colored_cloud); while (!viewer.wasStopped ()) { } return (0);}","link":"/2019/07/26/PCL/regiongrowing/"},{"title":"ICP-Registration","text":"点云配准之迭代最近点 A.配准的意义： 两个几何数据集的刚性配准在机器人导航、曲面重建和形状匹配等许多应用中都是必不可少的。最常见的方法是使用迭代最接近点(ICP)算法及其变体来完成这项任务。这些方法在最近点计算之间交替，以建立两个数据集之间的对应关系，并求解使这些对应关系对齐的最优转换。 求解刚体旋转平移关系–配准 B.ICP及其变种 1.最开始的3D icp Besl, Paul J., and Neil D. McKay. “A method for registration of 3-D shapes.” IEEE Transactions on pattern analysis and machine intelligence 14.2 (1992): 239-256. 可以使用PCL进行测试 2.Fast icp（Soft Outlier Rejection） Rusinkiewicz, Szymon, and Marc Levoy. “Efficient variants of the ICP algorithm.” 3-D Digital Imaging and Modeling, 2001. Proceedings. Third International Conference on. IEEE, 2001. 该文章被引用次数极高，文章分析了影响icp的各种因素，对几种icp变体进行比较，并且提出了fast icp。能够在几十毫秒内对齐两张深度图（range images） 工程：http://gfx.cs.princeton.edu/proj/trimesh2/ 该工程更新了收敛非常快的“对称ICP”。 3.广义ICP/plane-to-plane ICP：Generalized-icp（GICP） Segal, Aleksandr, Dirk Haehnel, and Sebastian Thrun. “Generalized-ICP.” Robotics: science and systems. Vol. 2. No. 4. 2009. 作者主页：http://www.robots.ox.ac.uk/~avsegal/ 工程：https://github.com/avsegal/gicp 4.sparse icp 稀疏ICP方法采用稀疏诱导准则对该问题进行求解，显著提高了配准过程对大量噪声和离群值的恢复能力，但引入了显著的性能退化。 Efficent Sparse icp：结合模拟退火搜索和Sparse ICP https://github.com/opengp/sparseicp 5.全局优化ICP：Go-ICPYang, Jiaolong, et al. “Go-ICP: a globally optimal solution to 3D ICP point-set registration.” IEEE transactions on pattern analysis and machine intelligence 38.11 (2016): 2241-2254. C.基于CUDA加速 1.em-icp cuda_emicp_softassign 2.cudaICP 应用 KinectFusion 中的 ICP 算法 GPU 代码解读 D.使用pcl来实现ICP 简单的程序：迭代猴子 E.给出其他参考： Iterative Closest Point (ICP) and other matching algorithms 后台回复“icp”自动回复论文和代码（完）","link":"/2019/05/24/Registration/1.ICP-Registration/"},{"title":"Efficient Sparse ICP","text":"稀疏ICP方法采用稀疏诱导准则对该问题进行求解，显著提高了配准过程对大量噪声和离群值的恢复能力，但引入了显著的性能退化。 本文首先分析了性能下降的原因，提出了一种结合模拟退火搜索和标准稀疏ICP的混合优化系统，以更有效地解决底层优化问题。 Efficient Sparse ICP稀疏ICP方法使用稀疏诱导规范来解决这一问题，显著提高了配准过程对大量噪声和异常值的恢复能力，但引入了显著的性能下降。 本文首先分析了性能下降的原因，提出了一种结合模拟退火搜索和标准稀疏ICP的混合优化系统，以更有效地解决底层优化问题。 我们还提供了一些关于如何通过结合使用近似距离查询、并行执行和统一子抽样进一步提高总体效率的见解。所得到的方法提供了超过一个数量级的累积性能增益，通过注册具有不同程度噪声和异常值的部分重叠扫描可以证明这一点。 结合模拟退火，可以快速接近解决方案，使用ADMM优化器，用于确保收敛到最优解决方案，为了进一步提高效率，我们的混合粗到细的方法在第一阶段使用了近似的距离查询。 Bouaziz在论文“Sparse iterative closest point.”中证明了：配准问题可以表示为残差向量的p范数最小化。","link":"/2019/04/09/Registration/3.Efficient-Sparseicp/"},{"title":"Sparse ICP","text":"（TODO）稀疏ICP能鲁棒地处理大量的噪声和异常值。 Sparse Iterative Closest Point 传统的最小二乘ICP不能区分外点和内点 “1-ICP更健壮，但仍然不能处理大量的对应异常值。我们证明了’ p- icp，与p2[0;1]鲁棒地处理大量的噪声和异常值。","link":"/2019/04/10/Registration/3.Sparseicp/"},{"title":"4PCS和Super4PCS","text":"相关4PCS：论文、PPT、可运行exe Spuer4PCS：论文、数据、源码 Auto-Super4PCS：不用设置参数版本super4PCS OpenGR：super4PCS不再维护，将维护版本转置OpenGR 论文解析（TODO）https://www.sohu.com/a/305675544_715754 实例测试（TODO）","link":"/2021/04/06/Registration/4PCSNSpuer4PCS/"},{"title":"GOICP","text":"（TODO）全局优化ICP 论文：Yang, Jiaolong, et al. “Go-ICP: a globally optimal solution to 3D ICP point-set registration.” IEEE transactions on pattern analysis and machine intelligence 38.11 (2016): 2241-2254.","link":"/2019/04/09/Registration/5.GOicp/"},{"title":"Multiview Levenberg-Marquardt ICP","text":"mv-LM-ICP论文解读 Multiview Levenberg-Marquardt ICP0 简介ICP在多视图场景中的应用 作者：Adrian Haarbach 工程：https://github.com/adrelino/mv-lm-icp 论文:mv-lm-icp 使用了nanflann库，实现了kdtree 使用了Ceres Solver库，非线性最小二乘算法（如Levenberg Marquardt）轻松地将点到点和点到面的度量最小化。 背景：ICP的变种 点到点ICP：(最开始的3DICP的论文) Besl, Paul J., and Neil D. McKay. “Method for registration of 3-D shapes.”Robotics-DL tentative (1992): 586-606. 点到面ICP： Chen, Yang, and Gérard Medioni. “Object modelling by registration of multiple range images.”image and vision computing 10.3 (1992): 145-155. 相关的工作： Fitzgibbon, Andrew W. “Robust registration of 2D and 3D point sets.”Image and Vision Computing 21.13 (2003): 1145-1153. Brown, Benedict J., and Szymon Rusinkiewicz. “Global non-rigid alignment of 3-D scans.”ACM Transactions on Graphics (TOG). Vol. 26. No. 3. ACM, 2007. Pulli, Kari. “Multiview registration for large data sets.” 3-D Digital Imaging and Modeling, 1999. Proceedings. Second International Conference on. IEEE, 1999. 1 ICP是什么icp使用两个步骤进行迭代直至收敛，来实现刚性对齐两个点云 寻找两个点集中的对应点对 通过最小化”通过对应点对定义的代价函数“来估计一个变换矩阵 mv-lm-icp主要是在第二步，如何通过代价函数估算出变换矩阵上面上做改进 2 两个点云之间对齐（Pairwise registration） 损失函数（Loss Function ）是定义在单个样本上的，算的是一个样本的误差。 代价函数（Cost Function ）是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。 目标函数（Object Function）定义为：最终需要优化的函数。等于经验风险+结构风险（也就是Cost Function + 正则化项）。关于目标函数和代价函数的区别还有一种通俗的区别：目标函数是最大化或者最小化，而代价函数是最小化 在两个点云对齐的情景中： 对应点集，为模型点云，为场景点云。有变换矩阵，来运动模型点云pi，其中为代价函数，为损失函数。 对应的误差函数(目标函数)为通过最小化误差函数来获得最优的刚体变换 3 多个点云之间对齐（Multiview registration）在多视角的情景中， 上面的方法不再适合，因为一个视角的点云，既可以充当场景点云可以充当也可以是 让代表一组用来对齐的点云：而为了表示哪个点云配准到哪个点云，我们将这些关系用有向图的邻接矩阵表示。 1.两个点云之间的误差函数：如果有M个点云，该邻接矩阵为M×M大小。举个例子，矩阵值表示点云可以配准到点云代表相机在全球坐标系下的绝对位姿，那么两个点云到的配准误差为：其中是两个点云之间的第最近对应点。可以通过设置将公式（2）变成公式（1） 2.多个点云之间的误差函数：通过对每一对重叠视图的贡献求和得到最小化的整体对齐误差可以表示为：我们要求解使得M个点云之间的最小二乘误差函数值最小化。对比与公式（1）的两个点云之间的误差函数中有闭合解，而多视图中没有闭合解。然而，刚性点云配准只是非线性最小二乘优化的一个实例，可以通过“Ceres Solver”来求解。 3.1 一般ICP的代价函数3.1.1Pairwise(两个点云)在论文Method for registration of 3-d shapes，以及论文Iterative point matching for registration of free-form curves and surfaces 中使用的代价函数是： 在论文Object modeling by registration of multiple range images中使用的代价函数是： 在这些情况下，损失函数就是恒等式，代价函数是 两个点云配准的情景中，虽然上述代价函数(4)(5)的存在闭合形式解，但也可以使用Ceres来求解。代价函数的计算被称为残差（residuals），残差不一定在空间中。 3.1.2多视角多视角点云配准的代价函数只是在两个点云配准的代价函数上做了些许修改。 在pairwise中，代价函数依赖于相对位姿。 在multiview中，代价函数d依赖于两个绝对位姿和。 4 参数化刚体运动4.1 Angle Axis旋转向量4.1.1 Cost function4.1.2 Jacobian依靠Ceres AutoDiCostFunction功能自动计算我们的代价函数的必要的导数参数化的角度轴表示和一个平移向量 4.2 Unit Quaternions 四元数4.2.1 Local Parametrization4.2.2 Cost function4.2.3 Jacobian4.3 Lie Algebra of Twists 李代数### 4.3.1 Cost function 4.3.2 Jacobian","link":"/2019/04/09/Registration/mvlmicp/"},{"title":"NDT-Registration","text":"点云配准之正态分布变换 精细配准，除了ICP，我用得比较多的就是ndt了。 ndt也可以粗配准。 ndt表现比icp要好。 A.NDT算法介绍： 详细请参考： 1.博主博文 Detailed Notes to NDT 2.以及AdamShan的博客 无人驾驶汽车系统入门（十三）——正态分布变换（NDT）配准与无人车定位 B.开源项目： 自动驾驶开源项目中Autoware https://github.com/CPFL/Autoware 利用 fast_pcl package实现了对NDT优化过程的并行加速 C.PCL中的NDT: pcl中的接口在官网和其他博客有详细描述这里不再细说。 调参是主要是设置分别率和步长，分辨率越大考虑的的范围越多，当分辨率很小（对比数据）的时候，会出现内存错误。步长越大，曲面移动A(位姿变换)得越快。 12345678910111213141516171819 pcl::NormalDistributionsTransform&lt;pcl::PointXYZ, pcl::PointXYZ&gt; ndt;​ Setting scale dependent NDT parameters​ ndt.setTransformationEpsilon(0.00001);​ ndt.setStepSize(5);​ ndt.setResolution(5);​ ndt.setMaximumIterations(50);//200​ ndt.setInputSource(filtered_cloud);​ ndt.setInputTarget(target_cloud);​ pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);​ ndt.align(*output_cloud); D.ndt算法和icp比较 http://ghx0x0.github.io/2014/12/30/NDT-match/ 后台回复“ndt”自动回复论文和代码(完）","link":"/2019/05/24/Registration/NDT-Registration/"},{"title":"3D scene reconstruction","text":"室内场景稠密重建 KinectFusion 和 ElasticFusion视频链接 KinectFusion 介绍：http://blog.csdn.net/fuxingyin/article/details/51417822 ElasticFusion 介绍：http://blog.csdn.net/fuxingyin/article/details/51433793 资料链接1 资料链接2","link":"/2019/06/30/Reconstruction/3D_scene_reconstruction/"},{"title":"3D reconstruction","text":"知识星球（3D视觉工坊）吴博课程笔记 解决左右相机匹配，通过投影机投影标记信息来标记物体的每个点的位置。 相关人： 南京理工大学左超教授 主讲嘉宾：吴博，四川大学三维传感与机器视觉实验室博士研究生,研究方向为便携式三维测量、高速三维形貌及形变测量。 笔记：TODO","link":"/2019/06/13/Reconstruction/3d_reconstruction2/"},{"title":"surface reconstruction","text":"点云生成网格 表面重建（点云到网格）[线上分享录播]基于点云数据的 Mesh重建与处理 笔记TODO PCL中的表面重建 gp3 greedy projection—贪婪投影算法 参考 贪心投影三角化的大致流程是这样的： （1）先将点云通过法线投影到某一二维坐标平面内 （2）然后对投影得到的点云做平面内的三角化，从而得到各点的拓扑连接关系。平面三角化的过程中用到了基于Delaunay三角剖分 的空间区域增长算法 （3）最后根据平面内投影点的拓扑连接关系确定各原始三维点间的拓扑连接，所得三角网格即为重建得到的曲面模型 grid_projection 网格投影 marching_cubes 移动立方体 marching_cubes_hoppe marching_cubes_rbf mls 移动最小二乘法 organized_fast_mesh poisson 泊松重建 EarClipping 耳切法 将一个普通多边形拆解成多个三角形 delaunay2.5D（cloudcompare） 所有边都是德劳内边的剖分是德劳内三角剖分。 扫描线法（Sweepline） 随机增量法（Incremental） 按照随机的顺序依次插入点集中的点 首先确定vi落在哪个三角形中（或边上） 然后将vi与三角形三个顶点连接起来构成三个三角形（或与共边的两个三角形的对顶点连接起来构成四个三角形） 由于新生成的边以及原来的边可能不是或不再是Delaunay边，故进行边翻转来调整使之都成为Delaunay边，从而得出DT(v1,v2,…,vi)。 分治法（Divide and Conquer） 三角剖分原理： 德劳内三角剖分 三种计算方法 开源： ofxDelaunay: delaunay-triangulation: Delaunay三角剖分算法是一种常用的算法，它的特点是剖分结果的每个三角形都尽量接近等边三角形。 平面域三角剖分、平面投影法 将三维点投影到某个平面，如XY平面，然后对投影点集 作平面域的三角剖分, 最终形成的曲面三角剖分的点间连接关系与相应的投影点间的连接关系相同, 最佳平面拟合 同理，只是投影到最佳拟合的平面上，再对点进行剖分。 直线或线段与mesh网格相交的计算https://blog.csdn.net/qq_33263124/article/details/88179289 MLSCUDA-MLS VOXELIZERhttps://github.com/Forceflow/cuda_voxelizer","link":"/2021/05/11/Reconstruction/surface_reconstruction/"},{"title":"SSE coding","text":"SSE指令集入门教程 简介官方文档：intel intrinsics guide SSE指令集使用方法和CUDA类似 123456789101112131415161718void sse_cal(float *a,float*b){ __m128 m1, m2, m3; //声明变量 __m128 SSEA = _mm_load_ss(a); //将a地址指向的值复制给SSEA __m128 SSEB = _mm_load_ss(b); //将a地址指向的值复制给SSEA __m128 h = _mm_set_ss(1.0f); //声明变量并赋值 for(int i=0;i&lt;LOOP;i++) { //类似于cuda里面的thrust函数进行一些常规操作 m1 = _mm_mul_ss(SSEA, SSEB);//相乘 m2 = _mm_sqrt_ss(SSEB); //平方和 m3 = _mm_add_ss(m1,m2); //相加 SSEA = _mm_add_ss(SSEA, h); SSEB = _mm_add_ss(SSEB, h); }} 参考： 入门教程 SSE指令的使用学习 SSE双线性插值 OpenMP+SSE123456789101112131415161718192021222324252627282930313233343536373839void TransformPointCloud(std::vector&lt;Vector3&gt;&amp; pointcloud, const Eigen::Matrix4&amp; transformation_matrix){ if (transformation_matrix == Eigen::Matrix4::Identity()) { return; }#pragma parallel for for (int i = 0; i &lt; pointcloud.size(); i++) { pointcloud[i] = transformation_matrix.topLeftCorner&lt;3, 3&gt;()*pointcloud[i] + transformation_matrix.topRightCorner&lt;3, 1&gt;(); }}void TransformPointCloud_SSE(std::vector&lt;Vector3&gt;&amp; pointsIn, std::vector&lt;Vector3&gt;&amp; pointsOut, const Eigen::Matrix4&amp; transformation_matrix){ int num = pointsIn.size(); if (num != pointsOut.size()) pointsOut.resize(num); __m128 c[4]; for (int i = 0; i &lt; 4; i++) { c[i] = _mm_load_ps(transformation_matrix.col(i).data()); } //T11*X+T21*Y+T31*Z+T41 //T12*X+T22*Y+T32*Z+T42 //T13*X+T23*Y+T33*Z+T43 //T14*X+T24*Y+T34*Z+T44#pragma omp parallel for for (int i = 0; i &lt; num; i++) { Vector4 temp; __m128 p0 = _mm_mul_ps(_mm_load_ps1(&amp;(pointsIn[i].x())), c[0]); __m128 p1 = _mm_mul_ps(_mm_load_ps1(&amp;(pointsIn[i].y())), c[1]); __m128 p2 = _mm_mul_ps(_mm_load_ps1(&amp;(pointsIn[i].z())), c[2]); _mm_store_ps(temp.data(), _mm_add_ps(p0, _mm_add_ps(p1, _mm_add_ps(p2, c[3])))); pointsOut[i] = temp.head&lt;3&gt;(); }} 780000个点运行100次 普通点云变换时间为：582msSSE加速变换时间为：173ms","link":"/2021/05/17/SSE/SSE/"},{"title":"cuda code error","text":"thrust[thrust::system::system_error] 1234567cudaMalloc((void**)&amp;nanFlags_dev, N*sizeof(int));getNANpts &lt;&lt; &lt;fullBlocksPerGrid, blockSize &gt;&gt; &gt;(N, z_dev, nanFlags_dev);cudaDeviceSynchronize();thrust::device_ptr&lt;int&gt; thrust_nanflags(nanFlags_dev);//int num_of_nan = thrust::reduce(thrust_nanflags, thrust_nanflags + N, (int)0, thrust::plus &lt;int &gt;()); //统计有多少个NAN点int num_of_nan = thrust::count(thrust_nanflags, thrust_nanflags + N, 1); //统计有多少个NAN点cudaDeviceSynchronize(); 出现错误： 原因：核函数getNANpts写错了。只对nanFlags_dev中的一个位置进行初始化，其他位置没有赋值，所以进行计算时会错误。","link":"/2021/01/17/cuda/CUDA_CodeError/"},{"title":"CUDA basic knowledge","text":"物理概念、CUDA基本概念、CUDA语法、调试器、错误处理 SSE增加数据吞吐（128位） OpenMP增加线程数，所以两个一起使用能使CPU程序最大化 物理概念本人设备： RTX 2060 、GTX1080TI 设备 RTX2060 GTX1080TI 架构 图灵 pascal 核心数（cuda core）/SP 1920 3584 核心频率 1365MHz 1480MHz 纹理单元 120 224 Tensor核心 240 无 RT核心 30 ROPs单元 48 88 显存大小 6GB 11GB 显存位宽为 192bit 352bit 显存带宽 336GB/s 484GB/s 484GB/s = 495616MB/s=495.616MB/s。理论上能在1ms内把500MB的数送进流处理器。 GPU实际上是一个SM阵列(GTX1080TI有28个SM)(RTX2060有30个SM)，SM每个SM中包含N个核(cuda core)也叫SP（1080TI每个SM中有128个sp）)(RTX2060每个SM有64个sp)。1080TI有3584个流处理器（SP），RTX2060有1920个流处理器（SP)。 SM每个SM都有一个寄存器文件（Register FIle），这是一组能够以与SP相同速度工作的存储单元，所以访问这组单元不需要任何等待时间。它用来存储SP上运行线程内部活跃的寄存器。 每个SM有一个内部访问的共享内存(shared memory)，可以用作程序可控的高速缓存。 SM每次可同时计算32个数而不是像CPU那样只计算一个数。 内存CPU和GPU有各自独立的内存空间，因此在GPU代码中，不可以直接访问CPU端的代码。反过来同理。 对于纹理内存、常量内存，全局内存，每一个SM都分别设置有独立访问它们的总线。 纹理内存内存是针对全局内存的一个特殊视图，用来存储插值(interpolation)计算所需的数据。（基于硬件进行插值） 常量内存用于存储那些只读的数据。常量内存也是全局内存建立的一个视图 原子操作是指那些必须一次性完成、不会被其他线程中断的操作 CUDA概念设备CUDA参数使用自带例程deviceQuery查询 页锁定主机内存测试demo CUDA页锁定主机内存（主机的固定内存），好处固定内存复制到显存，或显存复制到固定内存快。 使用页锁定内存也需要申请GPU内存和主机内存啊，只不过使用cudaHostAlloc()申请主机内存的时候，申请的主机内存是不可分页的（即申请的是固定内存，使用物理地址访问），还是需要使用cudaMemcpy()来将主机内存中的数据拷贝到GPU内存中。好处就是主机和GPU之间复制数据速率更快.主机内存到显存，显存到主机内存都有加快，大概两倍。缺点就是申请的是物理内存，不是虚拟内存，内存很快就会耗尽，所以一般都会用完就释放 线程GPU的每个线程组被送到SM中，然后N个SP开始执行代码。事实上，线程都是以每32个为一组。这个线程组叫线程束。以线程束为单位进行操作。 如果一个block中有128个线程，每个线程传递3个参数，那么就需要3X128=384个寄存器。这听起来很多，但是其实每个SM(流处理器)中至少有8192个寄存器。就是说每个线程可以使用64个寄存器，只有当运算前度很强的时候才使用64个寄存器。 线程块线程网格一个线程网格是由若干个线程块组成的，每个线程块是二维的，拥有X轴与Y轴。 由于数组的存在，数据往往不可能是一维的。这时我们可以使用二维的线程块。 线程束（大小为32）线程束是GPU的基本执行单元。GPU是一组SIMD向量处理器的集合。每一组线程或每个线程束中的线程同时执行。在理想状态下，获取当前指令只需要一次访存，然后将这个指令广播到这个线程束所占用的所有SP中。 GPU利用率注意事项： 每个线程块开启的线程数越多，就潜在地增加了等待执行较慢线程束的可能性。因为当所有线程没有到达同步点时GPU是无法继续向下执行的。因此，有时候我们会选择在每个线程块上开启较少的线程，例如，128个线程，以此来减少之前那种等待的可能性。但是这样做会严重影响性能。 CUDA语法12CUDA内核 kernel_function&lt;&lt;&lt;num_blocks,num_threads&gt;&gt;&gt;(param1,param2,…) # Nsight调试器 # 错误处理","link":"/2021/05/06/cuda/CUDA_baseKnowledge/"},{"title":"无标定立体视觉计算深度","text":"针孔模型与透视投影成像 相机标定过程 立体视觉的对极几何 无标定立体视觉的基本矩阵的估计 无标定立体视觉计算深度 笔记：TODO","link":"/2021/05/26/Reconstruction/3d_reconstruction3/"},{"title":"CUDA笔记补充","text":"几种同步方式 几种同步方式参考 1.cudaDeviceSynchronize(); 2.cudaThreadSynchronize(); 3.cudaStreamSynchronize(); cudaDeviceSynchronize()会阻塞当前程序的执行，直到所有任务都处理完毕（这里的任务其实就是指的是所有的线程都已经执行完了kernel function） udaThreadSynchronize()的功能和cudaDeviceSynchronize()基本上一样，这个函数在新版本的cuda中已经被“废弃”了，不推荐使用，如果程序中真的需要做同步操作，推荐使用cudaDeviceSynchronize()。 cudaStreamSynchronize()和上面的两个函数类似，这个函数带有一个参数，cuda流ID，它只阻塞那些cuda流ID等于参数中指定ID的那些cuda例程，对于那些流ID不等的例程，还是异步执行的。","link":"/2019/06/14/cuda/cuda FQA/"},{"title":"CUDA知识片段","text":"线程模型适合用于OpenMP。进程模型适用于MPI 在GPU环境下：CUDA使用一个线程块（block）构成网格（grid）。这可以看成是一个进程（即线程块）组成的队列（即网格），而进程之间没有通信。每一个线程块内部有很多线程以批处理的方式运行，称为线程束（warp）","link":"/2021/01/17/cuda/cudaKnowledgefragment/"},{"title":"CUDA Code Optimization","text":"张也冬视频笔记 内存上的优化 计算上的优化 B站视频 CUDA代码优化代码（转置矩阵） 输入/输出数据：N×N（1024 * 1024） 维度的矩阵 每个block的线程数目为16X16=256 运行时间0.46ms 影响代码性能的2个方面的因素 内存的存取耗时—可能是制约性能的主要原因，进入优化阶段 运算耗时—几乎没有运算 一、内存上的优化Memory Optimization deviceQuery查询得到; Memory clock rate(MHz)—每秒内存周期clock/second （每秒内存跑多少次） Memory Bus Width(bit)—每秒周期传输的比特数bits/clock （每次跑多少数据量） 可以计算内存峰值带宽(Theoretical peak bandwidth) Memory clock rate * Memory Bus Width （每秒跑多少数据量） Titan X的参数为： Memory clock rate =3505 MHz =3.42 GHz Memory Bus Width =384 bit Bus Type GDDR5(double data rate) 得理论峰值带宽为3.42 x (384/8) x 2 =328.31GB/s 经验法则Rule of Thumb接上面 一条经验法则是，如果实际内存带宽达到理想理论峰值内存带宽的： 40%~60%-&gt;okay 60%~75%-&gt;good 大于75%-&gt;excellent 本代码中世纪内存带宽表现如何？ 1024 * 1024 * 4(4字节数据) * 2（2次读写内存）/0.67e-3=18.24GB/s &lt;&lt;328.31GB/s 并行化元素级别后，DRAM利用率还是那么低，思考解决方法 解决方法合并Coalesce和跨步Strided 存储到全局内存时，线程数据的复制方式：合并形式与跨步形式，合并方式比跨步方式好，小跨步比大跨步好。 目前代码问题： Coalesced reads,scattered writes 修改的目标是： Coalesced reads,Coalesced writes 1.使用共享内存 声明了一个共享内存的空间tile，把全局内存in里面的数据转置后复制到tile中 同步线程块里面的线程（线程之间互相等待，同步好之后再执行下一步） 一次性将tile中的数据复制到全局内存out中 由于之前复制到全局内存的时候是以32×32=1024个 现在使用共享内存之后的步长为32个，但是没有带到完全Coalesced的方式，但是减少了步长。 2.Another Point:Useful memory bandwith 问题：如果内存不能及时将数据传递到处理器中，或及时存储运算结果，GPU工作的效率会大打折扣 目标：对于内存带宽受限的kernel函数，存在优化的子目标—充分利用有效的内存带宽 Little’s Law 什么是有效的内存带宽？—由排队论的Little’s Law Number of useful bytes delivered = average latency of each transaction*bandwidth 传送的字节数为每个内存事物的平均延迟与带宽的乘积 类似于在星巴克排队等待购买咖啡 由此，改善代码内存带宽还可以有以下出发点： 增加传送的字节数—有很多服务员同时提供咖啡 减少食物见的延迟—服务员更快地提供服务 3.Locate low efficiency 反观代码 每个tile完成转置后，执行__syncthreads()同步 32×32=1024个线程执行少量任务后，互相等待，再把这1024个数据存到内存当中，造成平局延迟较大 改进：reduce Average Delay 解决方法： 减少每个线程块中的线程束 增加使用每个SM中的线程块数 尝试结果： 占用率Occupancy 共享内存的架构 没有bank conflicts 各个线程同时分别访问对应的Bank（线程0访问Bank0，线程1访问Bank1。。。，大家同时进行Bank访问时没有冲突） 有bank conflicts 两个线程同时访问同一个Bank，造成Bank Conficts 八个线程同时访问同一个Bank，造成Bank Conficts，八个比两个更加严重 不能多个线程同时访问同一个内存位置（cache），否则会造成等待（延迟）。就把本来是一个并行的事变成串行的事。 bank conflict in code在上面改进后的代码(使用了共享内存的代码)中也存在这样的问题(bank conflicts)。是下面的图1中的情况。 下图中对应线程每次都访问同一个bank，比如线程0每次访问的都是绿色的bank0。线程1每次访问的都是橙色的bank1。 下图中，线程1第一次访问的是bank0，第二次访问的是bank1，不会每次都在等候同一个bank。下面的图2中加了个padding（填充），使得线程0访问的是Bank1，线程1访问的是Bank2了，这样子使得线程不会一直占用着同一个bank进行等候。 二、计算上的优化 优化内存访问通常是GPU优化的瓶颈 优化内存访问之余，优化运算性能也很重要 最小化线程发散程度 选择效率更高的数学计算—提升“最后一点性能” 减少线程发散：Minimize Threads DIvergence 线程束内线程会进行等待，避免有的线程计算时间长有的线程计算时间短。 更有效果的方法More efficiency,less accuracy—save the amount of time 仅在必要时使用双精度浮点运算 快速的数学近似算法：牺牲精度追求效率。 内部函数（intrinsic functions） cuda的内部函数，比如sin，cos，指数运算 在Thrust库里面有reduce函数 三、CPU-GPU Interaction GPU通过DMA方式访问CPU的锁叶内存(pinned memory) cudaMemcpy()是一种阻塞传输；而cudaMemcpyAsync()非阻塞 cudaHostMalloc()+cudaMemcoyAsync()实现异步传输和计算 四、Stream 保证流之间不相关。 基本算法一、Reduce（规约）自带库中已经有很好的接口。下图中，第二个和第三个都是四步，但是第二个没有第三个好。 规约版本1(不是指上图的第一个版本的计算)，线程的执行在下面表示 执行线程流程 遍历0～14 遍历0～12 遍历0～8 最后一个执行线程0 存在一些没有意义的遍历，线程分散度比较高， 使用求余运算符占用时间大 在线程号上面改动，线程的执行在下面表示， 遍历个数在减少第一次遍历8个，第二次遍历4个，第三次2个 但是引起bank conflicts（格子表示bank）下图中bank4（第5个格子）对应了两个线程，线程2和1，会引起多对1问题。 线程的执行在下面表示， 保证了对应线程的对应bank一直是一样的，那么每个bank就不会被其他线程索引，除去了线程冲突。 但是后面大量的线程没有被利用，是空着的。 改进4 在把数据移到共享内存的过程中实现一部分规约操作 其他优化手段 TIPs 书籍推荐不推荐买书，因为CUDA更新得快，看文档就好了","link":"/2019/06/28/cuda/CUDAcodeOptimazation/"},{"title":"cudanote1","text":"第三章 简介 缓冲与缓存的区别，核函数，内置参数，参数传递 GitHub 建议下载下来用Typora软件阅读markdown文件 作者github:littlebearsama 原文链接 (建议下载Typora来浏览markdown文件) 缓冲区(buffer)与缓存区(cache)一、缓冲缓冲区(buffer)，它是内存空间的一部分。也就是说，在内存空间中预留了一定的存储空间，这些存储空间用来缓冲输入或输出的数据，这部分预留的空间就叫做缓冲区，显然缓冲区是具有一定大小的。 缓冲区根据其对应的是输入设备还是输出设备，分为输入缓冲区和输出缓冲区。 二、缓存 CPU的Cache，它中文名称是高速缓冲存储器，读写速度很快，几乎与CPU一样。由于CPU的运算速度太快，内存的数据存取速度无法跟上CPU的速度，所以在cpu与内存间设置了cache为cpu的数据快取区。当计算机执行程序时，数据与地址管理部件会预测可能要用到的数据和指令，并将这些数据和指令预先从内存中读出送到Cache。一旦需要时，先检查Cache，若有就从Cache中读取，若无再访问内存，现在的CPU还有一级cache，二级cache。简单来说，Cache就是用来解决CPU与内存之间速度不匹配的问题，避免内存与辅助内存频繁存取数据，这样就提高了系统的执行效率。 磁盘也有cache,硬盘的cache作用就类似于CPU的cache，它解决了总线接口的高速需求和读写硬盘的矛盾以及对某些扇区的反复读取。 三、缓存（cache）与缓冲(buffer)的主要区别Buffer的核心作用是用来缓冲，缓和冲击。比如你每秒要写100次硬盘，对系统冲击很大，浪费了大量时间在忙着处理开始写和结束写这两件事嘛。用个buffer暂存起来，变成每10秒写一次硬盘，对系统的冲击就很小，写入效率高了，日子过得爽了。极大缓和了冲击。 Cache的核心作用是加快取用的速度。比如你一个很复杂的计算做完了，下次还要用结果，就把结果放手边一个好拿的地方存着，下次不用再算了。加快了数据取用的速度。 简单来说就是buffer偏重于写，而cache偏重于读。 第三章 简介 将CPU即系统的内存称为主机（host），而将GPU及其内存称为设备（device） 123456789101112131415161718#include&lt;stdio.h&gt;__global__ void add(int a,int b,int *c){ *c = a + b;}int main(){ int c; int *dev_c; cudaMalloc((void**)&amp;dev_c,sizeof(int)); add&lt;&lt;&lt;1,1&gt;&gt;&gt;(2,7,dev_c); cudaMemcpy(&amp;c, dev_c, sizeof(int), cudaMemcpyDeviceToHost); printf(\"2 + 7 = %d\",c); cudafree（dev_c）; return 0;} 1.核函数调用 1.函数的定义带有了__global__这个标签，表示这个函数是在GPU上运行。函数add()将被交给“编译设备代码的编译器”。需要指出的是尽管是在GPU上执行，但是仍然是由CPU端发起调用的。 在每个启动线程中都被调用一遍。 2.主机代码发送给一个编译器，而将设备代码发送给另外一个编译器（CUDA编译器）,CUDA编译器运行时将负责实现从主机代码中调用设备代码。 3.核函数相对于CPU代码是异步的，也就是控制会在核函数执行完成之前就返回，这样CPU就可以不用等待核函数的完成而继续执行后面的CPU代码 4.核函数内部只能访问device内存。因为核函数是执行在设备端，所以只能访问设备端内存。所以要使用cudaMalloc在GPU的内存(全局内存)里开辟一片空间。用来存放结果dev_c。再通过*cudaMemcpy这个函数把内容从GPU**复制出来。 函数部分前缀： 限定符 在哪里被调用 在哪里被执行 __host__（默认缺省） 仅由CPU调用 由CPU执行 __gobal__ 仅由CPU调用 由GPU执行 __device__ 仅由GPU中一个线程调用的函数 由GPU执行 限制： __host__： 限定符无法一起使用 __gobal__： 限定符无法一起使用； 函数不支持递归； 函数的函数体内无法声明静态变量； 函数不得有数量可变的参数； 支持函数指针； 函数的返回类型必须为空； 函数的调用是异步的，也就是说它会在设备执行完成之前返回； 函数参数将同时通过共享存储器传递给设备，且限制为 256 字节； __device__： 函数不支持递归； 函数的函数体内无法声明静态变量； 函数不得有数量可变的参数； 函数的地址无法获取 之前说了__host__和__gobal__限定符无法和其他限定符使用，但与 __device__限定符不是 __constant__ 限定符可选择与 __device__限定符一起使用，所声明的变量具有以下特征： 1.位于固定存储器空间中；2. 与应用程序具有相同的生命周期；3.可通过网格内的所有线程访问，也可通过“运行时库”从主机访问。 __shared__ 限定符可选择与 __device__限定符一起使用，所声明的变量具有以下特征：1.位于线程块的共享存储器空间中；2. 与块具有相同的生命周期；3.尽可通过块内的所有线程访问。只有在_syncthreads()_的执行写入之后，才能保证共享变量对其他线程可见。除非变量被声明为瞬时变量，否则只要之前的语句完成，编译器即可随意优化共享存储器的读写操作。 2.参数传递 &lt;&lt;&lt;&gt;&gt;&gt;尖括号表示要将一些参数传递给运行时系统，这些参数并不是传递给设备代码的参数，而是告诉运行时如何启动设备代码。传递给设备代码本身的参数是放在圆括号中传递的。 尖括号作用？线程配置。 &lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt; Dg 的类型为 dim3，指定网格的维度和大小，Dg.x * Dg.y 等于所启动的块数量，Dg.z =1无用，目前还不支持三维的线程格；如果指定Dg=256，那么将有256个线程块在GPU上运行。 Db 的类型为 dim3，指定各块的维度和大小，Db.x * Db.y * Db.z 等于各块的线程数量； Ns 的类型为 size_t，指定各块为此调用动态分配的共享存储器（除静态分配的存储器之外），这些动态分配的存储器可供声明为外部数组的其他任何变量使用，Ns 是一个可选参数，默认值为 0； S 的类型为 cudaStream_t，指定相关流；S 是一个可选参数，默认值为 0。 核函数内部可以调用CUDA内置变量，比如threadIdx，blockDim等。下下章将具体谈到线程索引。 参数传递和普通函数一样，通过括号内的形参传递。","link":"/2019/05/24/cuda/cudanote1/"},{"title":"cudanote5","text":"第八章 互操作性 OpenGL与互操作性 GitHub 建议下载下来用Typora软件阅读markdown文件 作者github:littlebearsama 原文链接 (建议下载Typora来浏览markdown文件) 第八章 互操作性GPU的成功要归功于它能实时计算复杂的渲染任务，同时系统的其他部分还可以执行其他工作。 互操作性概念： 通用计算：譬如前面的计算，在GPU上面进行的计算 渲染任务 互操作是指在通用计算与渲染模式之间互操作 提出问题：问1：那么能否在同一个应用程序中GPU既执行渲染计算，又执行通用计算？ 问2：如果要渲染的图像依赖于通用计算的结果，那么该如何处理？ 问3：如果想要在已经渲染的帧上执行某种图像处理或者统计，又该如何实现？ 与OpenGL的互操作性CUDA程序生成图像数据传递给OpenGL驱动程序并进行渲染 1.代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121/********************************************************************* SharedBuffer.cu* interact between CUDA and OpenGL*********************************************************************/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;//下面两个头文件如果放反了会出错#include \"GL\\glut.h\"#include \"GL\\glext.h\"#include &lt;cuda_runtime.h&gt;//#include &lt;cutil_inline.h&gt;#include &lt;pcl\\cuda\\cutil_inline.h&gt;#include &lt;cuda.h&gt;#include &lt;cuda_gl_interop.h&gt;#define GET_PROC_ADDRESS(str) wglGetProcAddress(str)#define DIM 512PFNGLBINDBUFFERARBPROC glBindBuffer = NULL;PFNGLDELETEBUFFERSARBPROC glDeleteBuffers = NULL;PFNGLGENBUFFERSARBPROC glGenBuffers = NULL;PFNGLBUFFERDATAARBPROC glBufferData = NULL;// step one:// Step1: 申明两个全局变量，保存指向同一个缓冲区的不同句柄，指向要在OpenGL和CUDA之间共享的数据；GLuint bufferObj;cudaGraphicsResource *resource;__global__ void cudaGLKernel(uchar4 *ptr){ int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; int offset = x + y * blockDim.x * gridDim.x; //将图像中心设为原点后的像素索引 float fx = x / (float)DIM - 0.5f; float fy = y / (float)DIM - 0.5f; unsigned char green = 128 + 127 * sin(abs(fx * 100) - abs(fy * 100)); ptr[offset].x = 0; ptr[offset].y = green; ptr[offset].z = 0; ptr[offset].w = 255;}void drawFunc(void){ glDrawPixels(DIM, DIM, GL_RGBA, GL_UNSIGNED_BYTE, 0); glutSwapBuffers();}static void keyFunc(unsigned char key, int x, int y){ switch (key){ case 27: cutilSafeCall(cudaGraphicsUnregisterResource(resource)); glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0); glDeleteBuffers(1, &amp;bufferObj); exit(0); }}int main(int argc, char* argv[]){ // step 2: // 初始化CUDA // Step2: 选择运行应用程序的CUDA设备(cudaChooseDevice),告诉cuda运行时使用哪个设备来执行CUDA和OpenGL (cudaGLSetGLDevice）； cudaDeviceProp prop; int dev; memset(&amp;prop, 0, sizeof(cudaDeviceProp)); prop.major = 1; prop.minor = 0; cutilSafeCall(cudaChooseDevice(&amp;dev, &amp;prop)); //为CUDA运行时使用openGL驱动做准备 cutilSafeCall(cudaGLSetGLDevice(dev)); //初始化OpenGL //在执行其他的GL调用之前，需要首先执行这些GLUT调用。 glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGBA); glutInitWindowSize(DIM, DIM); glutCreateWindow(\"CUDA interact with OpenGL\"); glBindBuffer = (PFNGLBINDBUFFERARBPROC)GET_PROC_ADDRESS(\"glBindBuffer\"); glDeleteBuffers = (PFNGLDELETEBUFFERSARBPROC)GET_PROC_ADDRESS(\"glDeleteBuffers\"); glGenBuffers = (PFNGLGENBUFFERSARBPROC)GET_PROC_ADDRESS(\"glGenBuffers\"); glBufferData = (PFNGLBUFFERDATAARBPROC)GET_PROC_ADDRESS(\"glBufferData\"); // Step3：在OpenGL中创建像素缓冲区对象； glGenBuffers(1, &amp;bufferObj); glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, bufferObj); glBufferData(GL_PIXEL_UNPACK_BUFFER_ARB, DIM*DIM * 4, NULL, GL_DYNAMIC_DRAW_ARB);//glBufferData()的调用需要OpenGL驱动程序分配一个足够大的缓冲区来保存DIM*DIM 个32位的值 // step 4: // Step4: 通知CUDA运行时将像素缓冲区对象bufferObj注册为图形资源，实现缓冲区共享。 cutilSafeCall(cudaGraphicsGLRegisterBuffer(&amp;resource, bufferObj, cudaGraphicsMapFlagsNone));//cudaGraphicsMapFlagsNone表示不需要为缓冲区指定特定的行为 //cudaGraphicsMapFlagsReadOnly将缓冲区指定为只读的 //通过标志cudaGraphicsMapFlagsWriteDiscard来制定缓冲区之前的内容应该抛弃，从而使缓冲区变成只写的 uchar4* devPtr; size_t size; cutilSafeCall(cudaGraphicsMapResources(1, &amp;resource, NULL)); cutilSafeCall(cudaGraphicsResourceGetMappedPointer((void**)&amp;devPtr, &amp;size, resource)); dim3 grids(DIM / 16, DIM / 16); dim3 threads(16, 16); cudaGLKernel &lt;&lt; &lt;grids, threads &gt;&gt; &gt;(devPtr); cutilSafeCall(cudaGraphicsUnmapResources(1, &amp;resource, NULL)); glutKeyboardFunc(keyFunc); glutDisplayFunc(drawFunc); glutMainLoop(); return 0;} 2.代码解析： Step1: 申明两个全局变量，保存指向同一个缓冲区的不同句柄，指向要在OpenGL和CUDA之间共享的数据； 12GLuint bufferObj;cudaGraphicsResource *resource; Step2: 选择运行应用程序的CUDA设备(cudaChooseDevice),告诉cuda运行时使用哪个设备来执行CUDA和OpenGL (cudaGLSetGLDevice）cutilSafeCall(cudaChooseDevice(&amp;dev, &amp;prop)); Step3：共享数据缓冲区是在CUDA C核函数和OpenG渲染操作之间实现互操作的关键部分。要在OpenGL和CUDA之间传递数据，我们首先要创建一个缓冲区在这两组API之间使用，在OpenGL中创建像素缓冲区对象；，并将句柄保存在全局变量GLuint bufferObj中： 123glGenBuffers(1, &amp;bufferObj);glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, bufferObj);glBufferData(GL_PIXEL_UNPACK_BUFFER_ARB, DIM*DIM * 4, NULL, GL_DYNAMIC_DRAW_ARB); Step4: 通知CUDA运行时将像素缓冲区对象bufferObj注册为图形资源，实现缓冲区共享。 123cutilSafeCall(cudaGraphicsGLRegisterBuffer(&amp;resource, bufferObj, cudaGraphicsMapFlagsNone)); 互操作性基本上就是调用接口，可以通过GPU Computing SDK的代码示例来学习 与DirectX的互操作性（略）","link":"/2019/05/24/cuda/cudanote5/"},{"title":"cudanote8","text":"第十一章 多GPU 零拷贝主机内存，可移动固定的内存 GitHub 建议下载下来用Typora软件阅读markdown文件 作者github:littlebearsama 原文链接 (建议下载Typora来浏览markdown文件) 第十一章 多GPU零拷贝主机内存 前面使用函数cudaHostAlloc()申请固定内存，并且设定参数cudaHostAllocDefault来获得默认的固定内存。 在函数cudaHostAlloc()使用其他参数值：cudaHostAllocMapped分配的主机内存也是固定的，它与通过cudaHostAllocDefault分配的固定内存有着相同的属性，特别当它不能从物理内存中交换出去或者重新定位时。 这种内存除了可以用于主机和GPU之间的内存复制外，还可以打破第三章主机内存规则之一：可以在CUDA C核函数中直接访问这种类型的主机内存。由于这种内存不需要复制到GPU，因此也称为零拷贝内存 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455float cuda_pinned_alloc_test(int size) { cudaEvent_t start, stop; float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; float elapsedTime; cudaEventCreate(&amp;start); cudaEventCreate(&amp;stop); // allocate the memory on the CPU cudaHostAlloc((void**)&amp;a, size * sizeof(float), cudaHostAllocWriteCombined | cudaHostAllocMapped); cudaHostAlloc((void**)&amp;b, size * sizeof(float), cudaHostAllocWriteCombined | cudaHostAllocMapped); cudaHostAlloc((void**)&amp;partial_c, blocksPerGrid * sizeof(float), cudaHostAllocMapped); // find out the GPU pointers cudaHostGetDevicePointer(&amp;dev_a, a, 0); cudaHostGetDevicePointer(&amp;dev_b, b, 0); cudaHostGetDevicePointer(&amp;dev_partial_c, partial_c, 0); // fill in the host memory with data for (int i = 0; i &lt; size; i++) { a[i] = i; b[i] = i * 2; } cudaEventRecord(start, 0); dot &lt;&lt; &lt;blocksPerGrid, threadsPerBlock &gt;&gt; &gt;(size, dev_a, dev_b, dev_partial_c); cudaThreadSynchronize(); cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&amp;elapsedTime, start, stop); // finish up on the CPU side c = 0; for (int i = 0; i &lt; blocksPerGrid; i++) { c += partial_c[i]; } //无论使用什么标志都使用这个函数来释放 cudaFreeHost(a); cudaFreeHost(b); cudaFreeHost(partial_c); // free events cudaEventDestroy(start); cudaEventDestroy(stop); printf(\"计算结果: %f\\n\", c); return elapsedTime;} cudaHostAllocMapped：这个标志告诉运行时将从GPU中访问这块内存（分配零拷贝内存） cudaHostAllocWriteCombined：这个表示，运行时将内存分配为“合并式写入（Write-Combined）”内存。这个标志并不会改变应用程序的功能，但却可以显著地提升GPU读取内存时的性能。然而CPU也要读取这块内存时，“合并式写入”会显得很低效。 cudaHostGetDevicePointer：获取这块内存在GPU上的有效指针。这些指针将被传递给核函数。 cudaThreadSynchronize()：将CPU与GPU同步，在同步完成后面就可以确信核函数已经完成，并且在零拷贝内存中包含了计算好的结果。 零拷贝内存的性能 所有固定内存都存在一定的局限性，零拷贝内存同样不例外：每个固定内存都会占用系统的可用物理内存，这终将降低系统的性能。(只用在使用一次的情况的原因) 使用零拷贝内存通常会带来性能的提升，因为内存在物理上与主机是共存的。将缓冲区声明为零拷贝内存的唯一作用就是避免不必要的数据复制。 当输入内存和输出内存都只是用一次时，那么独立GPU上使用零拷贝内存将带来性能提升。如果多次读取内存，那么最终将得不偿失，还不如一开始将数据复制到GPU。 使用多个GPUNVIDIA一个显卡可能包含多个GPU。例如GeForce GTX 295、Tesla K10。虽然GeForce GTX 295物理上占用一个扩展槽，但在CUDA应用程序看来则是两个独立的GPU。 将多个GPU添加到独立的PCIE槽上，通过NVIDIA的SLI技术将他们桥接。 略。。。 可移动的固定内存—使得多个GPU共享固定内存问题： 固定内存实际上是主机内存，只是该内存页锁定在物理内存中，以防止被换出或重定位。然而这些内存页仅对于单个GPU线程（书上写的是单个CPU线程）来说是“固定的”，如果某个线程分配了固定内存，那么这些内存页只是对于分配它们的线程来说是页锁定的。如果在线程之间共享指向这块内存的指针，那么其他的线程把这块内存视为标准的、可分页的内存。 副作用：当其他线程（不是分配固定内存的线程）试图在这块内存上执行cudaMemcpy()时，将按照标准的可分页内存速率来执行复制操作。这种速率大约为最高传输速度的50%。更糟糕的时，如果线程视图将一个cudaMemcpyAsync()调用放入CUDA流的队列中，那么将失败，因为cudaMemcpyAsync()需要使用固定内存。由于这块内存对于除了分配它线程外的其他线程来说视乎是可分页的，因为这个调用会失败，甚至导致任何后续操作都无法进行。 解决： 可以将固定内存分配为可移动，这意味着可以在主机线程之间移动这块内存，并且每个线程都将其视为固定内存。 使用cudaHostAlloc()来分配内存，并在调用时使用一个新标志：cudaHostAllocPortable这个标志可以与其他标志一起使用，例如cudaHostAllocWriteCombined和cudaHostAllocMapped这意味着分配主机内存时，可以将其作为可移动，零拷贝以及合并写入等的任意组合。","link":"/2019/05/24/cuda/cudanote8/"},{"title":"cudanote6","text":"第九章 原子性 计算功能集、原子操作、计算直方图 GitHub 建议下载下来用Typora软件阅读markdown文件 作者github:littlebearsama 原文链接 (建议下载Typora来浏览markdown文件) 第九章 原子性1.计算功能集 不同架构的CPU有着不同的功能和指令集（例如MMX、SSE(70条指令)、SSE2(使用了144个新增指令)等） 对于支持CUDA的不同图形处理器来说同样如此。NVIDIA将GPU支持的各种功能统称为计算功能集（Compute Capability）。 基于最小功能集的编译 要支持全局内存原子操作，计算功能集的最低版本为1.1 当编译代码时，你需要告诉编译器：如果硬件支持的计算功能集版本低于1.1，那么将无法运行这个核函数。 要将这个信息告诉编译器，只需在调用NVCC时增加一个命令行选项：nvcc -arch=sm_11 当设置的计算能力比硬件本身高比如计算能力是6.1的（1080TI），设置 compute=62，sm=62 会出现错误，kernel不会被执行。 在.cu文件设置自己硬件的计算能力，如果不去设置或者去设置比较低的计算能力，比如设置compute_30,sm_30，那么自然地编译出来的程序的性能就会打折扣。 2.原子操作示例： x++；包含三步操作：a.读取x中的值；b.将步骤1中读到的值增加1；c.将递增后的结果写回到x。 现在考虑线程A和B都需要执行上面三个操作，如果线程调度方式不正确，那么最终将（可能，因为六个步骤也可能会排出正确的结果）得到错误的结果； 解决： 我们需要通过某种方式一次性执行完读取-修改-写入这三个操作，并且在执行过程中不会被其他线程所中断。我们将满足这些条件限制的操作称为原子操作。 CUDA C支持多种原子操作，当有数千个线程在内存访问上发生竞争时，这些操作能够确保在内存上实现安全的操作。 3.计算直方图概念：给定一个包含一组元素的数据集，直方图表示每个元素出现的频率。 在利用cpu实现的程序中，统计函数是： 123//统计 for (int i=0; i&lt;SIZE; i++) histo[buffer[i]]++; 在GPU计算中，计算输入数组的直方图存在一个问题，即多个线程同时对输出直方图的同一个元素进行递增。在这种情况下，我们需要通过原子的递增操作来避免上面提到的问题。 1.GPU代码：123456789101112131415161718192021222324252627//声明变量 unsigned int *dev_histo; HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_histo, 256 * sizeof( int ) ) ); //代码块内的变量一定要手动初始化 HANDLE_ERROR( cudaMemset( dev_histo, 0, 256 * sizeof( int ) ) );...............__global__ void histo_kernel( unsigned char *buffer, long size, unsigned int *histo ) { int i = threadIdx.x + blockIdx.x * blockDim.x; int stride = blockDim.x * gridDim.x; while (i &lt; size) { atomicAdd( &amp;histo[buffer[i]], 1 ); i += stride; }}.............. // kernel launch - 2x the number of mps gave best timing cudaDeviceProp prop; HANDLE_ERROR( cudaGetDeviceProperties( &amp;prop, 0 ) ); int blocks = prop.multiProcessorCount; histo_kernel&lt;&lt;&lt;blocks*2,256&gt;&gt;&gt;( dev_buffer, SIZE, dev_histo ); 这里的atomicAdd就是同时只能有一个线程操作，防止了其他线程的骚操作。 引入了一个新的CUDA运行时函数，cudaMemset()函数，用于内存空间初始化。 由于直方图包含了256个元素，因此可以在每个线程块中包含256个线程 通过一些性能实验，我们发现当线程块的数量为GPU数量的2倍是，将达到最佳性能。 由于核函数中只包含非常少的计算工作，因此很可能是全局内存上的原子操作导致性能的降低，当数千个线程尝试访问少量的内存位置是，将发生大量的竞争。 2.改进版： 使用共享内存和全局内存原子操作的直方图核函数 123456789101112131415161718192021222324252627282930#define SIZE (100*1024*1024)__global__ void histo_kernel( unsigned char *buffer, long size, unsigned int *histo ) { __shared__ unsigned int temp[256];//声明一个共享缓冲区 temp[threadIdx.x] = 0; //将清除内存，每个线程写一次，由于我们在核函数设置启动线程中 //为每个block分配了256个线程，所以很容易清除累计缓冲区temp。 __syncthreads(); int i = threadIdx.x + blockIdx.x * blockDim.x; int stride = blockDim.x * gridDim.x;//因为线程数没有数据多所以要设定步长（步长为分配的线程数目） while (i &lt; size) { atomicAdd( &amp;temp[buffer[i]], 1 ); i += stride; } __syncthreads(); atomicAdd( &amp;(histo[threadIdx.x]), temp[threadIdx.x] );}············· cudaDeviceProp prop; HANDLE_ERROR( cudaGetDeviceProperties( &amp;prop, 0 ) ); int blocks = prop.multiProcessorCount; histo_kernel&lt;&lt;&lt;blocks*2,256&gt;&gt;&gt;( dev_buffer, SIZE, dev_histo ); 在共享内存中计算这些直方图，这将避免每次将写入操作从芯片发送到DRAM，现在只有256个线程在256个地址上发生竞争，这将极大地减少在全局内存中数千个线程之间发生竞争的情况。","link":"/2019/05/24/cuda/cudanote6/"},{"title":"cudanote9","text":"第十二章 后记 CUDA 工具 GitHub 建议下载下来用Typora软件阅读markdown文件 作者github:littlebearsama 原文链接 (建议下载Typora来浏览markdown文件) 第十二章 后记CUDA工具 CUFFT：快速傅立叶变换 CUBLAS：线性代数函数 实例程序：NVIDIA GPU Computing SDK NVIDIA性能原语（NPP）：高性能图像处理或视频应用程序 调试工具NVIDIA Parallel Nsight 其他设备信息Device: &lt;GeForce GTX 1080 Ti&gt; canMapHostMemory: Yes CUDA Capable: SM 6.1 hardware 28 Multiprocessor(s) x 128 (Cores/Multiprocessor) = 3584 (Cores)","link":"/2019/05/24/cuda/cudanote9/"},{"title":"GIT教程2","text":"GIT2—笔记补充123456789101112131415快速创建分支：git branch test切换分支：git checkout test删除分支：git branch -d test修改了很多文件时候，需要commit，通过添加-a来避免每个都commitgit commit -a -m &quot;Changed some files&quot;查看远端：git remote -v移除远端关联：1 git remote rm origin // 移除本地关联2 git remote add origin git@github.com/example.git // 添加线上仓库3 git push -u origin master // 注意：更改后，第一次上传需要指定 origin","link":"/2021/01/16/other/git2/"},{"title":"hexo教程","text":"在两台电脑上面更新hexo博客 hexo基本操作命令 命令https://hexo.io/zh-cn/docs/commands","link":"/2020/07/01/other/hexo/"},{"title":"hexo教程2","text":"在两台电脑上面更新hexo博客 在两台电脑上面更新hexo博客实现思路：hexo d上传部署到github的其实是hexo编译后的文件，用来生成网页的，不包含源文件，上传的是.depoly_git里面的东西。 利用git分支实现，将整个hexo博客文件夹内容push到新建分支（本博客新分支名字为hexosource）。 我们现在将源文件（source、配置文件、主题文件）上传到仓库的新的分支。 步骤： 在GitHub中创建一个私有仓库hexoblog_source，设为私有。 在本地中新建文件夹hexosource，创建一个仓库 12345git initgit add README.mdgit commit -m &quot;first commit&quot;git remote add origin git@github.com:littlebearsama/hexoblog_source.gitgit push -u origin master 创建一个新的分支xiaoxiong $ git checkout -b xiaoxiong 将hexo的文件夹整个复制过来，将所有文件添加到暂存区 git add littlebear_hexoblog/ git ls-files 显示暂存区内容 git commit -m “add littlebear_hexoblog” git push –set-upstream origin xiaoxiong 在github的xxx.github.io仓库上新建一个hexo分支，并切换到改分支，并在仓库–&gt;setting—&gt;Branches—&gt;Default中将默认分支设为hexo（之前默认分支为master）,update保存。 这样每次同步的时候就不用指定分支，比较方便。 新建hexosource分支 git checkout -b hexosource 使用git branch 可以看到当前已经在hexosource分支上 git checkout hexosource 文件夹下面的内容全部添加到 q 手贱将GitHub Page仓库转成私有 将github静态博客网站转成私有后不能访问，再转回公有后还是不能访问。 解决： 随便·改一下gitpage仓库的名字，rename，保存。这样静态博客仓库名字就变了。 如原本是AAA.github.io改成了BBB.github.io 将仓库名字再改回来，AAA.github.io，并且将仓库改成公有。 改了一些源文件（不知道是否起作用） hexo g （不知道是否起作用） hexo d（不知道是否起作用）","link":"/2020/07/19/other/hexo2/"},{"title":"好用的工具","text":"listary：快速检索 石墨文档：大家一起写文档，简单好用 imageJ图像查看工具 vs插件imagewatch，debug时候可以查看图像","link":"/2019/06/12/other/nicetools/"},{"title":"ObjectDetection and PoseEstimation","text":"物体检测与位姿估计 针对刚性物体识别与位姿估计的方法主要分为三类： 基于模板匹配 基于三维局部特征 基于学习 下面来细讲： 资料整理 0.相关 网站：Detection and 6D Pose Estimation里面收录了很多文章和方法 没趣啊知乎：meiqua知乎 石头哥的目标检测(深度学习)笔记 stone 综述： 2017 在“Recovering 6D Object Pose: Multi-modal Analyses on Challenges”中：2018 在“BOP: Benchmark for 6D Object Pose Estimation”中：对各种方法进行了估计还有测试。2019 在“RGB-D image-based Object Detection: from Traditional Methods to Deep Learning Techniques”中：从传统识别方法到深度学习技术 1.基于模板匹配(template matching)基于模板匹配的6D目标位姿估计方法的研究始于20世纪90年代的单目图像。 以不同视点下目标对象的整体外观作为模型模板， A.2D基于线条特征[^3]、边缘轮廓[^4]、冲击图形和曲线[^5]进行模型与输入的匹配。 可用的开源项目： shape_based_matching edge_based_matching ShapeMatch LINE2D OpenSSE B.2.5D在增加了深度信息后，使得6D目标位姿估计对背景杂波具有更强的鲁棒性。针对机器人应用提出了快速、鲁棒的RGB-D特性， 如VFH[6]和CVFH[7]。stoisser等[8,9]提出了以图像梯度离散化方向和表面法线为特征的linemod方法。相似度得分在预先计算的响应图上快速计算出来，他们表明它比现有的方法在杂乱的背景下更健壮，也更快。 开源项目linemod(opencv和PCL中均有接口)： 6DPose PCL提供两个类LINEMOD和lineRGBD 2.基于三维局部特征(3D local features)在基于三维局部特征的方法中，六自由度位姿是根据局部特征的对应关系或Hough投票中恢复出来的。 早期提出了二维图像中提取的线条特征[^10]、边缘特征[^11]等多种局部特征。为了进行更稳健的估计，还提出了利用深度信息的局部描述符，如自旋图像[^12]和SHOT[^13]。 点对特性(PPF)[^14]是迄今为止最为成功和著名的三维局部描述符，并且已经提出了许多扩展版本。例如，选择边界或线[^15]点，计算分割点云[^16]上的PPF，改进点采样和投票[^17]。然而，与基于模板的方法相比，在6D位姿空间中进行模式搜索速度较慢。 （论文BOP: Benchmark for 6D Object Pose Estimation 中对15种方法进行了评估，得出结论是PPF表现最好，优于模板匹配方法（templates matching），基于学习（learning-based）的方法和基于3D local features的方法） 1.基于点云三维局部特征的方法3D local features一般点云物体识别的流程是： 提取关键点（keypoints）。比如iss关键点，sift关键点。它们的数据形式是三维向量XYZ+其他信息 利用关键点keypoints作为种子计算特征描述子descriptors。比如3DSC描述子，LSP描述子。它们的数据形式是多维向量比如PFH的长度是125，SI的长度是225。 匹配：实际上是通过特征描述子（descriptors）进行对应点（correspondence）估计。如SAC-IA算法。 匹配后再通过一些点云的配准（registration）方法比如迭代最近点（ICP）进行精确配准。 假设验证 使用PCL中的方法： 3D_object_recognition_(pipeline) 2.PPF vote-based pose estimation.（基于投票的位姿估计）典型方法：PPF OPENCV和PCL中均有接口 hough transform霍夫变换 hough random forests霍夫随机森林 3.基于学习(learning-based)在基于学习的方法中，出现了很多利用机器学习技术提取识别特征，训练识别前景/背景、对象类和三维对象姿态的分类器。例如，学习模板匹配[^18]或投票[^19]的权重，学习潜在类分布[^20]和学习霍夫森林进行坐标回归[^21]。近年来，CNN被引入学习三维物体姿态[^22]的流形。提出了基于卷积自动编码器[^23]和自监督增强自动编码器[^24]的流形学习方法。Kehl等人提出了类似ssd的CNN架构，用于估计对象的二维位置、类和三维位姿。利用基于CNN的检测器检测三维控制点或包围盒角的投影二维点，而不是估计三维位姿类[^25,26,27]。虽然最近的基于CNN的方法与其他两种方法相比，对背景杂波和局部遮挡的鲁棒性更高，但是它们的训练需要大量的带注释的训练样本，并且在GPU上花费更长的时间。 0.基于机器学习： 2012 6D pose estimation of textureless shiny objects using random ferns for bin-picking(随机蕨) 2014 Latent-Class Hough Forests for 3D Object Detection and Pose Estimation of Rigid Objects（LCFH） 2016 (有源码) 基于霍夫森林 Recovering 6D Object Pose and Predicting Next-Best-View in the Crowd 2016 Deep learning of local RGB-D patches for 3D object detection and 6D pose estimation 2016 Recovering 6D Object Pose and Predicting Next-Best-View in the Crowd （pixel difference+random forest） 2017 (必读)Pose Guided RGBD Feature Learning for 3D Object Pose Estimation 2017 Feature Mapping for Learning Fast and Accurate 3D Pose Inference 2017 On Pre-Trained Image Features and Synthetic Images for Deep Learning 2017 RGB-D Object Recognition and Grasp Detection Eric Brachmann 1.基于深度学习：a.基于2D投影的深度学习网络多视图处理神经网络在处理3D图像的分割和分类任务中的中心思想是：用多张不同角度2D图像的表面特征，直接处理相应的2D图片信息从而进行3D物体识别和探测，这样就可以直接利用二维图像上成熟的CNN技术。 代表方法：MVCNN，Snapnet，DeePr3SS 缺点：容易受到物体之间互相遮挡损失一些表面信息，投影变换过程 b.基于三维数据立体栅格化把原始点云转换为立体网格（vexel）然后采用改进的三维卷积神经网络进行处理。 代表方法：3D-CNN，VAE，VoxNet 缺点：需要转化为体素模型，设置不同的立体网格分辨率能不同程度的保留原始场景的细节信息，这个转换需要消耗大量的计算资源和时间，而且难以处理较复杂结构的大场景对象物体。 c.基于点的神经网络框架（point-based技术） 直接处理输入的点云数据，通过构建网络模型提取场景点云的三维空间结构特征。 有效处理大规模非结构化并且无序的点云数据，从中提取出各类地物目标信息 通过大量标记点云数据样本的训练得到具有更高精度的语义分割模型 代表方法：PointNet，PointNet++，PointCNN，PointSIFT，Superpoint Graph 2.3D-Machine-Learning3D-Machine-Learning Datasets 3D Pose Estimation Courses Single Object Classification Multiple Objects Detection Scene/Object Semantic Segmentation 3D Geometry Synthesis/Reconstruction Texture/Material Analysis and Synthesis Style Learning and Transfer Scene Synthesis/Reconstruction Scene Understanding 3.A Tutorial on 3D Deep LearningA Tutorial on 3D Deep Learning 4.3D Convolutional Neural Networks — A Reading List3D Convolutional Neural Networks — A Reading List （完）","link":"/2019/07/28/6DPose/ObjectDetection-and-PoseEstimation/"},{"title":"编程知识与VS错误","text":"[TOC] 1. 预编译头（提高编译速度）参考 #include “stdafx.h” 首先#include语句的作用是将对应名称的头文件的所有内容粘贴到include所在的文件中。如果头文件内容很多就会非常耗时。 所以如果重复include多个头文件，会造成多次代码的粘贴，对于头文件中有类声明等，会造成重定义。 预编译头就是把一个工程中的那一部分代码预先编译好放在一个文件里(通常是以.pch为扩展名的)，这个文件就称为预编译头文件。 预先编译好的代码可以是任何的C/C++代码——–甚至是inline的函数，但是必须是稳定的，在工程开发的过程中不会被经常改变。如果这些代码被修改，则需要重新编译生成预编译头文件。 Stdafx.h文件需要配合一个StdAfx.cpp文件来使用 使用了预编译头技术后，编译速度大大提高了。可以到你的工程目录下的Debug 或 Release 目录中看一看，里面有一个体积极为硕大的 .pch 文件，那就是“编译之后的预编译头”。 如果你使用了预编译头技术，就必须在所有的 cpp 中包含预编译头。MFC 工程中为你建立了一个默认的预编译头 stdafx.h，如果你愿意，也可以在自己的工程中使用其它文件名作为你的预编译头，如果你觉得有必要。 使用预编译头 在属性表中 设置C/C++—–&gt;预编译头—-&gt;使用（/Yu）—-&gt;预编译头文件stdafx.h 右键stdafx.cpp文件属性—&gt;预编译头—-&gt;创建（/Yc） 在每个cpp文件中加入预编译头文件stdafx.h 2. #pragma once 与 ifndef参考1 参考2 目的：为了避免同一个文件被include多次 同一个文件被include多次的危害： （1）防止重复定义的错误； （2）如果这个头文件变化，那么所有include这个文件的源文件都需要重新编译，即使没有去使用里面的任何内容 避免措施： （1）头文件加#pragma once （2）头文件加#ifndef 宏名 #define 宏名 #endif 12345678方式一：#ifndef __SOMEFILE_H__#define __SOMEFILE_H__... ... // 一些声明语句#endif方式二：#pragma once... ... // 一些声明语句 两者区别： #ifndef的方式依赖于宏名字不能冲突，这不光可以保证同一个文件不会被包含多次，也能保证内容完全相同的两个文件不会被不小心同时包含。当然，缺点就是如果不同头文件的宏名不小心“撞车”，可能就会导致头文件明明存在，不同文件相同宏名会使得编译器出现找不到声明的状况。 #pragma once则由编译器提供保证：同一个文件不会被包含多次。注意这里所说的“同一个文件”是指物理上的一个文件，而不是指内容相同的两个文件。带来的好处是，你不必再费劲想个宏名了，当然也就不会出现宏名碰撞引发的奇怪问题。对应的缺点就是如果某个头文件有多份拷贝，本方法不能保证他们不被重复包含。当然，相比宏名碰撞引发的“找不到声明”的问题，重复包含更容易被发现并修正。 3. VS由于无法找到 dll，无法继续执行代码C++在VS下创建、调用dll 如何在C++程序中调用dll文件 windows下C++项目引用其他项目 显式链接 显式链接是应用程序在执行过程中随时可以加载DLL文件，也可以随时卸载DLL文件，这是隐式链接所无法作到的，所以显式链接具有更好的灵活性，对于解释性语言更为合适。 新建项目，不需要特殊配置，添加cpp文件 隐式链接 隐式链接采用静态加载的方式，比较简单，需要.h、.lib、.dll三件套。新建“控制台应用程序”或“空项目”。配置如下: 项目-&gt;属性-&gt;配置属性-&gt;VC++ 目录-&gt; 在“包含目录”里添加头文件testdll.h所在的目录 项目-&gt;属性-&gt;配置属性-&gt;VC++ 目录-&gt; 在“库目录”里添加头文件testdll.lib所在的目录 项目-&gt;属性-&gt;配置属性-&gt;链接器-&gt;输入-&gt; 在“附加依赖项”里添加“testdll.lib”（若有多个 lib 则以空格隔开） 现在可以编译通过了，但是程序运行就报错，还需要将testdll.dll复制到当前项目生成的可执行文件所在的目录。 4. 内联的虚成员函数参考 内联虚成员函数：inline virtual void fun(int a);？ 函数的inline属性是在编译时确定的， 然而，virtual的性质是在运行时确定的，这两个不能同时存在，只能有一个选择，文件中的inline关键字只是对编译器的建议，编译器是否采纳是编译器的事情。 5.__declspec( dllexport )的作用参考 在工程开发中，我们往往需要将某个工程做成dll动态链接库的形式释放出去；但在工程初期，为方便调试，一般生成的是exe文件；在确认功能开发完毕后，再将其封装成dll文件进行释放。那么，当我们想要将原先是生成exe文件的vs工程，转换为生成dll文件的话；需执行的步骤如下（以vs2013为例）： 将工程的配置类型配置为dll 1项目-&gt;属性-&gt;配置属性-&gt;常规-&gt;配置类型-&gt;动态库(.dll) 将要释放的接口函数以如下格式进行声明 1_declspec(dllexport) 函数首; list.h 1234567struct ListNode{ int m_nValue; ListNode* m_pNext;};__declspec( dllexport ) ListNode* CreateListNode(int value); list.cpp 12345678910111213#include&lt;iostream&gt;#include \"include/List.h\"using namespace std;// 创建链表节点ListNode* CreateListNode(int value) { ListNode* pNode = new ListNode(); pNode-&gt;m_nValue = value; pNode-&gt;m_pNext = nullptr; return pNode;} __declspec( dllexport )的作用为不用导入库文件，就可以在外部直接调用其后的函数功能。 例如：加入建一个test.cpp文件，导入list.h后可以直接调用其函数 调用如下 12345678910111213141516171819#include &lt;stdio.h&gt;#include &lt;windows.h&gt;void main(void){ typedef int(*MyFunDll)(void); HMODULE hdll = LoadLibrary(\"Win32Project1.dll\"); //加载dll文件 if (hdll != NULL) { MyFunDll MyFunCall = (MyFunDll)GetProcAddress(hdll, \"main\");//检索要调用函数的地址 if (MyFunCall != NULL) { MyFunCall(); //调用接口函数 } } FreeLibrary(hdll); //释放dll文件} 通过LoadLibrary()函数对dll文件进行加载；再通过GetProcAddress()函数去获取要调用的接口函数的地址（上例中用MyFunCall去存储接口函数的地址）；再调用该接口函数(MyFunCall)；最后通过FreeLibrary()函数对dll文件进行释放。所以，如果要用于加载其他的dll文件，上例中需改动的地方有： 加载的dll文件名(上例中的”Win32Project1.dll”)； 要检索的接口函数名(上例中的”main”)； 调用的接口函数的格式(如上例中的MyFunCall()，函数的参数信息应保持与要调用的接口函数”main”一致)。","link":"/2020/07/05/Coding/coding1/"},{"title":"Neural Networks and Deep Learning Notes","text":"神经网络与深度学习（Neural Networks and Deep Learning）读书笔记 深度学习框架TensorFlow （主流）；Keras； Caffe；PyTorch （上升很快）；Theano ；MXNet ；Chainer ；CNTK 第一章：基本概念1. 感知器（perceptron）/也叫神经元零基础入门深度学习(1) - 感知器 感知器不仅仅能实现简单的布尔运算。它可以拟合任何的线性函数，任何线性分类或线性回归问题都可以用感知器来解决。前面的布尔运算可以看作是二分类问题，即给定一个输入，输出0（属于分类0）或1（属于分类1）。 感知器训练算法：将权重项和偏置项初始化为0，然后，利用下面的感知器规则迭代的修改权重和偏置，直到训练完成。（另外一种说法：设计学习算法，能够自动调整人工神经元的权重和偏置）。 2. S型神经元（sigmoid）零基础入门深度学习(2) - 线性单元和梯度下降 激活函数理解神经网络的激活函数 简单理解：简单来说，人工神经元计算输入的“加权和”，加上偏置(总的偏置) = Y，接着决定是否需要“激活”（好吧，其实是激活函数决定是否激活，但是现在让我们先这样理解吧）。 几种激活函数：将Y输入激活函数，获得输出 阶跃函数 当值大于0（阈值）时，输出为1（激活），否则输出为0（不激活）。 只能输出是或者否 因为我们希望输出中间（模拟）激活值，而不是仅仅输出“激活”或“不激活”（二元值）。 线性函数 线性激活函数将给出一定范围内的激活，而不是二元激活。我们当然可以连接若干神经元，如果不止一个神经元激活了，我们可以基于最大值（max或softmax）做决定。 问题： 线性函数的导数是个常数。常数怎么训练？不管我们有多少层，如果这些层的激活函数都是线性的，最后一层的最终激活函数将是第一层的输入的线性函数！这将使得我们找不到目标函数的迭代方向。 我们需要非线性的激活函数！ sigmoid function 阶跃函数平滑后的版本，它是非线性的。这意味着该函数的组合也是非线性的。它将给出模拟激活，而不是0或1，它趋向于将激活导向曲线的两边。这在预测上形成了清晰的差别。 问题： 越是接近sigmoid的两端，相对X的改变，Y就越趋向于作出非常小的反应。这意味着在该区域的梯度会很小。也就是“衰减的梯度”问题 。网络拒绝进一步学习，或者学习速度剧烈地变慢了（取决于具体案例，直到梯度/计算碰到了浮点值的限制）。不过，我们有一些变通措施，因此在分类问题中，sigmoid仍旧非常流行。 tanh function 这是一个经过拉升的sigmoid函数。tanh的性质和我们之前讨论的sigmoid类似。它是非线性的，因此我们可以堆叠网络层。它是有界的(-1, 1)，所以不用担心激活膨胀。值得一提的是，tanh的梯度比sigmoid更激烈（导数更陡峭）。因此，选择sigmoid还是tanh将取决于你对梯度强度的需求。和sigmoid类似，tanh也存在梯度衰减问题。 ReLU 修正线性单元： 乍看起来这和线性函数有一样的问题，因为在正值处它是线性的。首先，RuLu是非线性的。ReLu的组合也是非线性的！（实际上它是一个很好的逼近子。ReLu的组合可以逼近任何函数。）很好，这意味着我们可以堆叠网络层。不过，它并不是有界的。ReLu的值域是[0, inf)。这意味着它将膨胀激活函数。 ReLu的水平线部分（X的负值）意味着梯度会趋向于0。当激活位于ReLu的水平区域时，梯度会是0，导致权重无法随着梯度而调整。这意味着，陷入此状态的神经元将停止对误差/输入作出反应（很简单，因为梯度是0，没有什么改变）。这被称为死亡ReLu问题。这一问题会导致一些神经元直接死亡、失去响应，导致网络的很大一部分进入被动状态。有一些缓和这一问题的ReLu变体，将水平线转为非水平部分，例如，当x&lt;0时y = 0.01x，使图像从水平线变为略微倾斜的直线。这就是弱修正ReLu（leaky ReLu）。还有其他一些变体。主要的想法是让梯度不为零，这样网络可以逐渐从训练中恢复。 相比tanh和sigmoid，ReLu在算力上更经济，因为它使用的是比较简单的数学运算。 该选哪个？ 当我们知道尝试逼近的函数具有某些特定性质时，我们可以选择能够更快逼近函数的激活函数，从而加快训练过程。例如，sigmoid对分类器而言很有效（看看sigmoid的图像，是不是展示了一个理想的分类器的性质？），因为基于sigmoid的组合逼近的分类函数要比诸如ReLu之类的函数更容易。 如果你并不清楚试图学习的函数的本质，那我会建议你从ReLu开始，然后再试其他。在大多数情况下，ReLu作为一个通用的逼近子效果很不错。 3. 神经网络架构零基础入门深度学习(3) - 神经网络和反向传播算法 神经网络其实就是按照一定规则连接起来的多个神经元。上图展示了一个全连接(full connected, FC)神经网络，通过观察上面的图，我们可以发现它的规则包括： 神经元按照层来布局。最左边的层叫做输入层，负责接收输入数据；最右边的层叫输出层，我们可以从这层获取神经网络输出数据。输入层和输出层之间的层叫做隐藏层，因为它们对于外部来说是不可见的。 同一层的神经元之间没有连接。 第N层的每个神经元和第N-1层的所有神经元相连(这就是full connected的含义)，第N-1层神经元的输出就是第N层神经元的输入。 每个连接都有一个权值。 4. 使用梯度下降法进行学习神经网络学习算法：用来计算目标函数找到合适的权重和偏置，使得目标函数的数值≈0 动量随机梯度下降法（SGD） RMSprop算法 Adam算法（自适应矩估计） 遗传算法 随机梯度下降算法(Stochastic Gradient Descent, SGD) 要遍历训练数据中所有的样本进行计算，我们称这种算法叫做批梯度下降(Batch Gradient Descent) 实用的算法是SGD算法。在SGD算法中，每次更新w的迭代，只计算一个样本。这样对于一个具有数百万样本的训练数据，完成一次遍历就会对w更新数百万次，虽然存在一定随机性，大量的更新总体上沿着减少目标函数值的方向前进的，因此最后也能收敛到最小值附近。 SGD不仅仅效率高，而且随机性有时候反而是好事。今天的目标函数是一个『凸函数』，沿着梯度反方向就能找到全局唯一的最小值。然而对于非凸函数来说，存在许多局部最小值。随机性有助于我们逃离某些很糟糕的局部最小值，从而获得一个更好的模型。 第二章：反向传播算法如何工作反向传播算法：一种快速计算代价函数的梯度的方法 第三章：改进神经网络的学习方法3.1 交叉熵代价函数二次代价函数改成交叉熵代价函数（神经元在犯错误时学习得更快） 我们大多数情况会使用交叉熵代价函数来解决学习缓慢的问题，但是还有一种方法：基于柔性最大值（softmax）神经元 3.2 过拟合和规范化防止过拟合： 使用验证集来代替测试机防止过拟合问题 增加训练样本数量 规范化：又称权重衰减或者L2规范化 即对代价函数进行规范化，交叉熵代价函数进行L2规范化。 局部相应规范化（Local Responsible Normalization, LRN）： 使用LRN对局部的特征进行归一化，结果作为ReLU激活函数的输入能有效降低错误率。 弃权（drop out） 选择性地忽略训练中的单个神经元，避免模型的过拟合 认为扩展训练数据 3.3 权重初始化 之前的方式就是根据独立高斯随机变量来选择权重和偏置。 使用归一化的高斯分布做得更好。 3.5 如何选择神经网络的超参数超参数：开始学习之前设置的参数 参考 3.6 其他技术第四章：神经网络可以计算任何函数的可视化证明4.1 两个预先声明4.2 一个输出和一个输入的普遍性4.3 多个输入变量4.4 S型神经元的延申4.5 修补阶跃函数第五章：深度神经网络为何很难训练5.1 梯度消失问题5.2 什么导致消失的梯度问题？神经网络中的梯度不稳定性5.3 在更加复杂网络中的不稳定梯度5.4 其它深度学习的障碍第六章：深度学习1. 介绍卷积网络零基础入门深度学习(4) - 卷积神经网络 零基础入门深度学习(5) - 循环神经网络 零基础入门深度学习(6) - 长短时记忆网络(LSTM) 零基础入门深度学习(7) - 递归神经网络 2. 卷积网络在实际中的应用神经网络各层分析卷积神经网络各层分析 1.卷积Convolution2.池化PoolingPooling层主要的作用是下采样，通过去掉Feature Map中不重要的样本，进一步减少参数数量。 Pooling的方法很多，最常用的是Max Pooling。Max Pooling实际上就是在n*n的样本中取最大值，作为采样后的样本值。下图是2*2 max pooling： 3.全连接Full Connection","link":"/2019/07/30/MAD_Learning/DeepLearningNotes/"},{"title":"glfw显示点云","text":"一个简单的glfw显示点云的例程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290#include &lt;functional&gt;#include &lt;memory&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;GL/glew.h&gt;#include &lt;GLFW/glfw3.h&gt;#include &lt;glm/glm.hpp&gt;#include &lt;glm/gtc/matrix_transform.hpp&gt;#include &lt;glm/gtx/transform.hpp&gt;#include \"src/glslUtility.hpp\"#ifndef PI#define PI 3.141592654#endifusing namespace std;//要实现设置显示点的数量static int N=100000;static int N2;GLFWwindow *window = nullptr;// For camera controlsstatic bool leftMousePressed = false;static bool rightMousePressed = false;static bool middleMousePressed = false;GLuint positionLocation = 0; // Match results from glslUtility::createProgram.GLuint velocitiesLocation = 1; // Also see attribtueLocations below.GLuint pointVAO = 0;//所有需要画的粒子都绑定在上面GLuint pointVBO_positions = 0;GLuint pointVBO_velocities = 0;GLuint pointIBO = 0;//indexsGLuint displayImage;GLuint program[2];const unsigned int PROG_POINT = 0;//const float fovy = (float)(PI / 4);const float zNear = 0.10f;const float zFar = 10.0f;//窗口相关std::string windowName = std::string(\"GLvisualizationWin\");int width = 1280;int height = 720;int pointSize = 2;bool BreakLoop = false;double lastX;double lastY;float theta = 1.22f;float phi = -0.70f;float zoom = 4.0f;glm::vec3 lookAt = glm::vec3(0.0f, 0.0f, 0.0f);glm::vec3 cameraPosition;glm::mat4 projection;//外部输入数据int numObjects_fixed = 1000;int numObjects_rotated = 1000;int blockSize = 128;//被init()调用void errorCallback(int error, const char *description);void keyCallback(GLFWwindow* window, int key, int scancode, int action, int mods);//键盘响应void mouseButtonCallback(GLFWwindow* window, int button, int action, int mods);//鼠标按键响应void mousePositionCallback(GLFWwindow* window, double xpos, double ypos);//鼠标位置响应void updateCamera();void initShaders(GLuint *program);void endrun();void initVAO(){ std::unique_ptr&lt;GLfloat[]&gt; bodies{ new GLfloat[4 * N] };//数据 std::unique_ptr&lt;GLfloat[]&gt; rgbs{ new GLfloat[4 * N] };//数据 std::unique_ptr&lt;GLuint[]&gt; bindices{ new GLuint[N] };//索引 glm::vec4 ul(-1.0, -1.0, 1.0, 1.0); glm::vec4 lr(1.0, 1.0, 0.0, 0.0); for (int i = 0; i &lt; N; i++) { float x = float(rand()) / 9.99f; x = x - (int)x; float y = float(rand()) / 9.99f; y = y - (int)y; float z = float(rand()) / 9.99f; z = z - (int)z; bodies[4 * i + 0] = x; bodies[4 * i + 1] = y; bodies[4 * i + 2] = z; bodies[4 * i + 3] = 1.0f; rgbs[4 * i + 0] = 1; rgbs[4 * i + 1] = 0; rgbs[4 * i + 2] = 0; rgbs[4 * i + 3] = 1.0f; bindices[i] = i; } //创建VAO 把所有需要画粒子的东西都粘在上面 glGenVertexArrays(1, &amp;pointVAO); // Attach everything needed to draw a particle to this glGenBuffers(1, &amp;pointVBO_positions);//该函数用来生成缓冲区对象的名称，第一个参数是要生成的缓冲区对象的数量，第二个是要用来存储缓冲对象名称的数组 glGenBuffers(1, &amp;pointVBO_velocities); glGenBuffers(1, &amp;pointIBO);//生成索引缓存区的名字 glBindVertexArray(pointVAO);//绑定一个顶点数组对象 // Bind the positions array to the pointVAO by way of the pointVBO_positions glBindBuffer(GL_ARRAY_BUFFER, pointVBO_positions); // bind the buffer pointVBO_positions变成了一个顶点缓冲类型 glBufferData(GL_ARRAY_BUFFER, 4 * N * sizeof(GLfloat), bodies.get(), GL_DYNAMIC_DRAW); // transfer data，创建和初始化一个buffer object的数据存储。 glEnableVertexAttribArray(positionLocation); glVertexAttribPointer((GLuint)positionLocation, 4, GL_FLOAT, GL_FALSE, 0, 0); // Bind the velocities array to the pointVAO by way of the pointVBO_velocities glBindBuffer(GL_ARRAY_BUFFER, pointVBO_velocities); glBufferData(GL_ARRAY_BUFFER, 4 * N * sizeof(GLfloat), rgbs.get(), GL_DYNAMIC_DRAW); glEnableVertexAttribArray(velocitiesLocation); glVertexAttribPointer((GLuint)velocitiesLocation, 4, GL_FLOAT, GL_FALSE, 0, 0); //给索引数据也绑定buffer glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, pointIBO); glBufferData(GL_ELEMENT_ARRAY_BUFFER, N * sizeof(GLuint), bindices.get(), GL_STATIC_DRAW); glBindVertexArray(0);}void testGLFW(){ //初始化前设置错误回调函数 glfwSetErrorCallback(errorCallback); //调用glfwInit函数，初始化glfw，在程序终止之前，必须终止glfw，这个函数只能在主线程上被调用 if (!glfwInit()) { std::cout &lt;&lt; \"Error: Could not initialize GLFW!\" &lt;&lt; \" Perhaps OpenGL 3.3 isn't available?\" &lt;&lt; std::endl; return ; } //在创建窗口之前调用glfwWindowHint，设置一些窗口的信息 //这些hints，设置以后将会保持不变，只能由glfwWindowHint、glfwDefaultWindowHints或者glfwTerminate修改。 glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //如果创建window失败则终结glfw，指定尺寸 //(int width, int height, const char* title, GLFWmonitor* monitor, GLFWwidnow* share); window = glfwCreateWindow(width, height, windowName.c_str(), NULL, NULL); if (!window) { std::cout &lt;&lt; \"Failed to create GLFW window\" &lt;&lt; std::endl; glfwTerminate();//glfwTerminate会销毁窗口释放资源，因此在调用该函数后，如果想使用glfw库函数，就必须重新初始化 return ; } // glfwMakeContextCurrent(window); glfwSetKeyCallback(window, keyCallback); glfwSetCursorPosCallback(window, mousePositionCallback); glfwSetMouseButtonCallback(window, mouseButtonCallback); glewExperimental = GL_TRUE; if (glewInit() != GLEW_OK) { std::cout &lt;&lt; \"Failed to initialize GLEW\" &lt;&lt; std::endl; return ; } // 初始化绘图状态 initVAO(); //互操作 //cudaGLSetGLDevice(0);//设置CUDA环境 ////用cuda登记缓冲区，该命令告诉OpenGL和CUDA 驱动程序该缓冲区为二者共同使用。 //cudaGLRegisterBufferObject(pointVBO_positions);//pointVBO_positions=0 //cudaGLRegisterBufferObject(pointVBO_velocities);//pointVBO_velocities=0 updateCamera(); initShaders(program); glEnable(GL_DEPTH_TEST); double fps = 0; double timebase = 0; int frame = 0; //返回指定窗口是否关闭的flag变量，可以在任何线程中被调用。 while (!glfwWindowShouldClose(window) &amp;&amp; !BreakLoop) { //这个函数主要用来处理已经在事件队列中的事件，通常处理窗口的回调事件，包括输入，窗口的移动，窗口大小的改变等， //回调函数可以自己手动设置，比如之前所写的设置窗口大小的回调函数；如果没有该函数，则不会调用回调函数，同时也不会接收用户输入，例如接下来介绍的按键交互就不会被响应； glfwPollEvents(); frame++; double time = glfwGetTime();//当前时间 if (time - timebase &gt; 1.0) { fps = frame / (time - timebase); timebase = time; frame = 0; } //runcuda();//更新点云 glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glUseProgram(program[PROG_POINT]); glBindVertexArray(pointVAO); glPointSize((GLfloat)pointSize); glDrawElements(GL_POINTS, N + N2 + 1, GL_UNSIGNED_INT, 0); glPointSize(1.0f); glUseProgram(0); glBindVertexArray(0); glfwSwapBuffers(window);//opengl采用双缓冲机制，该函数用于交换前后颜色缓冲区的内容 } endrun(); return ;}void endrun(){ glfwDestroyWindow(window); glfwTerminate();}void initShaders(GLuint *program){ GLint location; const char *vertexShaderPath = \"shaders/boid.vert.glsl\"; const char *geometryShaderPath = \"shaders/boid.geom.glsl\"; const char *fragmentShaderPath = \"shaders/boid.frag.glsl\"; const char *attributeLocations[] = { \"Position\", \"Velocity\" }; program[PROG_POINT] = glslUtility::createProgram(vertexShaderPath, geometryShaderPath, fragmentShaderPath, attributeLocations, GLuint(2)); glUseProgram(program[PROG_POINT]); if ((location = glGetUniformLocation(program[PROG_POINT], \"u_projMatrix\")) != -1) { glUniformMatrix4fv(location, 1, GL_FALSE, &amp;projection[0][0]); } if ((location = glGetUniformLocation(program[PROG_POINT], \"u_cameraPos\")) != -1) { glUniform3fv(location, 1, &amp;cameraPosition[0]); }}void errorCallback(int error, const char *description){ fprintf(stderr, \"error %d: %s\\n\", error, description);}void keyCallback(GLFWwindow* window, int key, int scancode, int action, int mods){ if (key == GLFW_KEY_ESCAPE &amp;&amp; action == GLFW_PRESS) { glfwSetWindowShouldClose(window, GL_TRUE); }}void mouseButtonCallback(GLFWwindow* window, int button, int action, int mods){ leftMousePressed = (button == GLFW_MOUSE_BUTTON_LEFT &amp;&amp; action == GLFW_PRESS); rightMousePressed = (button == GLFW_MOUSE_BUTTON_RIGHT &amp;&amp; action == GLFW_PRESS); middleMousePressed = (button == GLFW_MOUSE_BUTTON_MIDDLE &amp;&amp; action == GLFW_PRESS);}void mousePositionCallback(GLFWwindow* window, double xpos, double ypos){ if (leftMousePressed) { // compute new camera parameters phi += (xpos - lastX) / width; theta -= (ypos - lastY) / height; theta = std::fmax(0.01f, std::fmin(theta, 3.14f)); updateCamera(); } else if (rightMousePressed) { zoom += (ypos - lastY) / height; zoom = std::fmax(0.1f, std::fmin(zoom, 5.0f)); updateCamera(); } else if (middleMousePressed){ glm::vec3 forward = -glm::normalize(cameraPosition); forward.y = 0.0f; forward = glm::normalize(forward); glm::vec3 right = glm::cross(forward, glm::vec3(0, 1, 0)); right.y = 0.0f; right = glm::normalize(right); lookAt -= (float)(xpos - lastX) * right * 0.01f; lookAt += (float)(ypos - lastY) * forward * 0.01f; updateCamera(); } lastX = xpos; lastY = ypos;}void updateCamera(){ cameraPosition.x = zoom * sin(phi) * sin(theta); cameraPosition.z = zoom * cos(theta); cameraPosition.y = zoom * cos(phi) * sin(theta); cameraPosition += lookAt; cout &lt;&lt; lookAt.x &lt;&lt; \", \" &lt;&lt; lookAt.y &lt;&lt; \", \" &lt;&lt; lookAt.z &lt;&lt; \",\" &lt;&lt; endl; projection = glm::perspective(fovy, float(width) / float(height), zNear, zFar); glm::mat4 view = glm::lookAt(cameraPosition, lookAt, glm::vec3(0, 0, 1)); projection = projection * view; GLint location; glUseProgram(program[PROG_POINT]); if ((location = glGetUniformLocation(program[PROG_POINT], \"u_projMatrix\")) != -1) { glUniformMatrix4fv(location, 1, GL_FALSE, &amp;projection[0][0]); }}","link":"/2021/04/03/OPENGL/OpenGLSample/"},{"title":"pcl samples","text":"目的：本文简要介绍pcl源码自带例程里的项目的主要功能。 编译PCL源码之后，有一些PCL.sln里面包含所有自带的apps、samples和tools，下面来一一介绍，本文使用的是pcl1.8.1版本的pcl源码。 A.apps1.3d_rec_framework三维重建框架 pineline global_nn_classifier global_nn_recognizer_crh global_nn_recognizer_cvfh local_recognizer tools openni_frame_source apps global_classification local_recognition_mian_dataset 2.cloud_composer点云编辑器：处理，可视化，投影模型，变换点云，计算特征。 点云编辑器的工具 3.in_hand_scanner正如其名：手持扫描仪项目，里面有icp有，可视化置信度，有输入数据处理。 4.modeler 5.optronic_viewer可视化工具：openni+qt 6.point_cloud_editor点云编辑器：估计和composer差不多 7.face_detection点云人脸识别 8.manual_registrationpcl_manual_registration 配准加UI界面 9.pcd_video_playerpcd_video_player pcd播放器加UI界面 10.openni 凸包边缘计算 边缘估计 改变视角 基于颜色滤波 快速网格化 特征。。。 抓取帧 抓取图像 ii法线估计 klt 移动最小二乘法平滑 octree压缩 有序压缩 有序(点云边缘检测) 多平面分割 直通滤波 平面边缘检测 平面分割 shift_to_depth_conversion 相机跟踪 统一滤波 网格滤波 11.others convolve.cpp dinast_grabber_example multiscale_feature_persistence_example surfel_smoothing_test 曲面平滑 NI(关键点和描述符) ni_agast agast关键点 ni_brisk brisk特征描述符 ni_susan susan特征点检测 ni_trajkovic trajkovic关键点 识别匹配 ni_linemod linemod模板匹配 ppf_object_recognition ppf特征来实现物体检测 nn_classification_example 近邻分类 pyramid_surface_matching 金字塔表面匹配 render_views_tesselated_sphere 模型多视图渲染生成点云 statistical_multiscale_interest_region_extraction_example 统计学的多尺度感兴趣区域提取 test_search pcl_feature_matching 特征匹配 分割 organized_segmentation_demo有序点云分割 pcd_organized_edge_detection 有序点云边缘检测 grabcut_2d 图像分割grabcut算法 pcd_organized_multi_plane_segmentation 有序点云多平面分割 pcd_select_object_plane dominant_plane_segmentation stereo_ground_segmentation 深度相机地面分割 B.Examples1.common pcl_example_check_if_point_is_valid 查看该点是不是违法 pcl_example_copy_point_cloud 复制点云 pcl_example_get_max_min_coordinates 获取最大最小的坐标点 pcl_example_organized_point_cloud 有序点云 pcl_example_scope_time 2.featurespcl features 成员（各式各样的描述子） 例程： pcl_example_difference_of_normals 法线之间的夹角 pcl_example_fast_point_feature_histograms 快速点特征直方图 pcl_example_normal_estimation 法线估计 pcl_example_point_feature_histograms 点特征直方图 pcl_example_principal_curvatures_estimation 曲率估计 pcl_example_rift_estimation rift描述子计算 pcl_example_shape_contexts pcl_example_spin_images 3.filterspcl filters 成员（各式各样的滤波器） 例程： pcl_example_extract_indices 提取索引 pcl_example_remove_nan_from_point_cloud 移除点云中的空点nan点 4.geometryexample_half_edge_mesh 5.keypoints例程： pcl_example_get_keypoints_indices pcl_example_sift_keypoint_estimation pcl_example_sift_normal_keypoint_estimation pcl_example_sift_z_keypoint_estimation 6.outofcore例程： pcl_example_outofcore pcl_example_outofcore_with_lod tools pcl_outofcore_print pcl_outofcore_process pcl_outofcore_viewer 7.segmentation例程： pcl_example_cpc_segmentation cpc分割 pcl_example_extract_clusters_normals pcl_example_lccp_segmentation lccp分割 pcl_example_region_growing 区域生长法 pcl_example_supervoxels 超体素分割 8.stereo例程： pcl_example_stereo_baseline 9.surface例程： pcl_example_nurbs_fitting_closed_curve pcl_example_nurbs_fitting_closed_curve3d pcl_example_nurbs_fitting_curve2d. pcl_example_nurbs_fitting_surface pcl_example_nurbs_viewer_surface pcl_test_nurbs_fitting_surface C.CUDA1.Apps D.IOtools pcl_convert_pcd_ascii_binary pcl_converter pcl_hdl_grabber pcl_pcd_convert_NaN_nan pcl_pcd_introduce_nan ply pcl_ply2obj pcl_ply2ply pcl_ply2raw pcl_plyheader E.tools其他 pcl_add_gaussian_noise 添加高斯噪声 pcl_transform_point_cloud 点云刚体变换 pcl_pcd_change_viewpoint pcl_transform_from_viewpoint pcl_boundary_estimation 边缘估计 pcl_cluster_extraction 聚类提取 pcl_compute_cloud_error 计算点点云误差 pcl_compute_hausdorff 计算hausdorff距离 pcl_compute_hull 计算凸包 pcl_concatenate_points_pcd 连接两个PCD文件 pcl_crop_to_hull crop到hull pcl_demean_cloud pcl_generate pcl_outlier_removal 点云外点去除 pcl_elch ELCH优化方法 Linemod pcl_linemod_detection linemod模板检测 pcl_match_linemod_template linemod模板匹配 pcl_train_linemod_template 滤波器 pcl_fast_bilateral_filter pcl_passthrough_filter pcl_uniform_sampling pcl_progressive_morphological_filter pcl_radius_filter pcl_morph 3D点云地图地面去除Progressive Morphological Filter pcl_voxel_grid pcl_voxel_grid_occlusion_estimation 点云分割 pcl_plane_projection 采样一致性获得平面 pcl_crf_segmentation CRF分割 pcl_sac_segmentation_plane 平面分割 pcl_train_unary_classifier pcl_unary_classifier_segment 关键点与特征 pcl_normal_estimation 法线估计 pcl_extract_feature 提取特征 pcl_fpfh_estimation FPFH特征描述子计算 pcl_spin_estimation spin描述子计算 pcl_vfh_estimation vfh描述子计算 pcl_grid_min pcl_local_max 配准 pcl_icp pcl_icp2d pcl_ndt2d pcl_ndt3d pcl_lum lum配准 物体重建： pcl_obj_rec_ransac_accepted_hypotheses pcl_obj_rec_ransac_hash_table pcl_obj_rec_ransac_model_opps pcl_obj_rec_ransac_orr_octree pcl_obj_rec_ransac_orr_octree_zprojection pcl_obj_rec_ransac_result pcl_obj_rec_ransac_scene_opps 表面重建 pcl_poisson_reconstruction 泊松重建 pcl_marching_cubes_reconstruction 移动最小二乘法重建 pcl_gp3_surface 贪心三角化 pcl_mesh_sampling 网格下采样 pcl_mls_smoothing 移动最小二乘法曲面平滑 可视化： pcl_octree_viewer 八叉树可视化 pcl_registration_visualizer 配准可视化 格式转换1.pcl_vtk2obj2.pcl_vtk2pcd3.pcl_vtk2ply4.pcl_xyz2pcd5.pcl_ply2pcd6.pcl_ply2vtk7.pcl_png2pcd8.pcl_pcd2ply9.pcl_pcd2png10.pcl_pcd2vtk11.pcl_tiff2pcd12.pcl_pclzf2pcd13.pcl_obj2pcd14.pcl_obj2ply15.pcl_obj2vtk16.pcl_mesh2pcl17.pcl_organized_pcd_to_png","link":"/2019/06/30/PCL/pcl1.8samples/"},{"title":"SAC-IA","text":"随机采样一致性（RANSAC）—— 模型参数估计； 最大似然估计（MLESAC）—— 模型参数估计； 采样一致性初始对齐算法（SAC-IA）—— 粗对齐； 处理外点的最常用的两种方案： 随机采样一致性（random sample consensus） M估计(M-Estimation)—–误差分布不是正态分布时,最小二乘估计不是最优估计，M-估计中可以找到优于最小二乘法的估计 一、RANSAC在计算机视觉领域广泛应用各种不同的采样一致性参数估计算法，用于排除错误的样本，样本不同，对应的应用则也不同，例如剔除错误的匹配点对，分割出处在模型上的点集等。 PCL中的“模型参数”估计方法PCL中以随机采样一致性算法（RANSAC）为核心，同时实现了五种类似于随机采样一致性参数估计算法。 随机采样一致性估计（RANSAC） 最大似然估计（MLESAC） 最小中值方差估计（LMEDS） 1.随机采样一致性估计（RANSAC）两个缺点： 当模型具有明显的物理意义时，阈值比较容易设定，但若模型比较抽象是，阈值不易确定。 RANSAC迭代次数是运行期决定的，不能与之迭代的确切次数 只能从一个特定数据集中估计一个模型，当来年改革或者更多个模型存在是，RANSAC不能找到别的模型。 步骤： 从样本中抽选出一个（最小）样本子集作为假设的内点（例如，如果根据数据拟合一条二维直线，则选择两个点）。 根据假设的内点拟合一个模型（例如，根据两个点拟合直线）。实际上是，使用最小方差估计算法对这个子集计算模型参数。 计算所有样本与该模型的偏差，再使用预先设定好的阈值t与偏差比较，当偏差小于阈值是，该样本点属于模型内样本点（inliers），否则为外样本点。 记录下当前inliers的个数，然后重复这一过程（选子集-&gt;估计模型参数-&gt;记录inliers个数）。每一次重复，都记录当前最佳（inliers个数最多，best_nlinliers）的模型参数。 每次迭代的末尾，根据期望的误差率、best_nlinliers、总样本个数，当前迭代次数，计算一个迭代结束评判因子，根据此决定是否结束迭代，结束迭代后，最佳模型参数就是最终的模型参数估计值。 2.最大似然估计（MLESAC）LMedS理论上也可以提出outliers的影响，并得到全局最优的参数估计，并且克服了RANSAC的两个缺点。但是当outliers在样本中比例达到或超过50%时，LMeds就无能为力。 从样本中抽选出一个样本子集，使用最小方差估计算法对子集计算模型参数 计算所有样本与该模型的偏差，与RANSAC不同的是，LMedS记录的是所有样本中，偏差值居中的那个样本的偏差[称为Med偏差]，以及本次计算得到的模型参数。 因此，LMedS不用预先设定阈值来剔除outliers。 重复前面的过程N次，从N个Med偏差中挑选最小的一个，其对应的模型参数就是最终的模型参数估计值。 注：迭代次数N是由样本子集中样本的个数、期望的模型误差、实现与聚集的样本中outliers的比例所决定的 二、SAC-IA不同于“采样一致性模型参数估计”，这里讲的是“采样一致性初始对齐”，主要是用采样一致性算法剔除错误点对（错误的对应估计）。 任务：对于已有的对应关系集合中，确定能够用于正确计算刚体变换矩阵的对应点对子集。 对于初始变换矩阵粗略估计，贪婪的配准方法工作量很大，它使用了点云数据旋转不变的特性，但计算复杂度较高，因为在合并的步骤需要查看所有可能的对应关系。此外，因为这是一个贪婪算法，所以有可能得到局部最优解。 因此我们采用采样一致性方法，试图保持相同的对应关系的几何关系而不必尝试了解有限个对应关系的所有组合。相反，我们从候选对应关系中进行大量的采样并通过以下步骤对它们中的每一个进行排名。 SAC-IA流程 从P中选择s个样本点，同时确定他们的配对距离大于用户设定的最小值dmin（相当于下采样，保证样本点之间是稀疏的）。 对于每个样本点，在Q中找到满足直方图和样本点直方图相似的点（可能是一个或多个）存进一个列表中。从这些点中随机选取”一些”代表采样点的对应关系； (通过SVD???)计算“通过采样点定义的刚体变换”和“其对应变换”，计算点云的度量错误来评价转换的质量。 我们计划通过查看非常大量的对应关系，快速找到一个很好的变换。 重复这三个步骤（在P中去取样本点-&gt;），直至取得存储了最佳度量错误，并使用暴力配准部分数据。最后使用一个LM算法进行非线性局部优化。 三、RandomSample Matching用于机器人抓取的随机采样一致性匹配方法应用论文：Efficient Bin-Picking and Grasp Planning Based on Depth Data 感觉方法有点扯淡，不如使用line2d看看就好。 要点：对应点匹配后用随机采样一致性算法，剔除错误对应关系。 物体定位流程：•通过深度相机（3d扫描仪）获取点云数据 •通过点云分割算法把单个物体点云数据分割出来 •通过模型与分割出来的（扫描数据）对齐匹配(配准)来估计姿态（变换） •通过精确对齐来完善 RANSAM算法（ Random Sample Matching ）描述： 计算特征点（关键点），这个点是通过计算每个三维网格来得到的；通过计算模型点云与相机点云得到特征点点集合P、Q： P: 模型特征点和它的法向 Q: 扫描特征点和它的法向 怎么选取一个点集里面的两个点？把这两个点称为an oriented point pair（有向点对）或dipole（偶极子） 特征描述： 这个特征具有旋转平移不变形的 构建特征表：（找出两个数据的带有特征的关键点集） •那么我们可以构建两张关于这个特征的表 •一张是由扫描得出来的数据的表 •一张是有CAD模型的来的表 特征匹配：得到两个带法向的对应点 我们通过一张表中的一个有向点对（偶极子），去搜寻匹配另外一张表中的相应的有向点对（偶极子），如果两个点对相似或相等，那么就说这两个偶极子是对应的， 计算变换矩阵： 通过这两个带法向的对应点（通过特定框架）解算变换矩阵，就可以找到一个将模型偶极变换到扫描的偶极子上的姿态假设。 找到最好的变换矩阵：(自己加的) 查看非常大量的对应关系，快速找到一个很好的变换。 ICP精确配准刚刚的操作是一个预对齐，还要通过一个ICP algorithm 去 refine the pose estimate. 改进特征：•再考虑到扫描条件不好的表面时候，比如塑料件还有金属表面，由于光学条件，我们用扫描仪扫出来的点云会有部分的点扫描不出来。 •以及由于扫描仪的成像系统结构原理的原因，有的部分也会扫不出来，像图b一样 Problem：请看图b 由于扫描数据不好，会算出错误的”特征点” 边缘处的点计算法线会出现错误 由于扫出来的只有平面会导致dipoles匹配错误(特征匹配错误) 改进： 改进的特征点集 Using 2d Image Analysis to Enhance the LocalizationPerformance（改进后通过2D图像的边界来代表特征点云） 新的特征：tripole（不带法线） 通过添加第三点和利用点云的三个随机顶点构建一个随机三角形(tripole)，可以使用三个顶点的距离来计算三个不变特征。使用这个，可以建立两个三维关系表，算法现在可以处理没有法线的点集。 优点就是：只使用边缘数据，减少了计算时间，增强了描述场景中的robust性 注：百度中的RANSAC算法简介： RANSAC算法(Random Sample Consensus)的基本假设是 样本中包含正确数据(inliers，可以被模型描述的数据)， 也包含异常数据(outliers，偏离正常范围很远、无法适应数学模型的数据)，即数据集中含有噪声。这些异常数据可能是由于错误的测量、错误的假设、错误的计算等产生的。 同时RANSAC也假设，给定一组正确的数据，存在可以计算出符合这些数据的模型参数的方法。 RANSAC基本思想描述如下： ①考虑一个最小抽样集的势为n的模型(n为初始化模型参数所需的最小样本数)和一个样本集P，集合P的样本数#(P)&gt;n，从P中随机抽取包含n个样本的P的子集S初始化模型M；(P中随机采样出子集S，利用S初始化模型M) ②余集SC=P\\S中与模型M的误差小于某一设定阈值t的样本集以及S构成S。S认为是内点集，它们构成S的一致集(Consensus Set)；(将余集中的点尝试加入内点集S，计算加入点与模型M之间的误差，小于误差则加入) ③若#(S)≥N，认为得到正确的模型参数，并利用集S(内点inliers)采用最小二乘等方法重新计算新的模型M*；重新随机抽取新的S，重复以上过程。(当S中的点已经够了，即认为估算出本次抽样计算出的模型M*；进行counts次抽样后得到counts个M*) ④在完成一定的抽样次数后，若未找到一致集则算法失败，否则选取抽样后得到的最大一致集判断内外点，算法结束。(在达到设定的抽样次数后，选取一致性最大的模型M max，然后判断P中的点是内点还是外点（要剔除的点）) 算法优化策略 ①如果在选取子集S时可以根据某些已知的样本特性等采用特定的选取方案或有约束的随机选取来代替原来的完全随机选取； ②当通过一致集S*计算出模型M*后，可以将P中所有与模型M*的误差小于t的样本加入S*，然后重新计算M*。","link":"/2020/04/11/Registration/0.SAC-IA/"},{"title":"Detailed Notes to NDT","text":"配准算法之 — NDT 超级详细介绍NDT 建议下载下来用Typora软件阅读markdown文件 NDT配准算法详解论文： The Three-Dimensional Normal-Distributions Transform– an Efficient Representation for Registration, Surface Analysis, and Loop Detection 作者： Martin Magnusson 用于表示表面的概率密度函数 点云由深度传感器等获取的一组来自表面的空间采样点。使用点云来表示表面有许多限制。例如，点云不包含关于表面特征(如方向、平滑度或孔)的明确信息。1.根据传感器的配置，点云也可能是低效的，需要不必要的大量存储。2.为了在远离传感器位置的地方获得足够的样本分辨率，通常有必要对传感器进行配置，以便从传感器附近的表面产生大量冗余数据。（离传感器远的地方单位体积内点云密度小，离传感器近的地方单位体积内点云冗余） 正态分布变换可以描述为一种紧表示曲面的方法。首被Biber和Straßer在2003年作为二维扫描注册方法而提出。 该变换将点云映射到光滑的表面表示，该表面表示为一组局部概率密度函数(PDFs)，每一个PDFs都描述了表面的一段形状。 PDFs：PDF的几何意义正态分布给出了具有连续导数的点云的分段光滑表示。每个PDF都可以看作是局部表面的近似，描述了表面的位置以及它的方向和平滑度。二维激光扫描及其对应的正态分布如图6.1所示。图6.2展示了矿井巷道扫描的三维正态分布。 一个二维激光扫描从一个矿井隧道(显示为点)和PDFs描述的表面形状。在这种情况下，每个单元格都是一个边长为2米的正方形。较亮的区域表示较高的概率。PDFs只计算了五点以上的单元格 上图为隧道断面的3D-NDT表面表示。 更亮、更密集的部分表示更高的概率。cell的边长为1米。 单变量和多变量正态分布的特征 在一维情况下,对于一个正态分布随机变量x来说，有确定的期望值:μ ​ 和还不确定方差的值:σ。 在式子6.1中的多元概率函数，在一维情况下(D = 1)降为上面的p(x)。 在多维的情况下，均值μ和方差σ取而代之的是均值向量和协方差矩阵。 协方差矩阵的对角线元素表示每个变量的方差，非对角元素表示变量的协方差。图6.3说明了一维、二维和三维的正态分布。 在二维和三维的情况下，可以通过协方差矩阵的特征向量和特征值来判断曲面的方向和光滑度,也就是说，一组正交向量对应于各变量协方差的主方向。取决于方差的比例，二维正态分布可以是点形(如果方差相似)，也可以是线形(如果一个比另一个大得多)，或者介于两者之间。 在三维情况下如图6.4所示 正态分布可以描述点或球(如果方差的大小在各个方向上是相似的)， 一条直线(如果一个方向的方差远大于另两个方向的方差)， 或者一个平面(如果一个方向的方差比另两个方向的方差小得多)。 计算每个网格里面的PDF 该算法的第一步是将扫描占用的空间细分为单元格网格（a grid of cells）(二维情况下为正方形case，三维情况下为立方体cubes)。 根据单元内的点分布，每个单元计算一个PDF。（probability density functions）概率密度函数 每个单元中的PDF可以解释为单元内表面点的生成过程(generative process)。换句话说，我们假设的位置是由这个分布生成的。 假设参考扫描表面点的位置是由d维正态随机过程产生的，则该cell中的，的概率为 ：该cell中的均值向量(mean vector)和协方差矩阵(covariance matrix) 是在cell中的参考表面点集(reference scan points)的位置(positions) 分母作用：缩放函数使其积分为1，在实际应用中，可以用常数c0替换它。 NDT配准算法当你使用NDT算法用于点云配准时，目的是为了找到一个位姿pose（要最优化的对象）—&gt;可以最大化current scan的点位于reference scan表面的可能性。—&gt;maximises the likelihood（目标函数）. a.要优化的参数：要优化的参数:R, t。即对the current scan的位姿估计的旋转和平移，可以用向量来表示这个参数。 b.输入 current scan’s points:被表示为一个点云。假设存在一个空间变换函数，通过位姿来移动 给定的一些scan points的PDF，应该找到一个最好的位姿使得下面的似然函数（极大似然函数）最大。 c.两种目标函数1.极大似然估计（最大化） 对点云通过变换函数变换后，对新的点云中每个点的概率累乘 2.负对数似然估计（最小化）或者可以找到一个最好的位姿使得化负对数似然函数最小 对点云通过变换函数变换后，对新的点云中每个点的概率的负对数累加 d.改进PDF如图6.5所示比较正态分布和混合模型。 负对数似然是进行NDT扫描配准时的“目标函数”。 它的导数描述了特定测量对解的偏置。（Its derivative characterises the bias that a particular measurement has on the solution.） 对于，对于较大的，影响是没有边界的，而对于，影响是有边界的。 1.使用正态分布和均匀分布的混合模型的PDF：PDF(概率密度函数)不一定限于正态分布，任何局部捕获表面点结构并对异常值具有鲁棒性的PDF都是合适的。 “正态分布的负对数”可能性在远离均值的点上无限增长。 因此，扫描数据中的异常值可能对结果有很大的影响。 在这项工作中(Biber，Fleck,和Straßer 的论文中）采用的是正态分布和均匀分布的混合模型: po是异常值的期望比率，利用这个函数，异常值的影响是有界的。 常量c1和c2可以通过”在一个单元格所张成的空间内，让的“概率质量等于1”来确定。 概率质量函数：mass强调的是一个聚集在一起的物体，就是它一个块一块的。这和离散型数据很像，就是一数据属于某个类。他们是聚集一块一块的。所以用mass这个词来描述他们的概率。翻译成中就变成了概率质量函数。你可以这么记忆：离散型数据是块状物体，物体是有质量，所以叫概率质量函数。 概率密度函数(Probability Density Function）这个是描述连续性数据。就是落在某个区间内的概率多大。这个就像液体，液体是连续的。同等体积有些液体重有些液体轻，用密度这个词描述会更合适。它的缩写很意思，叫做PDF，哈哈哈 要优化的对数似然能量函数的和由具有这种形式的项组成（要优化的对数似然估计由这样的项相加）它们没有简单的一阶和二阶导数。下面提供解决思路。 2.将目标函数近似为高斯函数（负对数似然函数拟合成高斯函数）由于“要优化的对数似然函数”没有简单的一阶和二阶导数，这样子目标函数优化起来很难，将改进的正态分布和均匀分布的混合近似看作高斯分布，然而,图6.5 b表明对改进的数似然函数（目标函数）可以近似为一个高斯函数。 一个这样的函数: ， 可以近似为高斯函数： 拟合参数通过分别让 应该像 中还有来获得。 3.最终的目标函数：对多维的”混合模型的分布“构造的负对数似然函数（目标函数）用高斯函数来近似，来作为目标函数，来对参数(位姿)进行优化。 a.目标函数的项：利用这种高斯近似，得到了一个current scan point对*NDT score function *的影响 分别代表网格中在网格中所在位置的均值和协方差 这个NDT score function的导数比6.7式正态分布和均匀分布的混合的导数要简单（优化起来更简单），但在优化时仍然具有相同的一般性质（功能相同但是更加简单）。 d3项在公式6.9中被省略了。当使用NDT进行扫描配准时，这不是必需的，因为它只向score函数添加一个常量偏移量，并且不改变其形状或优化参数。 b.score function（目标函数）：给定一组点和一个变换函数用来通过一个位姿变换每个点。 the current parameter vector的NDT评分函数为: 该函数表示通过位姿变换点集（k=1～n）到the reference scan上对应的新的点集计算出的似然值(the likelihood)。 似然函数需要求协方差矩阵的逆矩阵![](Detailed_Notes_to_NDT/inverse of the covariance matrix.png)。如果网格中的点是完全共面或共线的，协方差矩阵是奇异的，不可逆。在三维情况下，由三个或更少的点计算的协方差矩阵总是奇异的， 因此，PDFs只计算包含5个以上点的单元格。 此外，作为对数值问题的预防，当![](Detailed_Notes_to_NDT/covariance matrix.png)被发现几乎是奇异时，它就会轻微地膨胀。如果最大的特征值比还要大100被以上，然后是较小的特征值被设成 然后更新矩阵为:![](Detailed_Notes_to_NDT/newcovariance matrix.png) 中包含![](Detailed_Notes_to_NDT/covariance matrix.png)的特征向量， e.使用牛顿法对目标函数进行优化牛顿算法可以用来求使评分（目标）函数最优化的参数 牛顿法迭代地解等式 是海森矩阵 是的梯度向量 在每次迭代中，将增量（牛顿方向）添加到当前的位姿估计中以计算出下一次迭代的参数 1.计算点云变换后在该cell中的去质心坐标是“通过位姿参数变换后得到的新的坐标”减去”所在网格的测点的均值“。 2.梯度向量的元素（分量）可以写成 3.海森矩阵中的元素海森矩阵中的元素这样计算： NDT 的score function中的“式子6.12的梯度”，和“式子6.13中的海森矩阵”，无论配准是在2D还是3D(或任何其他维度)中执行，函数都以相同的方式表示。它们同样独立于正在使用的转换表示。 对于在式子6.12和6.13中的一阶和二阶偏导数来说，它依赖于变换函数T。T可以是2D变换也可以是3D变换 f.以前文章使用的目标函数也可行在之前的几篇关于NDT扫描配准的文章中[7,48,57,64,67,89]， score function（ 目标函数）是直接使用高斯形式的正态分布的PDFs之和来定义的！！！，虽然从概率的角度来看，这样的公式不太令人满意，但是最终的结果与使用混合模型的对数似然的高斯近似(6.9)的结果非常相似(6.7)。 算法流程算法2描述了如何使用NDT注册(配准)两个点云X和Y。 初始化工作： 划分网格，找出参考点云Y的所有点对应的网格 对于每个网格计算网格中的参数 计算网格中分布的参考点云的点的去质心坐标 计算网格中参考点云的去质心坐标的平均值 计算网格中参考点云的去质心点的协方差 配准工作： 第一步判断是否收敛 当还没有收敛时，将目标函数，梯度，海森矩阵设为0 第二步对源点集进行相关计算 对于源点集中的所有点应用变换矩阵后，这些点坐落在“找到之前划分的网格”的位置 计算每个点的高斯近似目标函数的分数，将每个网格中的分数加起来 使用公式6.12更新梯度 使用公式6.13更新Hessian矩阵 第三步，计算牛顿方向，然后计算出下一个优化矩阵，然后跳到第一步。","link":"/2019/06/04/Registration/Detailed_Notes_to_NDT/"},{"title":"3D reconstruction","text":"A.三种重构技术的简单介绍 B.需要了解的知识 C.书籍与其他资源 三种重构技术简介本文部分是从“3D视觉工坊”公众号摘取 A.三种重构技术的简单介绍在2D图像处理领域，可以采用面阵和线阵相机，二者相辅 相成，从而满足不同的应用要求，与之类似，3D图像处理也提 供各种技术，现在最常使用的技术包括： 立体视觉和结构光 激光三角测量法 ToF(Time-of-Flight) 每项技术根据不同的原理来记录三维信息，它们均有不同的优点和缺点。在此，这些技术同样可以实现优势互补，至于 哪种最适合，这取决于各自应用的要求。 一、立体视觉和结构光 立体视觉的工作原理依照人类的一双眼睛4使用两个相机 记录一对象的两个2D图像，并且，从两个不同的位置记录同样的场景，借助三角测是原理，使用深度信息合成一幅三维图像。立体视觉使用从两个普通的2D面阵相机提供的图像数据，为场景提供深度值。同时，根据相机位置以及应用的几何信息 对图像进行调整。在调整后，使用匹配算法搜索右侧和左侧的对应点，创建场景的深度图像。 此方法运行的工作距离取决于基准（相机之间的距离）， 因此因情况而异。 提高立体系统性能的一种方式是向立体解决方案添加结构光。通过使用光源将明亮的几何图案投射在场景上，可以提高测量结果的准确度，这显著降低因均质表面和低光造成的立体影像缺陷。通过校准投射灯和相机，甚至可以不使用第二台相机。 1.1立体视觉的优点和缺点优点： 可以在较短距离内获得茼精度 可以使用2D面阵相机 阳光照射不是问题 高反光（称为难处理表面）的情况下也可以使用 缺点： 不能用于均质表面 在低光照条件下不能运行 高计算能力导致实时性难以实现 1.2结构光的优点和缺点优点： 可以在较短距离内获得高精度 可以使用2D面阵相机 阳光照射不是问题 高反光（称为难处理表面）的情况下也可以使用 缺点： 高计算负载导致实时性难以实现 设置复杂、安装成本高、导致总体系统安装成本高昂 1.3立体视觉和结构光的典型应用领域立体视觉可以实现较高精度。难处理表面不会对立体视觉造成较大影响，但始终要求对象存在少量标记或随机图案。这意味看这种技术一般不太适合在生产环境中使用。立体视觉通常的应用范围包括：坐标测量技术，工业、服务或机器人系统方面应用的对象和工作区的3D测量。 以及危险工作区或 人类无法进入的工作区的3D显示。立体系统也非常适合在室外区域的测是系统中使用，如在锯木厂中测量和检查树干。然而，如果可以接受高处理负载、复杂的安装工作和更高成本，在添加结构光后，立体视觉也适合进行目标测量的工业应用。 1.4相关资源 结构光(格雷码)和重构 内含投影仪-相机标定程序:projector-calib-src 论文：Simple, Accurate, and Robust Projector-Camera Calibration 二、激光三角测量法在运用激光三角测量法是，结合使用了2D相机和激光光源。在此过程中，激光将线或者点投射在相机前的场景上。激光线或点出现在相机前的对象上，由2D相机记录。如果使相机跨过目标或在目标旁移动（例如通过传送带），被测量对象到芯片之间的距离会改变，那么激光线或点的观察角度随它们的相机图像中的位置一起改变。这样，通过数学运算，对象和光源之间的距离就可以通过图像中的位置坐标计算得出。 2.1激光三角测量法的优点和缺点优点： 精度极高 照明条件较差是仍可工作 可用于镜面反射或高反光（难处理）表面 缺点： 需要对目标进行激光扫描，导致速度变慢 工作距离小 高精度要求采用非常昂贵的单个组件 设置复杂，安装成本高，导致总体系统成本高昂 如果没有安全预防措施无法保证眼睛安全 2.2激光扫描仪应用激光三角测量法对于准确性要求极高的应用，常常是一种好的选择。而对于高反光且光照条件不理想的难处理表面，也建议选择激光三角测量法。举例来说，在亚毫米范围内测量高反光的金属片就是激光三角测量法的典型应用。另外一个例子是对玻璃瓶进行分拣，这种情况下对比度极小。 三、ToF(Time-of-Flight)方法ToF(Time-of-Flight)方法是获取深度数据及测量距离的非常有效的技术。ToF(Time-of-Flight)相机为每个像素提供两种信息：亮度值（描述为灰度值）以及相机和目标的距离（即深度值）。 ToF(Time-of-Flight)方法有两种不同的用法：连续波和脉冲ToF(Time-of-Flight)方法。 连续波ToF(Time-of-Flight)方法基于亮度调制光源的相位长度测量。该方法较成熟，采用标准电子元件。在此方法中使用的芯片相对较大，只能工作在较低分辨率下。 脉冲的ToF(Time-of-Flight)方法根据许多单个光脉冲的传播时间测量距离。这就需要非常快速和精确的电子元件，以实现+/-1cm精度范围。到目前为止，通过技术进步，能够以合理的成本生成精确的光脉冲及在高分辨率下进行精确测量。这就是脉冲ToF(Time-of-Flight)方法能够继续快速发展的原因，而转向高分辨率的趋势同样显著。 ToF(Time-of-Flight)相机是一个紧凑的系统，没有可移动部件，它由以下组件组成： 主动集成光源 集成镜头 ToF(Time-of-Flight)芯片 光源发出脉冲或连续光。这种光照对象，然后返回相机。同时。集成镜头确保反射的光线到达芯片。以简化的方式来诠释，就是以光线再次到达芯片的时间计算距离，从而得出每个像素的深度值。这一方法可以简单且实时地描述散点图/深度图，并可以提供同时记录的强度和置信度的图像。 3.1优点和缺点优点： 一次记录场景，无需扫描 高速度 在多部分图像中提供2D和3D信息 高X/Y分辨率 系统紧凑，无锡移动组件 在低光照条件下工作理想 确保眼睛安全 无结构或对比度要求 只需提供足够强的光源，可以实现长工作距离 总体系统成本低 可实现高度实时性 缺点： 镜面反射及高反光（难处理）表面存在问题 对杂散光敏感 太阳光下难以运行 3.2ToF(Time-of-Flight)的典型应用领域ToF (Time-of-Flight)相机适合长工作距离、高速和低复杂度需求的应用。如果有这些需求，且对低预算的要求高于对毫米级精确度的要求，那么，脉冲的ToF (Time-of-Flight)技术是 正确选择。物流、码探和写垛的容积测是以及物流环境中的自动驾驶车辆都适合采用ToF (Time-of-Flight)相机。ToF (Time-of-Flight)相机在医疗领域也获得了令人兴奋的新任务， 那就是定位和监测患者。在工业领域中，由于ToF (Time-of- FNght)相机的深度精度相对较低，采用这种相机的系统更适合一般化任务，如较大对象的选择和放置应用。它们还可以用于机器人控制系统或大型对象的测畺和位置检测，例如用于汽车制造。 3D技术的比较 立体视觉 结构光 将激光扫描仪 ToF 范围 中到远 中 短 远 分辨率 中 中 不同 高 深度精度 短范围内极高 短范围内极高 极高 中 软件复杂性 高 中 高 低 实时性 低 低到中 低 高 低光条件下的运行情况 差 好 好 好 户外区域 好 差 中 目前较差 紧凑性 中 中 差 非常差 材料成本 中 高 高 中到高 总运行成本 高 中到高 高 中到高 B.需要了解的知识具体内容待补充 1.相机模型与对极几何 针孔相机模型 外参数矩阵 内参数矩阵 透视矩阵 径向畸变 对极几何 对极约束 基础矩阵 RANSAC 基础矩阵F 本征矩阵E 单应矩阵H C.书籍与其他资源 书籍：《机器视觉与算法应用》 源码：OpenCV、halcon 待补充。。。","link":"/2019/06/13/Reconstruction/3d_reconstruction/"},{"title":"cudanote2","text":"第四章 CUDA C 并行编程、第五章线程协作 CUDA C并行编程、线程协作、GPU逻辑结构、配置线程、共享内存与同步、二维线程块实现波纹、共享内存实现点积 GitHub 建议下载下来用Typora软件阅读markdown文件 作者github:littlebearsama 原文链接 (建议下载Typora来浏览markdown文件) 第四章 CUDA C 并行编程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include&lt;stdio.h&gt;#define N 10__global__ void add( int *a, int *b, int *c ) { int tid = blockIdx.x; // this thread handles the data at its thread id if (tid &lt; N) c[tid] = a[tid] + b[tid];}int main( void ) { int a[N], b[N], c[N]; int *dev_a, *dev_b, *dev_c; // allocate the memory on the GPU cudaMalloc( (void**)&amp;dev_a, N * sizeof(int) ); cudaMalloc( (void**)&amp;dev_b, N * sizeof(int) ); cudaMalloc( (void**)&amp;dev_c, N * sizeof(int) ); // fill the arrays 'a' and 'b' on the CPU for (int i=0; i&lt;N; i++) { a[i] = -i; b[i] = i * i; } // copy the arrays 'a' and 'b' to the GPU cudaMemcpy( dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice ); cudaMemcpy( dev_b, b, N * sizeof(int), cudaMemcpyHostToDevice ); add&lt;&lt;&lt;N,1&gt;&gt;&gt;( dev_a, dev_b, dev_c ); // copy the array 'c' back from the GPU to the CPU cudaMemcpy( c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost ); // display the results for (int i=0; i&lt;N; i++) { printf( \"%d + %d = %d\\n\", a[i], b[i], c[i] ); } // free the memory allocated on the GPU cudaFree( dev_a ); cudaFree( dev_b ); cudaFree( dev_c ); return 0;} 调用cudaMalloc()在设备上为三个数组分配内存。 使用完GPU后调用cudaFree()来释放他们。 通过cudaMemcpy()进行主机与设备之间复制数据。 第五章 线程协作1.GPU逻辑结构 CUDA的软件架构由网格（Grid）、线程块（Block）和线程（Thread）组成， 相当于把GPU上的计算单元分为若干（2~3）个网格， 每个网格内包含若干（65535）个线程块， 每个线程块包含若干（512）个线程， 三者的关系如下图： 2.线程索引（ID）定位作用： 线程ID用来定位线程，根据线程ID来给各个线程分配数据以及其他操作。 计算线程ID需要通过本线程的各个内建变量来计算被调用核函数所进入的线程ID. 内建变量： threadIdx(.x/.y/.z代表几维索引)：线程所在block中各个维度上的线程号 blockIdx(.x/.y/.z代表几维索引)：块所在grid中各个维度上的块号 blockDim(.x/.y/.z代表各维度上block的大小)： block的大小即block中线程的数量， blockDim.x代表块中x轴上的线程数量， blockDim.y代表块中y轴上的线程数量， blockDim.z代表块中z轴上的线程数量 gridDim(.x/.y/.z代表个维度上grid的大小)： grid的大小即grid中block的数量， gridDim.x代表grid中x轴上块的数量， gridDim.y代表grid中y轴上块的数量， gridDim.z代表grid中z轴上块的数量 定义grid、block大小：dim3 numBlock(m,n)dim3 threadPerBlock(i,j)则blockDim.x=i; blockDim.y=j; gridDim.x=m; gridDim.y=n kernel调用：kernel&lt;&lt;&lt;numBlock,threadPerBlock&gt;&gt;&gt;(a,b)这是调用kernel时的参数，尖括号&lt;&lt;&lt;&gt;&gt;&gt;中第一个参数代表启动的线程块的数量，第二个参数代表每个线程块中线程的数量。 总的线程号：设线程号为tid,以下讨论几种调用情况下的tid的值，这里只讨论一维／二维的情况 一维：１．kernel&lt;&lt;&lt;1,N&gt;&gt;&gt;()block和thread都是一维的，启动一个block，里面有N个thread，１维的。tid=threadIdx.x ２．kernel&lt;&lt;&lt;N,1&gt;&gt;&gt;()启动N个一维的block，每个block里面１个thread。tid=blockIdx.x ３．kernel&lt;&lt;&lt;M,N&gt;&gt;&gt;()启动Ｍ个一维的block，每个block里面N个一维的thread。tid=threadIdx.x+blockIdx.x * blockDim.x 一般如何配置线程？ kernel&lt;&lt;&lt;M,N&gt;&gt;&gt;() M，N为1维度 输入数据numbers，设定每个线程块有N=128或256或512个线程，一般设为128。 计算应该设置的线程块M=（numbers+N-1）/N，向上取整；线程块是数量不能超过65535，这是一种硬件限制，如果启动的线程块数量超过了这一限值，那么程序将运行失败。 二维：dim3 grid(4, 4, 1), block(4, 4, 1); 一维索引： 1234567__global__ void vector_add(float* vec1, float* vec2, float* vecres, int length) { // 在第几个块中 * 块的大小 + 块中的x, y维度（几行几列） int tid = (blockIdx.y * gridDim.x + blockIdx.x) * (blockDim.x * blockDim.y) + threadIdx.y * blockDim.y + threadIdx.x; if (tid &lt; length) { vecres[tid] = vec1[tid] + vec2[tid]; }} 二维索引： 1234567__global__ void vector_add(float** mat1, float** mat2, float** matres, int width) { int x = blockIdx.x * blockDim.x + threadIdx.x; int y = blockIdx.y * blockDim.y + threadIdx.y; if (x &lt; width &amp;&amp; y &lt; width) { matres[x][y] = mat1[x][y] + mat2[x][y]; }} tid&lt;N公式M=（numbers+N-1）/N保证了启动了足够多的线程,当输入数据numbers不是线程块里面线程数N的整数倍时,将启动过多线程。 为了防止启动过多线程：在核函数中，在访问输入数组和输出数组之前，必须检查线程的偏移（索引）tid是否位于0到N之间 12if(tid&lt;N) c[tid]=a[tid]+b[tid]; 因此，当索引越过数组边界时，例如当启动并行线程数量不是线程块中线程的数目N（128）就会出现这种情况，那么核函数将自动停止执行计算。更重要的是，核函数不会对越过数组边界的内存进行读取或写入。 简单来说就是启动了充足的线程，而有的线程不用工作，为了防止核函数不会出现越界读取等错误，我们使用了条件判断if（tid&lt;N）。 当数据大于运行线程时因为数据数目大于线程数目，所以正在运行的所有线程都可能会再被执行，直到所有数据处理完毕。所以while(tid&lt;N)不仅仅用于判断线程ID tid，是否执行线程。也用于循环。 添加语句tid+=blockDim.x*gridDim.x;增加的值等于每个线程块中的线程数量乘以线程网格中线程块的数量，在上面的线程分配(一维的线程格，一维的线程块)中为blockDim.x*gridDim.x 故核函数被改写为 123456__global__ void add( int *a, int *b, int *c ) { int tid = threadIdx.x+blockIdx.x*blockDim.x; // this thread handles the data at its thread id while (tid &lt; N) c[tid] = a[tid] + b[tid]; tid+=blockDim.x*gridDim.x;//新增的} 3.二维的线程格，二维的线程块（实现波纹效果） 1234567891011121314151617181920212223__global__ void kernel( unsigned char *ptr, int ticks ) { // map from threadIdx/BlockIdx to pixel position int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; int offset = x + y * blockDim.x * gridDim.x; // now calculate the value at that position float fx = x - DIM/2; float fy = y - DIM/2; float d = sqrtf( fx * fx + fy * fy ); unsigned char grey = (unsigned char)(128.0f + 127.0f * cos(d/10.0f - ticks/7.0f) / (d/10.0f + 1.0f)); ptr[offset*4 + 0] = grey; ptr[offset*4 + 1] = grey; ptr[offset*4 + 2] = grey; ptr[offset*4 + 3] = 255;}dim3 blocks(DIM/16,DIM/16);dim3 threads(16,16);kernel&lt;&lt;&lt;blocks,threads&gt;&gt;&gt;( data.dev_bitmap, ticks ); blocks和threads是两个二维变量 由于生成的是一幅图像，因此使用二维索引，并且每个线程都有唯一的索引(x,y)，这样可以很容易与输出图像中的像素一一对应起来。就是输出图像的像素索引(x,y) offset是数据的线程索引（被称为全局偏置）,该线程对应图像像素索引(x,y)也对应数据索引offset (fx,fy)=像素点(x,y)相对于图像中心点（DIM/2，DIM/2）位置，即把图像原点移到图像中心 加入线程块是一个16X16的线程数组，图像有DIMXDIM个像素，那么就需要启动DIM/16 x DIM/16个线程块，从而使每一个像素对应一个线程。 GPU优势在于处理图像时比如1920X1080需要创建200万个线程，CPU无法完成这样的工作。 4.共享内存和同步 共享内存术语Shared Memory，是位于SM（流多处理器）中的特殊存储器。还记得SM吗，就是流多处理器，大核是也。 将关键字__share__添加到变量声明中，这将是这个变量驻留在共享内存中。 block与block的线程无法通信 共享内存缓存区驻留在物理GPU上，而不是驻留在GPU以外的系统内存中。因此，在访问共享内存时的延迟要远远低于访问普通缓存区的延迟，使得共享内存像每个线程块的高速缓存或中间结果暂存器那样高效。 想要在线程之间通信，那么还需要一种机制来实现线程之间的同步，例如，如果线程A将一个值写入到共享内存，并且我们希望线程B对这个值进行一些操作，那么只有当线程A写入操作完成后，线程B才能开始执行它的操作。如果没有同步，那么将发生竞态条件。 这里的例子是点积的例子，就是： 代码： 123456789101112131415161718192021222324__global__ void dot(float *a, float *b, float *c) { __shared__ float cache[threadsPerBlock]; int tid = threadIdx.x + blockIdx.x * blockDim.x;//全局偏移用来索引数据 int cacheIndex = threadIdx.x; //共享内存缓存中的偏移就等于线程索引 float temp = 0; while (tid &lt; N) { temp += a[tid] * b[tid]; //线程被执行的次数是未知的，数据最终被保存成temp并 tid += blockDim.x * gridDim.x; //存入到threadsPerBlock维的cache中 } cache[cacheIndex] = temp; __syncthreads(); //归约运算 int i = blockDim.x / 2;//取threadsPerBlock的一半作为i值 while (i != 0) { if (cacheIndex &lt; i) cache[cacheIndex] += cache[cacheIndex + i]; __syncthreads(); i /= 2; } //结束while()循环后，每个线程块都得到一个值。这个值位于cache[]的第一个元素中，并且就等于该线程中两两元素乘积的加和。然后，我们将这个值保存到全局内存并结束核函数。 if (cacheIndex == 0) c[blockIdx.x] = cache[0];} __shared__ float cache[threadsPerBlock];在共享内存中申请浮点数组，数组大小和线程块中线程数目相同每个线程块都拥有该共享内存的私有副本。 共享内存缓存区cache将保存该block内每个线程计算的加和值。 __syncthreads();等待线程块里面的所有线程执行完毕，简称线程同步。确保线程块中的每个线程都执行完__syncthreads();前面的语句后才会执行下一语句。 用规约运算，我们取threadsPerBlock的一半作为i值，只有索引小于这个值的线程才会执行。只有当线程索引小于i时，才可以把cache[]的两个数据项相加起来。__syncthreads()作用如下图（下图中是等待4个线程中的相加操作完成）。 ​ 假设cache[]中有8个元素，因此i的值为4。规约运算的其中一个步骤如下图所示 由于线程块之间无法通信。只能将每个线程块算出来的值存出来,存到数组c中，最后会返回block数量个c，然后由cpu执行最后的加法。 当某些线程需要执行一条指令，而其他线程不需要执行时，这种情况就称为线程发散（Thread Divergence）。在正常环境中，发散的分支只会使得某些线程处于空闲状态，而其他线程将执行分支中的代码。但是在__syncthreads()情况中，线程发散造成的结果有些糟糕。CUDA架构将确保，除非线程块中的每个线程都执行了__syncthreads()，否则没有任何线程能执行__syncthreads()之后的指令。如果__syncthreads()位于发散分支中，一些线程将永远无法执行__syncthreads()。硬件将一直保持等待。 下面代码将使处理器挂起，因为GPU在等待某个永远无法发生的事件。 1234if (cacheIndex &lt; i){ cache[cacheIndex] += cache[cacheIndex + i]; __syncthreads(); } 例子2（二维线程布置）基于共享内存的位图（略）","link":"/2019/05/24/cuda/cudanote2/"},{"title":"cudanote3","text":"第六章 常量内存与事件 光线追踪、常量内存与事件、常量内存带来的性能提升、线程束 GitHub 建议下载下来用Typora软件阅读markdown文件 作者github:littlebearsama 原文链接 (建议下载Typora来浏览markdown文件) 第六章 常量内存与事件0.光线追踪 常量内存用于保存在核函数执行期间不会发生变化的数据。Nvidia硬件提供了64KB的常量内存，并且对常量内存采取了不同于标准全局内存的处理方式。在某些情况中，用常量内存来替换全局内存能有效地减少内存带宽。 在光线跟踪的例子中，没有利用常量内存的代码运行时间为1.8ms，利用了常量内存的代码运行时间为0.8ms 将球面数组存入常量内存中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119#include \"cuda.h\"#include \"../common/book.h\"#include \"../common/image.h\"#define DIM 1024#define rnd( x ) (x * rand() / RAND_MAX)#define INF 2e10fstruct Sphere { float r,b,g; float radius; float x,y,z;//球心相对于图像中心的坐标 __device__ float hit( float ox, float oy, float *n ) { float dx = ox - x; float dy = oy - y; //计算来自于(ox,oy)处像素的光线（垂直于图像平面），计算光线是否与球面相交 //然后计算相机到光线命中球面出的距离 if (dx*dx + dy*dy &lt; radius*radius) { float dz = sqrtf( radius*radius - dx*dx - dy*dy ); *n = dz / sqrtf( radius * radius ); return dz + z; } return -INF; }};#define SPHERES 20__constant__ Sphere s[SPHERES];__global__ void kernel( unsigned char *ptr ) { // map from threadIdx/BlockIdx to pixel position int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; int offset = x + y * blockDim.x * gridDim.x; float ox = (x - DIM/2);//(ox, oy)=(x, y)相对于图像中心点（DIM / 2，DIM / 2）位置或者说将图像移到中心 float oy = (y - DIM/2); float r=0, g=0, b=0; float maxz = -INF; for(int i=0; i&lt;SPHERES; i++) { float n; float t = s[i].hit( ox, oy, &amp;n ); if (t &gt; maxz) { float fscale = n; r = s[i].r * fscale; g = s[i].g * fscale; b = s[i].b * fscale; maxz = t; } } ptr[offset*4 + 0] = (int)(r * 255); ptr[offset*4 + 1] = (int)(g * 255); ptr[offset*4 + 2] = (int)(b * 255); ptr[offset*4 + 3] = 255;}// globals needed by the update routinestruct DataBlock { unsigned char *dev_bitmap;};int main( void ) { DataBlock data; // capture the start time cudaEvent_t start, stop; HANDLE_ERROR( cudaEventCreate( &amp;start ) ); HANDLE_ERROR( cudaEventCreate( &amp;stop ) ); HANDLE_ERROR( cudaEventRecord( start, 0 ) ); IMAGE bitmap( DIM, DIM ); unsigned char *dev_bitmap; // 在GPU上分配内存以计算输出位图 HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_bitmap, bitmap.image_size() ) ); // 分配临时内存，对其初始化，并复制到GPU上的常量内存，然后释放临时内存 Sphere *temp_s = (Sphere*)malloc( sizeof(Sphere) * SPHERES ); for (int i=0; i&lt;SPHERES; i++) { temp_s[i].r = rnd( 1.0f ); temp_s[i].g = rnd( 1.0f ); temp_s[i].b = rnd( 1.0f ); temp_s[i].x = rnd( 1000.0f ) - 500; temp_s[i].y = rnd( 1000.0f ) - 500; temp_s[i].z = rnd( 1000.0f ) - 500; temp_s[i].radius = rnd( 100.0f ) + 20; } HANDLE_ERROR( cudaMemcpyToSymbol( s, temp_s, sizeof(Sphere) * SPHERES) ); free( temp_s ); // generate a bitmap from our sphere data dim3 grids(DIM/16,DIM/16); dim3 threads(16,16); kernel&lt;&lt;&lt;grids,threads&gt;&gt;&gt;( dev_bitmap ); // copy our bitmap back from the GPU for display HANDLE_ERROR( cudaMemcpy( bitmap.get_ptr(), dev_bitmap, bitmap.image_size(), cudaMemcpyDeviceToHost ) ); // get stop time, and display the timing results HANDLE_ERROR( cudaEventRecord( stop, 0 ) ); HANDLE_ERROR( cudaEventSynchronize( stop ) ); float elapsedTime; HANDLE_ERROR( cudaEventElapsedTime( &amp;elapsedTime, start, stop ) ); printf( \"Time to generate: %3.1f ms\\n\", elapsedTime ); HANDLE_ERROR( cudaEventDestroy( start ) ); HANDLE_ERROR( cudaEventDestroy( stop ) ); HANDLE_ERROR( cudaFree( dev_bitmap ) ); // display bitmap.show_image();} 变量前面加上__constant__修饰符：__constant__ Sphere s[SPHERES];常量内存为静态分配空间，所以不需要调用 cudaMalloc(), cudaFree()； 在主机端分配临时内存，对其初始化Sphere *temp_s = (Sphere*)malloc( sizeof(Sphere) * SPHERES );在把变量复制到常量内存后释放内存free( temp_s ); 使用函数cudaMemcpyToSymbol()将变量从主机内存复制到GPU上的常量内存。（cudaMencpyHostToDevice()的cudaMemcpy()之间的唯一差异在于，cudaMemcpyToSymbol()会复制到常量内存，而cudaMemcpy()会复制到全局内存） 1.常量内存带来的性能提升与从全局内存中读取数据相比，从常量内存中读取相同的数据可以节约带宽，原因有二： 对常量内存的单次读操作可以广播到其他的“邻近”线程，这将节约15次读取操作。 常量内存的数据将缓存(cache)起来，因此对相同地址的连续读操作将不会产生额外的内存通信量。 2.线程束Warp在CUDA架构中，线程束是指一个包含32个线程的集合，这个线程集合被“编织在一起”并且以“步调一致（Lockstep）”的形式执行。在程序中的每一行，线程束中的每个线程都将在不同数据上执行相同的指令。 线程束当处理常量内存是，NVIDIA硬件将把单次内存读取操作广播到每半个线程束（Half-Warp）。在半线程束中包含了16和线程。如果在半线程束中的每个线程都从常量内存的相同地址上读取数据，那么GPU只会产生一次读取请求并在随后将数据广播到每个线程。如果从常量内存中读取大量的数据，那么这种方式生产的内存流量只是全局内存的1/16（大约6%）。 常量内存与缓存但在读取常量内存是，所节约的并不只限于减少94%的带宽。由于这块内存的内容是不会发生变化的，因此硬件将主动把这个常量数据缓存在GPU上。在第一次从常量内存的某个地址上读取后，当其他半线程束请求同一地址是，那么将命中缓存(cahce)，这同样减少了额外的内存流量。在光线追踪程序中，将球面数据保存在常量内存后，硬件只需要请求这个数据一次。在缓存数据后，其他每个线程将不会产生内存流量，原因有两个：1. 线程将在半线程结束的广播中收到这个数据。 2. 从常量内存缓存中收到数据。 负面影响当使用常量内存是，也可能对性能产生负面影响。半线程束广播功能实际是把双刃剑。虽然当所有16个线程地址都读取相同地址是，这个功能可以极大地提高性能，但当所有16个线程分别读取不同地址时，它实际上会降低性能。 3.使用事件来测试性能代码： 1234567891011121314cudaEvent_t start, stop;cudaEventCreate( &amp;start );cudaEventCreate( &amp;stop );cudaEventRecord( start, 0 );// 在GPU上执行一些工作cudaEventRecord( stop, 0 );cudaEventSynchronize( stop );float elapsedTime;cudaEventElapsedTime( &amp;elapsedTime,start, stop );printf( \"Time to generate: %3.1f ms\\n\", elapsedTime );cudaEventDestroy( start );cudaEventDestroy( stop ); 运行记录事件start时，还指定了第二个参数。cudaEventRecord( start, 0 );在上面代码中为0，流(Stream)的编号。 当且仅当GPU完成了之间的工作并且记录了stop事件后，才能安全地读取stop时间值。幸运的是，还有一种方式告诉CPU在某个事件上同步，这个时间API函数就是cudaEventSynchronize();,当cudaEventSynchronize返回时，我们知道stop事件之前的所有GPU工作已经完成了，因此可以安全地读取在stop保存的时间戳。 由于CUDA事件是直接在GPU上实现的，因此它们不适用于对同时包含设备代码和主机代码的混合代码计时。也就是说，你通过CUDA事件对核函数和设备内存复制之外的代码进行计时，将得到不可靠的结果。","link":"/2019/05/24/cuda/cudanote3/"},{"title":"cudanote4","text":"第七章 纹理内存 纹理内存、纹理内存实现热传导模拟 GitHub 建议下载下来用Typora软件阅读markdown文件 作者github:littlebearsama 原文链接 (建议下载Typora来浏览markdown文件) 第七章 纹理内存 纹理内存(Texture Memory)和常量内存一样，纹理内存是另外一种类型的只读内存，在特定的访问模式中，纹理内存同样能够提升性能并减少内存流量。 虽然纹理内存最初是针对传统的图形处理应用程序而设计的，但在某些GPU计算应用程序中同样非常有用。 与常量内存类似的是，纹理内存同样缓存在芯片上（利用了芯片上的缓存加速）！！！，因此在某些情况中，它能够减少对内存的请求并提供更高效的内存带宽。 纹理缓存是专门为那些在内存访问模式中存在大量空间局部性（Spatial Locality）的图形应用程序而设计的。在某个计算应用程序中，这意味着一个线程读取的位置可能与邻近的线程的读取位置非常接近 上图中，从数学角度来看，图中的四个地址并非连续的，在一般的CPU缓存模式中，这些地址将不会缓存。但由于GPU纹理内存是专门为了加速这种访问模式而设计的，因此如果在这种情况中使用纹理内存而不是全局内存，那么将获得性能提升。 使用纹理内存实现热传导模拟1.算法描述： 环境是一个矩形网格，在网格中随机散布一些”热源“，热源有着不同的固定温度（该点处的温度不会变） 在随时间递进的每个步骤中，我们假设热量在某个单元机器邻接单元之间”流动“/如果某个单元的温度比邻接单元的温度更高，那么热量将从邻接单元传导到该单元。 我们对新单元中心温度的计算方法为，将单元与邻接单元的温差相加起来，加上原有温度： 常量k表示模拟过程中热量的流动速率。k值越大，表示系统会更快地达到稳定温度，而k值越小，则温度梯度将存在更长时间。 只考虑上下左右四个邻域的话讲上述式子展开有 2.实现流程： 给定一个包含初始输入温度的网格，将其中作为热源的单元温度值复制到网格的相应单元中。这将覆盖这些单元之前计算出的温度，因此也就确保了”加热单元将保持恒温“这个条件。用下面代码中的copy_const_kernel()实现； 给定一个输入网格，用上面公式计算出输出网格。用下面代码中的blend_kernel()实现； 将输入网格和输出网格交换，为下一个计算步骤做好准备。当模拟下一个时间步时，在步骤2中计算得到的输出温度网格将成为步骤1中的输入温度网格。 3.代码：（使用的是二维纹理内存）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206#include \"cuda.h\"#include \"../common/book.h\"#include \"../common/image.h\"#define DIM 1024#define PI 3.1415926535897932f#define MAX_TEMP 1.0f#define MIN_TEMP 0.0001f#define SPEED 0.25f// these exist on the GPU sidetexture&lt;float,2&gt; texConstSrc;texture&lt;float,2&gt; texIn;texture&lt;float,2&gt; texOut;__global__ void blend_kernel( float *dst, bool dstOut ) { // map from threadIdx/BlockIdx to pixel position //线程布置是二维线程格，二维线程块时的像素坐标索引，以及数据偏置 int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; int offset = x + y * blockDim.x * gridDim.x; float t, l, c, r, b; //根据dstOut标志来看读取的输出部分的内存还是输出部分的内存 if (dstOut) { t = tex2D(texIn,x,y-1); l = tex2D(texIn,x-1,y); c = tex2D(texIn,x,y); r = tex2D(texIn,x+1,y); b = tex2D(texIn,x,y+1); } else { t = tex2D(texOut,x,y-1); l = tex2D(texOut,x-1,y); c = tex2D(texOut,x,y); r = tex2D(texOut,x+1,y); b = tex2D(texOut,x,y+1); } dst[offset] = c + SPEED * (t + b + r + l - 4 * c);}__global__ void copy_const_kernel( float *iptr ) { // map from threadIdx/BlockIdx to pixel position int x = threadIdx.x + blockIdx.x * blockDim.x;//将线程中的内部线程索引变量变成图像坐标 int y = threadIdx.y + blockIdx.y * blockDim.y; int offset = x + y * blockDim.x * gridDim.x;//计算偏移 float c = tex2D(texConstSrc,x,y); if (c != 0) iptr[offset] = c;//把热源温度复制到图像中(替换成原来的热源温度)}// globals needed by the update routinestruct DataBlock { unsigned char *output_bitmap; float *dev_inSrc; float *dev_outSrc; float *dev_constSrc; IMAGE *bitmap; cudaEvent_t start, stop; float totalTime; float frames;};// clean up memory allocated on the GPUvoid cleanup( DataBlock *d ) { cudaUnbindTexture( texIn ); cudaUnbindTexture( texOut ); cudaUnbindTexture( texConstSrc ); HANDLE_ERROR( cudaFree( d-&gt;dev_inSrc ) ); HANDLE_ERROR( cudaFree( d-&gt;dev_outSrc ) ); HANDLE_ERROR( cudaFree( d-&gt;dev_constSrc ) ); HANDLE_ERROR( cudaEventDestroy( d-&gt;start ) ); HANDLE_ERROR( cudaEventDestroy( d-&gt;stop ) );}int main( void ) { DataBlock data; IMAGE bitmap_image( DIM, DIM ); data.bitmap = &amp;bitmap_image; data.totalTime = 0; data.frames = 0; HANDLE_ERROR( cudaEventCreate( &amp;data.start ) ); HANDLE_ERROR( cudaEventCreate( &amp;data.stop ) ); int imageSize = bitmap_image.image_size(); HANDLE_ERROR( cudaMalloc( (void**)&amp;data.output_bitmap, imageSize ) ); // assume float == 4 chars in size (ie rgba) HANDLE_ERROR( cudaMalloc( (void**)&amp;data.dev_inSrc, imageSize ) ); HANDLE_ERROR( cudaMalloc( (void**)&amp;data.dev_outSrc, imageSize ) ); HANDLE_ERROR( cudaMalloc( (void**)&amp;data.dev_constSrc, imageSize ) ); //通道格式描述符 cudaChannelFormatDesc desc = cudaCreateChannelDesc&lt;float&gt;(); HANDLE_ERROR( cudaBindTexture2D( NULL, texConstSrc, data.dev_constSrc, desc, DIM, DIM, sizeof(float) * DIM ) ); HANDLE_ERROR( cudaBindTexture2D( NULL, texIn, data.dev_inSrc, desc, DIM, DIM, sizeof(float) * DIM ) ); HANDLE_ERROR( cudaBindTexture2D( NULL, texOut, data.dev_outSrc, desc, DIM, DIM, sizeof(float) * DIM ) ); // initialize the constant data float *temp = (float*)malloc( imageSize ); for (int i=0; i&lt;DIM*DIM; i++) { temp[i] = 0; int x = i % DIM; int y = i / DIM; if ((x&gt;300) &amp;&amp; (x&lt;600) &amp;&amp; (y&gt;310) &amp;&amp; (y&lt;601)) temp[i] = MAX_TEMP; } temp[DIM*100+100] = (MAX_TEMP + MIN_TEMP)/2; temp[DIM*700+100] = MIN_TEMP; temp[DIM*300+300] = MIN_TEMP; temp[DIM*200+700] = MIN_TEMP; for (int y=800; y&lt;900; y++) { for (int x=400; x&lt;500; x++) { temp[x+y*DIM] = MIN_TEMP; } } HANDLE_ERROR( cudaMemcpy( data.dev_constSrc, temp, imageSize, cudaMemcpyHostToDevice ) ); // initialize the input data for (int y=800; y&lt;DIM; y++) { for (int x=0; x&lt;200; x++) { temp[x+y*DIM] = MAX_TEMP; } } HANDLE_ERROR( cudaMemcpy( data.dev_inSrc, temp, imageSize, cudaMemcpyHostToDevice ) ); free( temp ); int ticks=0; bitmap_image.show_image(30); while(1) { HANDLE_ERROR( cudaEventRecord( data.start, 0 ) ); dim3 blocks(DIM/16,DIM/16); dim3 threads(16,16); IMAGE *bitmap = data.bitmap; // since tex is global and bound, we have to use a flag to // select which is in/out per iteration volatile bool dstOut = true; for (int i=0; i&lt;90; i++) { float *in, *out; if (dstOut) { in = data.dev_inSrc; out = data.dev_outSrc; } else { out = data.dev_inSrc; in = data.dev_outSrc; } copy_const_kernel&lt;&lt;&lt;blocks,threads&gt;&gt;&gt;( in ); blend_kernel&lt;&lt;&lt;blocks,threads&gt;&gt;&gt;( out, dstOut ); dstOut = !dstOut; } float_to_color&lt;&lt;&lt;blocks,threads&gt;&gt;&gt;( data.output_bitmap, data.dev_inSrc ); HANDLE_ERROR( cudaMemcpy( bitmap-&gt;get_ptr(), data.output_bitmap, bitmap-&gt;image_size(), cudaMemcpyDeviceToHost ) ); HANDLE_ERROR( cudaEventRecord( data.stop, 0 ) ); HANDLE_ERROR( cudaEventSynchronize( data.stop ) ); float elapsedTime; HANDLE_ERROR( cudaEventElapsedTime( &amp;elapsedTime, data.start, data.stop ) ); data.totalTime += elapsedTime; ++data.frames; printf( \"Average Time per frame: %3.1f ms\\n\", data.totalTime/data.frames ); ticks++; char key = bitmap_image.show_image(30); if(key==27) { break; } } cleanup(&amp;data); return 0;} 4.代码解析（下面是使用一维纹理内存的解析） 1.申请纹理内存：使用了浮点类型纹理内存的引用；纹理内存必须声明为文件作用域内的全局变量！ 1234//这些变量位于GPU上texture&lt;float&gt; texConstSrc;texture&lt;float&gt; texIn;texture&lt;float&gt; texOut; 2.申请GPU全局内存：下面代码为这三个缓存区分配了GPU内存（全局内存）,data.dev_inSrc等三个指针已经在结构对象data中声明了。 123456HANDLE_ERROR( cudaMalloc( (void**)&amp;data.dev_inSrc, imageSize ) );HANDLE_ERROR( cudaMalloc( (void**)&amp;data.dev_outSrc, imageSize ) );HANDLE_ERROR( cudaMalloc( (void**)&amp;data.dev_constSrc, imageSize ) ); 3.纹理内存与GPU全局内存绑定：需要通过cudaBindTexture()将这些变量（上面的纹理内存引用）绑定到内存缓冲区。相当于告诉CUDA运行时两件事情： a. 指定的缓冲区作为纹理来使用 b.纹理引用作为纹理的”名字” 123456789HANDLE_ERROR( cudaBindTexture( NULL, texConstSrc, data.dev_constSrc, imageSize ) );HANDLE_ERROR( cudaBindTexture( NULL, texIn, data.dev_inSrc, imageSize ) );HANDLE_ERROR( cudaBindTexture( NULL, texOut, data.dev_outSrc, imageSize ) ); 4.使用内置函数tex1Dfetch()：当读取核函数中的纹理时，需要通过特殊的函数来告诉GPU将读取请求转发到纹理内存而不是标准的全局内存。tex1Dfetch()它是一个编译器内置函数（Instrinsic）。 5.使用二维纹理内存：性能与一维的基本相同，但代码更简单。在使用内置函数tex2Dfetch()，读取缓存区中的数据时，不用计算缓存区中的线性偏置，而是可以直接用计算的像素索引x，y，这样使得代码更为简洁，并且能自动处理边界问题。 6.通道格式描述符：在绑定二维纹理内存时，CUDA运行时要求提供一个cudaChanelFormatDesc()。在二维纹理内存的代码包含了一个对通道格式描述符的声明(Channel Format Descriptor)。在这里可以使用默认的参数，并且只要指定需要的是一个浮点描述符。然后我们通过1.cudaBindTexture2D(),2.纹理内存的位数（DIMXDIM）以及3.通道格式描述（desc）将这三个输入缓冲区绑定为二维纹理，main()函数其他部分保持不变。 纹理采样器（Texture Sampler），找不到该部分的内容？如果使用了纹理采样器自动执行某种转换，那么纹理内存还能带来额外的加速。","link":"/2019/05/24/cuda/cudanote4/"},{"title":"GIT教程","text":"[TOC] GIT—版本管理器参考 一、基本概念git—饭桶 git和svn同为版本管理工具，区别是什么 svn是集中式版本管理工具，必须装一个svn服务器，通过svn服务器集中管理代码。每个客户端通过svn服务器来提交，下载代码，每个客户端都是和服务器直接进行交互的。缺点是服务器单点故障（也不算缺点），容错性差。 git是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 二、Git工作流程一般工作流程如下： 1．git clone，从远程仓库中克隆 Git 资源作为本地仓库。 2．git checkout，从本地仓库中checkout代码然后进行代码修改 3．git add，在提交前先将代码提交到暂存区。 4．git commit，提交修改。提交到本地仓库。本地仓库中保存修改的各个历史版本。git和svn最大的区别是，Git有一个本地仓库的概念。 5．git push，在修改完成后，需要和团队成员共享代码时，可以将代码push到远程仓库。 下图展示了 Git 的工作流程： 三、使用Git管理文件版本0. 安装git 下载git，安装 安装tortoisegit（GUI），勾选使用OpenSS，Git default Client。指定git.exe所在的目录。 1. 创建版本库有目录D:\\codes\\repositories，在该路径下创建文件夹repo1 创建本地仓库：git init 2. 添加文件 向本地版本库添加文件，在git文件夹同等级上面添加文件。 本地仓库：包含git文件夹的文件夹，即D:\\codes\\repositories\\repo1 版本库：.git隐藏文件夹，将来文件都需要保存到版本库中。Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 工作目录（仓库目上一级）：D:\\codes\\repositories 工作区：repositories文件夹就是一个工作区。 然后用乌龟添加（相当于git add），相当于将这个文件加入到暂存区了。创建了一个本地仓库一定会有一个主分支master， 向本地仓库提交（git commit），一定要写日志，实际上就是把暂存区的所有内容提交到当前分支。 3. 修改文件 可以通过“显示日志“来查看修改。 差异比较 当文件内容修改后，需要和修改之前对比一下修改了哪些内容此时可以使用“比较差异功能”来确认文件的最终版本。 还原修改 当文件修改后不想把修改的内容提交，还想还原到未修改之前的状态。此时可以使用“还原”功能，此操作会撤销所有未提交的修改，所以当做还原操作是需要慎重慎重。 使用乌龟或者visual stdio右下角的还原都会将选中修改的文件还原成未修改前的样子。 4. 删除本地仓库中的文件 通过版本库浏览器可以知道本地仓库有什么 可以将删除的文件通过对比版本库还原回来 删除并保留本地副本，然后提交：从本地版本库删除文件，但是本地还将文件保留下来了。—-用于提交工程的时候不提交无关的文件。 5. 忽略提交的文件 忽略文件或文件夹 并不是所有文件都需要保存到版本库中的例如“bin”目录及目录下的文件就可以忽略。好在Git考虑到了大家的感受，这个问题解决起来也很简单，在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 忽略文件语法规范 空行或是以 # 开头的行即注释行将被忽略。 可以在前面添加正斜杠 / 来避免递归,下面的例子中可以很明白的看出来与下一条的区别。 可以在后面添加正斜杠 / 来忽略文件夹，例如 build/ 即忽略build文件夹。 可以使用 ! 来否定忽略，即比如在前面用了 *.apk ，然后使用 !a.apk ，则这个a.apk不会被忽略。 * 用来匹配零个或多个字符，如 *.[oa] 忽略所有以”.o”或”.a”结尾， *~ 忽略所有以 ~ 结尾的文件（这种文件通常被许多编辑器标记为临时文件）； [] 用来匹配括号内的任一字符，如 [abc] ，也可以在括号内加连接符，如 [0-9] 匹配0至9的数； ? 用来匹配单个字符。 看了这么多，还是应该来个栗子： # 忽略 .a 文件: *.a # 但否定忽略 lib.a, 尽管已经在前面忽略了 .a 文件: !lib.a # 仅在当前目录下忽略 TODO 文件， 但不包括子目录下的 subdir/TODO: /TODO # 忽略 build/ 文件夹下的所有文件: build/ # 忽略 doc/notes.txt, 不包括 doc/server/arch.txt: doc/*.txt # 忽略所有的 .pdf 文件 在 doc/ directory 下的: doc/**/*.pdf 6. 提交代码 将代码添加到master分支上，其中.gitignore文件也需要添加到暂存区，然后提交到版本库。 四、远程仓库现在我们已经在本地创建了一个Git仓库，又想让其他人来协作开发，此时就可以把本地仓库同步到远程仓库，同时还增加了本地仓库的一个备份。 常用的远程仓库就是github：https://github.com/，接下来我们演示如何将本地代码同步到github。 1. github/码云创建远程仓库 在github上面创建账号并且新建一个仓库 github支持两种同步方式“https”“ssh”，https每次提交代码和下载代码都需要输入用户名和密码 使用ssh只需要在客户端先生成一个密钥对，及一个公钥“id_rsa”和一个私钥”id_rsa.pub”。 先生成密钥对，没有后缀的是私钥，不要告诉任何人，有后缀的是公钥，可以告诉其他人（github服务器），在服务器中添加公钥。 1ssh-keygen -t rsa 2. 同步本地仓库到远程将本地仓库与远程仓库建立联系，并将本地仓库代码推送到远程仓库。 123456jhluo@laptop-xiaoxiong MINGW64 /d/codes/repositories/repo1 (master)$ git remote add origin git@github.com:littlebearsama/repo1.gitjhluo@laptop-xiaoxiong MINGW64 /d/codes/repositories/repo1 (master)$ git push -u origin master origin 指的就是远程仓库，非本地仓库，在命令行命令中出现的 origin ，指操作是对远程仓库操作 origin指向的是repository，master只是这个repository中默认创建的第一个branch。(git push origin master )当你git push的时候因为origin和master都是默认创建的。 如果出现如下错误： 可以先执行命令 git remote rm origin，然后再执行上面的命令。 3. 从远程仓库克隆克隆远程仓库也就是从远程把仓库复制一份到本地，克隆后会创建一个新的本地仓库。选择一个任意部署仓库的目录，然后克隆远程仓库。 git clone git@github.com:littlebearsama/repo1.git 4. 从远程仓库取代码 git fetch :获取。相当于是从远程获取最新版本到本地，不会自动merge（合并代码） git pull：拉取。相当于是从远程获取最新版本并merge到本地 5. 搭建私有git服务器5.1 服务器搭建远程仓库实际上和本地仓库没啥不同，纯粹为了7x24小时开机并交换大家的修改。GitHub就是一个免费托管开源代码的远程仓库。但是对于某些视源代码如生命的商业公司来说，既不想公开源代码，又舍不得给GitHub交保护费，那就只能自己搭建一台Git服务器作为私有仓库使用。（现在仓库可以免费设为私有了），搭建Git服务器需要准备一台运行Linux的机器，在此我们使用CentOS。以下为安装步骤： 1、安装git服务环境准备 yum -y install curl curl-devel zlib-devel openssl-devel perl cpio expat-devel gettext-devel gcc cc 2、下载git-2.5.0.tar.gz 1）解压缩 2）cd git-2.5.0 3）autoconf 4）./configure 5）make 6）make install 3、添加用户 adduser -r -c ‘git version control’ -d /home/git -m git 此命令执行后会创建/home/git目录作为git用户的主目录。 5、设置密码 passwd git 输入两次密码 6、切换到git用户 su git 7、创建git仓库 git –bare init /home/git/first 注意：如果不使用“–bare”参数，初始化仓库后，提交master分支时报错。这是由于git默认拒绝了push操作，需要.git/config添加如下代码： [receive] denyCurrentBranch = ignore 推荐使用：git –bare init初始化仓库。 5.2 连接服务器私有git服务器搭建完成后就可以向连接github一样连接使用了，但是我们的git服务器并没有配置密钥登录，所以每次连接时需要输入密码。 使用命令连接： $ git remote add origin ssh://git@192.168.25.156/home/git/first 这种形式和刚才使用的形式好像不一样，前面有ssh://前缀，好吧你也可以这样写： $ git remote add origin git@192.168.25.156:first 使用TortoiseGit同步的话参考上面的使用方法。 五、分支管理1. 创建并合并分支在我们每次的提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD指针严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。 一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点： 每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长。 当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： 你看，Git创建一个分支很快，因为除了增加一个dev指针，改改HEAD的指向，工作区的文件都没有任何变化！不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： 所以Git合并分支也很快！就改改指针，工作区内容也不变！ 合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 2. 使用tortoisegit实现分支管理 创建分支 使用TortoiseGit管理分支就很简单了。在本地仓库文件夹中点击右键，然后从菜单中选择“创建分支”： 如果想创建完毕后直接切换到新分支可以勾选“切换到新分支”选项或者从菜单中选择“切换/检出”来切换分支： 合并分支 分支切换到dev后就可以对工作区的文件进行修改，然后提交到dev分支原理的master分支不受影响。例如我们修改mytest.txt中的内容，然后提交到dev分支。 切换回master分支后，master分支还是原来的内容。 将dev分支的内容合并到master分支，当前分支为master。从右键菜单中选择“合并”： 相当于git merge xiaoxiong 3. 解决冲突两个分支中编辑的内容都是相互独立互不干扰的，那么如果在两个分支中都对同一个文件进行编辑，然后再合并，就有可能会出现冲突。冲突需要手动解决。使用乌龟选择文件冲突部分的要保留的代码。 六、命令与基本操作流程1. 命令查表 git clone 克隆整个仓库 将本地仓库和远程仓库关联 git remote add origin “ssh:……..git” git checkout 建立远端分支 git checkout -b xiaoxiong 在当前分之下（一般是master分支），创建xiaoxiong本地分支 git push origin xiaoxiong::xiaoxiong 将本地分支推送到远程 创建本地分支AAA并且与远端分支关联起来 git checkout -b xiaoxiongorigin/xiaoxiong 啊 git branch 查看所有分支（包括远端分支） git branch -a 删除远端分支 git branch -r -d origin/AAA 删除本地分支 git branch -D AAA 将本地分支xiaoxiong和远端分支xiaoxiong关联起来 git branch —track xiaoxiong origin/xiaoxiong 啊啊 git add git commit git reset 撤销上一步的git add添加的文件filename git reset HEAD filename 撤销上一步的git commit git reset –hard HEAD^ 撤销】】 git list 查看当前仓库当前目录下的所有文件 git ls-files git pull git merge git push，参考 git push的一般形式为 git push &lt;远程主机名&gt; &lt;本地分支名&gt; &lt;远程分支名&gt; ，例如 git push origin master：refs/for/master ， 即是将本地的master分支推送到远程主机origin上的对应master分支， origin 是远程主机名， 第一个master是本地分支名，第二个master是远程分支名。 与远程分支建立连接 git push --set-upstream origin xiaoxiong git remote，参考 git remote 不带参数，列出已经存在的远程分支 git remote -v | –verbose 列出详细信息，在每一个名字后面列出其远程url，此时， -v 选项(译注:此为 –verbose 的简写,取首字母),显示对应的克隆地址。 git remote add url 添加一个远程仓库 2. 基本操作流程","link":"/2020/07/05/other/git/"},{"title":"howtowriteaCUDAprogram","text":"学习资源 简单总结如何写一个CUDA程序 CUDA自带的库 建议下载下来用Typora软件阅读markdown文件 A.学习资源 官方文档(安装cuda时自带的) 自带例程 例程中文介绍：CUDA Samples CUDA书籍与博客 书籍 博客 B.CUDA并行计算原理CUDA程序运行可以简单理解为：主机代码在CPU中运行，在调用__device__和__global__核函数时，进入GPU运行（此时并不会中断主机代码的运行，除非在等待GPU出结果）。此时在设备中每个线程执行一个核函数。 C.CUDA程序编写步骤一、编写GPU运行的核函数 根据数据的个数与数据形式（二维图像？三维点云？）来考虑线程配置。 在二维中： 12dim3 blocks(DIM/16,DIM/16);dim3 threads(16,16); 核函数参数一般为： 输入数组(指针形式) 数组大小 输出数组(指针形式) 核函数中，根据线程布置来确定线程索引tid。而在二维线程格和二维线程块中，数据索引根据图像的xy坐标来确定。 1234&gt; int x = threadIdx.x + blockIdx.x * blockDim.x;&gt; int y = threadIdx.y + blockIdx.y * blockDim.y;&gt; int offset = x + y * blockDim.x * gridDim.x;&gt; 核函数中，设置线程索引判断条件,检测当前线程是否要工作while (tid &lt; N)或if (tid &lt; N)。 然后添加该线程执行的运算/函数。 当数据大于运行线程时，在核函数中，添加语句tid+=blockDim.x*gridDim.x;增加的值等于每个线程块中的线程数量乘以线程网格中线程块的数量，在一维的线程格，一维的线程块线程分配中为blockDim.x*gridDim.x 二、给数据在GPU中分配内存GPU内存类型：1.全局内存GPU中用cudaMalloc()申请的GPU全局内存 2.共享内存 简介 规约运算是在核函数申请的共享内存。 通过共享内存实现block内的线程通信，实现通信前要进行线程同步，否则会发生竞态条件，但是block和block之间的线程是无法互相通信的。 细节 使用该语句申请共享内存：__shared__ float cache[threadsPerBlock]; 将关键字__share__添加到变量声明中，这将是这个变量驻留在共享内存中。在访问共享内存时的延迟要远远低于访问普通缓存区的延迟，使得共享内存像每个线程块的高速缓存或中间结果暂存器那样高效 每次对共享内存的数据进行操作时都要对线程块内的线程同步：__syncthreads(); 例程 规约运算 3.常量内存-只读内存 简介 常量内存用于保存在核函数执行期间不会发生变化的数据。 与从全局内存中读取数据相比，从常量内存中读取相同的数据可以节约带宽，原因有二： 对常量内存的单次读操作可以广播到其他的“邻近”线程，这将节约15次读取操作。 常量内存的数据将缓存(cache)起来，因此对相同地址的连续读操作将不会产生额外的内存通信量。 细节 在核函数外面，使用该语句申请常量内存：__constant__ Sphere s[SPHERES]; 常量内存为静态分配空间，所以不需要调用 cudaMalloc(), cudaFree() 应用 在光线追踪的程序中，将球面数组存入常量内存中。注意，处理图像使用二维的线程块和线程格。 4.纹理内存-只读内存 简介 纹理内存(Texture Memory)和常量内存一样，纹理内存是另外一种类型的只读内存，在特定的访问模式中，纹理内存同样能够提升性能并减少内存流量。 纹理内存同样缓存在芯片上（利用了芯片上的缓存加速）！！！ ！重点：纹理缓存是专门为那些在内存访问模式中存在大量空间局部性（Spatial Locality）的图形应用程序而设计的。在某个计算应用程序中，这意味着一个线程读取的位置可能与邻近的线程的读取位置非常接近。 比如在模拟热传导，计算温度时dst[offset] = c + SPEED * (t + b + r + l - 4 * c);参考了近邻像素的内容，那么这时后使用纹理内存能够加速读取数据。 细节 纹理内存有一维和二维，两者性能基本相同，但是使用二维的代码更简单 在核函数外面申请纹理内存，texture&lt;float,2&gt; texConstSrc; 需要申请全局内存用于和纹理内存进行绑定 应用 在使用纹理内存实现热传导模拟的程序中，1.初始的输入温度的网格，2.输入温度网格，3.输出温度网格都使用纹理内存。 申请GPU内存：1234567891011121314151617int a[N], b[N], c[N];int *dev_a, *dev_b, *dev_c;// 申请GPU全局内存cudaMalloc( (void**)&amp;dev_a, N * sizeof(int) );cudaMalloc( (void**)&amp;dev_b, N * sizeof(int) );cudaMalloc( (void**)&amp;dev_c, N * sizeof(int) ); // 申请共享内存__shared__ float cache[threadsPerBlock];//核函数中// 申请GPU常量内存__constant__ Sphere s[SPHERES]// 申请纹理内存texture&lt;float,2&gt; texConstSrc;texture&lt;float,2&gt; texIn;texture&lt;float,2&gt; texOut; 拷贝内存：情况一：将主机内存拷贝到GPU全局内存上 1234cudaMemcpy( dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice );cudaMemcpy( dev_b, b, N * sizeof(int), cudaMemcpyHostToDevice ); 情况二：使用GPU常量内存时，将数据拷贝到GPU常量内存上 12345678910111213// 分配临时内存，对其初始化，并复制到GPU上的常量内存，然后释放临时内存Sphere *temp_s = (Sphere*)malloc( sizeof(Sphere) * SPHERES );for (int i=0; i&lt;SPHERES; i++) { temp_s[i].r = rnd( 1.0f ); temp_s[i].g = rnd( 1.0f ); temp_s[i].b = rnd( 1.0f ); temp_s[i].x = rnd( 1000.0f ) - 500; temp_s[i].y = rnd( 1000.0f ) - 500; temp_s[i].z = rnd( 1000.0f ) - 500; temp_s[i].radius = rnd( 100.0f ) + 20; }cudaMemcpyToSymbol( s, temp_s, sizeof(Sphere) * SPHERES)；free( temp_s ); 情况三：全局内存绑定纹理内存 1234//申请全局内存用于绑定纹理内存cudaMalloc( (void**)&amp;data.dev_inSrc,imageSize );//纹理内存与GPU全局内存绑定cudaBindTexture( NULL, texConstSrc,data.dev_constSrc,imageSize ) 三、执行核函数、拷贝内存、释放内存执行核函数12345678910//一维add&lt;&lt;&lt;N,1&gt;&gt;&gt;( dev_a, dev_b, dev_c );//。。。//处理二维图像//图像有DIMXDIM个像素//启动DIM/16 x DIM/16个线程块，使得每个像素对应一个线程dim3 blocks(DIM/16,DIM/16);dim3 threads(16,16);kernel&lt;&lt;&lt;blocks,threads&gt;&gt;&gt;( data.dev_bitmap, ticks ); 拷贝内存将存在设备内存的结果拷贝到主机内存中 1cudaMemcpy( c, dev_c, N * sizeof(int),cudaMemcpyDeviceToHost ); 释放内存释放申请的主机内存和设备内存 123cudaFree( dev_a );cudaFree( dev_b );cudaFree( dev_c ); D.利用好CUDA自带的库以及性能原语","link":"/2019/06/13/cuda/howtowriteaCUDAprogram/"},{"title":"glfw相关知识以及与cuda之间的互操作","text":"OpenGL与CUDA互操作 OpenGL与CUDA互操作0. 基本概念：VBO：顶点缓冲对象（Vertex Buffer Objects，VBO）顶点缓冲对象VBO是在显卡存储空间中开辟出的一块内存缓存区，用于存储顶点的各类属性信息，如顶点坐标，顶点法向量，顶点颜色数据等。在渲染时，可以直接从VBO中取出顶点的各类属性数据，由于VBO在显存而不是在内存中，不需要从CPU传输数据，处理效率更高。 所以可以理解为VBO就是显存中的一个存储区域，可以保持大量的顶点属性信息。并且可以开辟很多个VBO，每个VBO在OpenGL中有它的唯一标识ID，这个ID对应着具体的VBO的显存地址，通过这个ID可以对特定的VBO内的数据进行存取操作。 VBO的创建以及配置 创建VBO的第一步需要开辟（声明/获得）显存空间并分配VBO的ID： 123//创建vertex buffer object对象GLuint vboId;//vertex buffer object句柄glGenBuffers(1, &amp;vboId); 1.openGL的基本使用12345678//被init()调用void errorCallback(int error, const char *description);void keyCallback(GLFWwindow* window, int key, int scancode, int action, int mods);//键盘响应void mouseButtonCallback(GLFWwindow* window, int button, int action, int mods);//鼠标按键响应void mousePositionCallback(GLFWwindow* window, double xpos, double ypos);//鼠标位置响应void updateCamera();void initVAO();void initShaders(GLuint *program); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647bool init(){ //初始化前设置错误回调函数 glfwSetErrorCallback(errorCallback); //调用glfwInit函数，初始化glfw，在程序终止之前，必须终止glfw，这个函数只能在主线程上被调用 if (!glfwInit()) { std::cout &lt;&lt; \"Error: Could not initialize GLFW!\" &lt;&lt; \" Perhaps OpenGL 3.3 isn't available?\" &lt;&lt; std::endl; return false; } //在创建窗口之前调用glfwWindowHint，设置一些窗口的信息 //这些hints，设置以后将会保持不变，只能由glfwWindowHint、glfwDefaultWindowHints或者glfwTerminate修改。 glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //如果创建window失败则终结glfw，指定尺寸 //(int width, int height, const char* title, GLFWmonitor* monitor, GLFWwidnow* share); window = glfwCreateWindow(width, height, windowName.c_str(), NULL, NULL); if (!window) { glfwTerminate();//glfwTerminate会销毁窗口释放资源，因此在调用该函数后，如果想使用glfw库函数，就必须重新初始化 return false; } // glfwMakeContextCurrent(window); glfwSetKeyCallback(window, keyCallback); glfwSetCursorPosCallback(window, mousePositionCallback); glfwSetMouseButtonCallback(window, mouseButtonCallback); glewExperimental = GL_TRUE; if (glewInit() != GLEW_OK) { return false; } // 初始化绘图状态 initVAO(); //互操作 cudaGLSetGLDevice(0);//设置CUDA环境 //用cuda登记缓冲区 cudaGLRegisterBufferObject(pointVBO_positions);//pointVBO_positions=0 cudaGLRegisterBufferObject(pointVBO_velocities);//pointVBO_velocities=0 updateCamera(); initShaders(program); glEnable(GL_DEPTH_TEST); return true;} 12345678910111213141516171819202122void loop(){ double fps = 0; double timebase = 0; int frame = 0; //返回指定窗口是否关闭的flag变量，可以在任何线程中被调用。 while (!glfwWindowShouldClose(window) &amp;&amp; !BreakLoop) { //这个函数主要用来处理已经在事件队列中的事件，通常处理窗口的回调事件，包括输入，窗口的移动，窗口大小的改变等， //回调函数可以自己手动设置，比如之前所写的设置窗口大小的回调函数；如果没有该函数，则不会调用回调函数，同时也不会接收用户输入，例如接下来介绍的按键交互就不会被响应； glfwPollEvents(); frame++; double time = glfwGetTime();//当前时间 if (time - timebase &gt; 1.0) { fps = frame / (time - timebase); timebase = time; frame = 0; } runcuda();//更新点云 endrun(); }} 123456789101112131415161718void runcuda(){ // Map OpenGL buffer object for writing from CUDA on a single GPU // No data is moved (Win &amp; Linux). When mapped to CUDA, OpenGL should not // use this buffer float4 *dptr = NULL; float *dptrVertPositions = NULL; float *dptrVertVelocities = NULL; cudaGLMapBufferObject((void**)&amp;dptrVertPositions, pointVBO_positions); cudaGLMapBufferObject((void**)&amp;dptrVertVelocities, pointVBO_velocities); // float c_scale = 1; //自己定义的复制函数 copyPointsToVBO(dptrVertPositions, dptrVertVelocities, numObjects_fixed, numObjects_rotated, blockSize, c_scale);//显存里面的数据相互赋值 // 解除yi cudaGLUnmapBufferObject(pointVBO_positions); cudaGLUnmapBufferObject(pointVBO_velocities);} 123456789101112131415void endrun(){ glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glUseProgram(program[PROG_POINT]); glBindVertexArray(pointVAO); glPointSize((GLfloat)pointSize); glDrawElements(GL_POINTS, N + N2 + 1, GL_UNSIGNED_INT, 0); glPointSize(1.0f); glUseProgram(0); glBindVertexArray(0); glfwSwapBuffers(window);//opengl采用双缓冲机制，该函数用于交换前后颜色缓冲区的内容 glfwDestroyWindow(window); glfwTerminate();} 2. opengl和cuda互操作基本原理CUDA和OpenGL互操作的过程CUDA和OpenGL互操作具体步骤如下： 1) 创建窗口及OpenGL运行环境。 2) 设置OpenGL视口和坐标系。要根据绘制的图形是2D还是3D等具体情况设置。(1)和(2)是所有OpenGL程序必需的，这里也没什么特殊之处，需要注意的是，后面的一些功能需要OpenGL 2.0及以上版本支持，所以在这里需要进行版本检查。 3)创建CUDA环境。可以使用cuGLCtxCreate或cudaGLSetGLDevice来设置CUDA环境。该设置一定要放在其他CUDA的API调用之前。 4)产生一个或多个OpenGL缓冲区用以和CUDA共享。使用PBO和使用VBO差不多，只是有些函数调用参数不同。以下是具体过程。 (5)用CUDA登记缓冲区。登记可以使用cuGLRegisterBufferObject或cudaGLRegisterBufferObject，该命令告诉OpenGL和CUDA 驱动程序该缓冲区为二者共同使用。 (6)将OpenGL缓冲区映射到CUDA内存。可以使用cuGLMapBufferObject或cudaGLMapBufferObject，它实际是将CUDA内存的指针指向OpenGL的缓冲区，这样如果只有一个GPU，就不需要数据传递。当映射完成后，OpenGL不能再使用该缓冲区。 (7)使用CUDA往该映射的内存写图像数据。前面的准备工作在这里真正发挥作用了，此时可以调用CUDA的kernel，像使用全局内存一样使用映射了的缓冲区，向其中写数据。 (8)取消OpenGL缓冲区映射。要等前面CUDA的活动完成以后，使用cuGLUnmapBufferObject或cudaGLUnmapBufferObject函数取消映射。 (9)前面的步骤完成以后就可以真正开始绘图了， OpenGL的PBO和VBO的绘图方式不同，分别为以下两个过程。 ①如果只是绘制平面图形，需要使用OpenGL的PBO及纹理。 glEnable(GL_TEXTURE_2D)； //使纹理可用glGenTextures(1，&amp;textureID)； //生成一个textureIDglBindTexture(GL_TEXTURE_2D，textureID)；//使该纹理成为当前可用纹理glTexImage2D(GL_TEXTURE_2D，0，GL_RGBA8，Width， Height，0，GL_BGRA，GL_UNSIGNED_BYTE，NULL)；//分配纹理内存。最后的参数设置数据来源，这里设置为NULL，表示数据来自PBO，不是来自主机内存glTexParameteri(GL_TEXTURE_2D，GL_TEXTURE_MIN FILTER，GL_LINEAR)；glTexParameteri(GL_TEXTURE_2D，GL_TEXTURE_MAG FILTER，GL_LINEAR)；//必须设置滤波模式，GL_LINEAR允许图形伸缩时线性差值。如果不需要线性差值，可以用GL_TEXTURE_RECTANGLE_ARB代替GL_TEXTURE_2D以提高性能，同时在glTexParameteri()调用里使用GL_NEAREST替换GL_LINEAR然后就可以指定4个角的纹理坐标，绘制长方形了。 ②绘制3D场景，需要使用VBO。glEnableClientState(GL_VERTEX_ARRAY)；//使顶点和颜色数组可用glEnableClientState(GL_COLOR_ARRAY)；glVertexPointer(3，GL_FLOAT，16，0)；//设置顶点和颜色指针glColorPointer(4，GL_UNSIGNED_BYTE，16，12)；glDrawArrays(GL_POINTS，0，numVerticies)；//根据顶点数据绘图，参数可以使用GL_LINES， GL_LINE_STRIP， GL_LINE_LOOP， GL_TRIANGLES，GL_TRIANGLE_STRIP， GL_TRIANGLE_FAN， GL_QUADS，GL_QUAD_STRIP，GL_POLYGON(10)前后缓存区来回切换，实现动画显示效果。调用SwapBuffers()，缓冲区切换通常会在垂直刷新间隙来处理，因此，可以在控制面板上关掉垂直同步，使得缓冲区切换立刻进行。 3. 详细文档一、 缓冲区相关1. glGenVertexArrays：名称: glGenVertexArrays —生成顶点数组对象名称 1void glGenVertexArrays（GLsizei n， GLuint *arrays）; n 指定要生成的顶点数组对象名称的数量。 arrays指定一个数组，在其中存储生成的顶点数组对象名称。 2. glGenBuffers：generate buffer object names 该函数用来生成缓冲区对象的名称，第一个参数是要生成的缓冲区对象的数量，第二个是要用来存储缓冲对象名称的数组 1234GLuint vbo;glGenBuffers(1,&amp;vbo);GLuint vbo[3];glGenBuffers(3,vbo); 3. glBindBuffer：bind a named buffer object 第一个就是缓冲对象的类型，第二个参数就是要绑定的缓冲对象的名称，也就是我们在上一个函数里生成的名称，使用该函数将缓冲对象绑定到OpenGL上下文环境中以便使用。如果把target绑定到一个已经创建好的缓冲对象，那么这个缓冲对象将为当前target的激活对象；但是如果绑定的buffer值为0，那么OpenGL将不再对当前target使用任何缓存对象。 1void glBindBuffer(GLenum target,GLuint buffer);//函数原型 4. glBindVertexArray：绑定一个顶点数组对象 1void glBindVertexArray( GLuint array);//原型,array 指定要绑定的顶点数组的名称 描述glBindVertexArray将顶点数组对象与名称数组绑定。 array是先前从glGenVertexArrays调用返回的顶点数组对象的名称，或者为0以绑定默认的顶点数组对象绑定。 如果不存在名称为array的顶点数组对象，则在第一次绑定array时创建一个对象。 如果绑定成功，则不会更改顶点数组对象的状态，并且任何先前的顶点数组对象绑定都会中断。 错误如果array不为零或先前从调用glGenVertexArrays返回的顶点数组对象的名称，则生成GL_INVALID_OPERATION。 5. glBufferData：123456void glBufferData( GLenum target,GLsizeiptr size,const GLvoid * data,GLenum usage);//原型//用法glBufferData(GL_ARRAY_BUFFER, 4 * (2 * N) * sizeof(GLfloat), bodies.get(), GL_DYNAMIC_DRAW); // transfer data，创建和初始化一个buffer object的数据存储。 target 指定target buffer object。必须是GL_ARRAY_BUFFER or GL_ELEMENT_ARRAY_BUFFER常量。 size 指定buffer object的新data store的大小。 data 指定即将被拷贝进data store并初始化的数据的指针，或者null，如果没有data要拷贝。 usage 指定你希望data store使用的模式。必须是GL_STREAM_DRAW, GL_STATIC_DRAW, or GL_DYNAMIC_DRAW. 1.glBufferData为绑定在target上的buffer object currently创建了一个新的data store。任何之前存在的data store被删除。新创建的data store将被指定size和usage.如果data参数为NULL,data store将被这个pointer指向的data初始化。 2.usage参数提示了在GL实现中一个a buffer object’s data store将如何被访问。这使GL做出更明智的可能显著提升性能的选择。然而，如果没有，这将限制data store的准确的usage。usage可以被拆成两部分：一，被访问的频率（修改或使用），二，访问的性质。访问的频率是如下几个之一:STREAM该data store内容将被修改一次，且被使用的次数也很少； STATIC该data store内容将被修改一次，但会被多次使用； DYNAMIC该data store内容将被不断修改，且被多次使用； 访问的性质如下：DRAW该data store内容将被应用程序修改，且被当做GL渲染和图像设置命令的源数据。 6. glEnableVertexAttribArray：1234void glEnableVertexAttribArray(GLuint index);void glDisableVertexAttribArray(GLuint index);//index//指定一个将被使能或禁止的已生成的顶点属性数组的索引。 glEnableVertexAttribArray enables the generic vertex attribute array specified by index. glDisableVertexAttribArray disables the generic vertex attribute array specified by index. 默认情况下，对所有客户端都是禁止状态，包括所有已生成的顶点属性数组。当使能时，如当调用 glDrawArrays or glDrawElements这些顶点数组命令时，这些顶点属性数组将被访问和用来渲染。 7. glVertexAttribPointer：1234567void glVertexAttribPointer（GLuint index,GLint size,GLenum type,GLboolean normalized,GLsize stride,const GLvoid * pointer）;//原型 index 指定要修改的通用顶点属性的索引。 size 指定每个通用顶点属性的组件数。 必须为1,2,3或4.初始值为4。 type 指定数组中每个组件的数据类型。 接受符号常量GL_BYTE，GL_UNSIGNED_BYTE，GL_SHORT，GL_UNSIGNED_SHORT，GL_FIXED或GL_FLOAT。 初始值为GL_FLOAT。 normalized 指定在访问定点数据值时是应将其标准化（GL_TRUE）还是直接转换为定点值（GL_FALSE）。 stride 指定连续通用顶点属性之间的字节偏移量。 如果stride为0，则通用顶点属性被理解为紧密打包在数组中的。 初始值为0。 pointer 指定指向数组中第一个通用顶点属性的第一个组件的指针。 初始值为0。 缓冲区对象只是OpenGL众多对象中的一种，其实当我们使用其它对象时，都是类似的思路 12345GLuint vbo;glGenObject(1,&amp;vbo);GLuint vbo[3];glGenObject(3,vbo);glBindObject(GL_WINDOW_TARGET,vbo[1]); 创建对象，绑定类型，设置数据。 二、1. glutMainLoopglutLeaveMainLoop() 2. glUseProgramglUseProgram- 使用程序对象作为当前渲染状态的一部分 void glUseProgram（GLuint program）; 参数 program 指定程序对象的句柄，该程序对象的可执行文件将用作当前渲染状态的一部分。 三、线程相关GLFWthread glfwCreateThread( GLFWthreadfun fun, void *arg ) A thread can wait for another thread to die with the command glfwWaitThread: int glfwWaitThread( GLFWthread ID, int waitmode ) 终止一个线程 void glfwDestroyThread( GLFWthread ID ) 产生互斥锁 GLFWmutex glfwCreateMutex( void ) 终止 void glfwDestroyMutex( GLFWmutex mutex ) 上锁 void glfwLockMutex( GLFWmutex mutex ) 解锁 void glfwUnlockMutex( GLFWmutex mutex ) 这个是等待状态变量 void glfwWaitCond( GLFWcond cond, GLFWmutex mutex, double timeout ) void glfwSignalCond( GLFWcond cond ) void glfwBroadcastCond( GLFWcond cond )","link":"/2021/03/30/OPENGL/GLFW_N_CUDA/"},{"title":"compute-transform","text":"计算刚体变换矩阵 问题：已知有对应点对(correspondence; point pairs)P、Q集合，求解PQ之间的刚体变换矩阵 参考1: 求解刚体旋转平移关系–配准 参考2: SVD Least-Squares Rigid Motion Using SVD 3D3D算变换矩阵 1.待定系数法 容易得到超定方程组，利用最小二乘法求解超定方程组 由于输入数据的误差，导致算出来不是一个正交的旋转矩阵 每一个一一对应点满足： 对于第 个一一对应点得到方程组: 同理将所有一一对应点的方程组合并, 得到超定方程： 利用最小二乘法求解 得到向量 , 写为矩阵形式即 . 缺点: 在有原始数据误差或者计算累积误差情况下, 得到的矩阵 不一定严格满足正交矩阵. 2.Levenberg-Marquardt方法求解（非线性） 输入变量从旋转矩阵R转为欧拉角R( , , )。 将非线性问题转化为线性优化。 使用信赖域法求极值。 旋转矩阵具有3个自由度, 可以理解为3个Euler角可确定一个旋转状态, 或一个四元数(范数为1, 自由度为4-1=3)可确定一个旋转状态. 可利用 作为非线性拟合的参数, 旋转矩阵 由 唯一确定, 并使得在该参数下误差最小, 即: 得到即得到旋转矩阵 , , 该方法可保证该矩阵严格为正交矩阵. 缺点: Levenberg-Marquardt方法一方面对该优化问题的初值有一定要求, 另一方面非线性算法的效率较低. LM算法原理LM算法，全称为Levenberg-Marquard算法，它可用于解决非线性最小二乘问题，多用于曲线拟合等场合。 它的关键是用模型函数 对待估参数向量 在其邻域内做线性近似，忽略掉二阶以上的导数项，从而转化为线性最小二乘问题. 它具有收敛速度快等优点。 LM算法属于一种“信赖域法”——所谓的信赖域法，此处稍微解释一下：在最优化算法中，都是要求一个函数的极小值，每一步迭代中，都要求目标函数值是下降的，而信赖域法，顾名思义，就是从初始点开始，先假设一个可以信赖的最大位移 ，然后在以当前点为中心，以 为半径的区域内，通过寻找目标函数的一个近似函数（二次的）的最优点，来求解得到真正的位移。在得到了位移之后，再计算目标函数值，如果其使目标函数值的下降满足了一定条件，那么就说明这个位移是可靠的，则继续按此规则迭代计算下去；如果其不能使目标函数值的下降满足一定的条件，则应减小信赖域的范围，再重新求解。 3.SVD奇异值分解方法（线性） 对协方差3X3矩阵用SVD(奇异值分解)来计算旋转矩阵R Singular Value Decomposition* 1.计算两个点集的中心（重心）。将两个点集利用中心（重心），平移到原点处。 2.利用两个平移后的点集计算协方差矩阵S 3.用SVD奇异值分解方法对S进行分解获得旋转矩阵S 4.通过两个点集的中心和旋转矩阵S获得平移向量t 总结方法一(待定系数求解方程组)和方法二(LM优化方法求解)并不是求解刚体旋转矩阵 和平移矩阵 的最佳方法. 方法三中只需利用SVD分解( ( 规模数据矩阵)即可得到所需结果, 不仅过程简单而且求解精度很高. 经过一些列推导后, 我们得到最终的结果, 是不是很晕….如果对推导的过程不感兴趣的话, 可以直接看下面的计算步骤: STEP0: 已知刚性运动前后的对应点分别为 和 ), 均为 向量 STEP1: 分别计算 和 的重心(求和平均)得到 和 STEP2: 计算重心平移到原点的数据 STEP3: 矩阵形式描述 记为 , 记为 STEP4: 计算数据矩阵 并作SVD分解 STEP5: 得到旋转矩阵 STEP6: 得到平移向量 SVD原理1.旋转矩阵 具有3个自由度, 可以理解为3个Euler角可确定一个旋转状态, 或一个四元数(范数为1, 自由度为4-1=3)可确定一个旋转状态. 可利用 作为非线性拟合的参数, 旋转矩阵 由 唯一确定, 并使得在该参数下误差最小, 即: 得到 即得到旋转矩阵 , 该方法可保证该矩阵严格为正交矩阵. 缺点: Levenberg-Marquardt方法一方面对该优化问题的初值有一定要求, 另一方面非线性算法的效率较低. 方法三: Singular Value Decomposition 奇异值分解方法 通过对应点求解旋转矩阵 可写为优化问题: 可以将对应点列写为矩阵形式 3行N列 矩阵 记为 , 记为 , 则优化问题简化为: 在求解上面优化问题之前, 先回顾几个线性代数里的基本知识: 旋转(正交)矩阵的性质 ; 为 Frobenius 范数, 即矩阵所有值的平方和之方根; 其中 为矩阵的迹; 矩阵 和 均为阶, 则 ; Singular Value Decomposition (SVD)分解, 矩阵 ,其中 和 为正交矩阵, 为对角矩阵; 于是优化问题可等价为: 其中矩阵 和 由原始数据得到的矩阵, 与旋转矩阵 无关, 于是 进一步, 利用矩阵迹的性质(基本知识第4点) 使用SVD分解数据矩阵 , 其中 和 为正交矩阵, 于是 再一次使用矩阵迹的性质(基本知识第4点) 记其中的矩阵 , 不难得知 也为正交矩阵, 综上: 由于 为对角矩阵 由于 矩阵为正交矩阵, 而且正常数据下对角阵 对角元素为数据矩阵的奇异值均大于0; 而且 均小于等于1, 不难得知当 时取最大值, 即: 从而得到: 至此可以得到旋转矩阵 , 不难得到平移向量 . 2.","link":"/2019/05/24/Registration/0.compute-transformation/"},{"title":"FastICP","text":"ICP变种之一 — FastICP 超级详细分析配准步骤与影响ICP的因素，FastICP的由来与论文解读。 建议下载下来用Typora软件阅读markdown文件 点云配准流程 对应估计 穷举配准(brute force matching) kd-tree最近邻查询(第三方库FLANN) 在有序点云数据的图像空间中查找 在无序点云数据的索引空间中查找 对应关系去除由于噪声的影响，通常不是所有估计的对应关系都是正确的。由于错误的对应关系对于最终的刚体变换矩阵的估算会产生负面影响，所以必须去它们。 采用随机采样一致性估计(RANSAC,random sample consensus)或者其他方法提出错误对应关系，最终使用的对应关系数量只使用一定比例的对应关系，这样既可以提高变换矩阵的精度，也可以提高匹配速度。 计算变换矩阵compute-transform ICP 寻找点集P在中点集Q的近邻点，将近邻点作为对应点。确定一组对应点。 如何寻找近邻点？ 一般通过kdtree数据结构来查找，找到另外一个点集的最近邻点；（PCL中是通过快速近邻算法FLANN库来进行查找） 也有通过octree来查找的。 有通过互相确认两个点集之间的最近邻点（互为最近邻点），来确定对应关系。 通过上一步骤计算出来的一组对应关系计算两个对应关系点集之间的变换矩阵； 计算变换矩阵的方法有compute-transform 在ICP中采用了SVD来解算变换矩阵。 a. 计算两个点集（对应点集）的质心 b. 将两个点集通过刚刚计算出来的中心移动到原点。（计算每个点的去质心坐标） c. 将移动了的两个点集计算三乘三协方差矩阵 d. 奇异值分解协方差矩阵得到，四元数，四元数转旋转矩阵。 e. 通过旋转矩阵和中心计算平移向量。旋转矩阵和平移向量组成了本次迭代的变换矩阵 将点集通过新计算出来的变换矩阵变换到新的位置。 判断是否收敛。 如何判断是否收敛？ 重新计算对应点，新计算的对应点之间欧式距离的平方和小于某个设定值则判定为收敛。 判断是否达到迭代次数，或者达到收敛条件，达到条件则停止迭代。没有达到条件就从第二步SVD计算变换矩阵开始执行，直至达到收敛标准。 FastICPFast ICP是对ICP的改进与扩展。 论文”Efficient Variants of the ICPalgorithm”详细给出了影响ICP算法的各种因素，且每种因素都哪些算法，其结果与性能如何。 下面内容参考了应用Fast ICP进行点集或曲面配准 算法解析 Fast ICP根据这些因素将ICP算法分为6个步骤：a. 筛选：点集或曲面的筛选（滤波） b. 匹配：两个点集之间的点进行配对 c. 权重：给每个匹配的点对分配权重 d. 去除：去除不符合条件的点对 e. 误差度量：基于以上点对，给出每个点对的误差计算方法 f. 最小化：最小化误差度量 为测试以上阶段中不同算法的性能和结果，论文提供了三个测试场景，并在这些点集（曲面）上加上噪声： 比较平滑的波纹： 比较简单的场景，几何尺度变换不是很大 较复杂的不规则的草原地形： 相对复杂的，包含不同尺度的细节 仅含有突出一个十字形雕刻面的平面： 对匹配而言，最困难的场景，因为特征太少 下面是每个阶段的算法的比较： a. 测试点对的选择对ICP收敛的影响筛选也有以下几种策略： 应用点集内所有可用的点[Besl 92]： 无疑是性能最差的方法 对可用的点进行等间距下采样筛选[Turk 94] 随机筛选法（每次迭代的采样点都不同）[Masuda 96] 根据点的密度，颜色来筛选[Weik 97] 用上面的方法对一个面进行采样或者两个面都进行采样[Godin 94] (本文提出(normal-space-sampling)):法线在所选点之间的分布尽可能地大,(筛选哪些能使点的向量的分布尽量大的点 )这样的目的是突出 特征很少的 点集的特征。 如下图 a 随机采用法“random sampling”， 图b是”normal-space sampling”策略 分析： 对一个点集进行筛选，或者两个点集都进行筛选：对于一般的点集，两种方法收敛率和结果基本相同，但仅对一个点集筛选的算法，数据运算量相对比较大。 对于单个mesh面采样和两个mesh面都采样的策略，使用“normal shooting”作为匹配方法，两面采样的收敛率只是比单面的高一点点（真的只是一点点）。 由图ab可以明显看出，normal-space sampling策略对点集的较少的特征有着比较好的提取能力。随机采样会对稀疏的特征造成覆盖，导致ICP算法不会收敛到一个正确值。而normal-space sampling策略确保了在特征中放置足够的样本点以使表面对齐 三种采样方法对于在wave数据中的比较，uniform、random、normal-space sampling，表现相似。 三种采样方法对于在incised plane数据中的比较，uniform、random、normal-space sampling。 对于incised plane数据只有normal-space sampling收敛，其他方法不收敛。 在低曲率数据中，误差又短暂的迭代增加。这说明实际误差（ground truth error）和算法中用于估计的误差（algorithm‘s estimate of its own error）是有区别的。 Sampling Direction：对于数据wave：由于使用了下面提出的匹配方法（对称的symmetric）（the closest compatible point matching algorithm），采样方法对收敛速率没什么大影响。如果我们使用更“非对称”的匹配算法，如projection或Normal shooting(参见3.2节)，对两个mesh下采样会给出稍微更好的结果。 b. 匹配：两个点集之间的点进行配对匹配的策略有以下几种： 最邻近点法：此方法还可以应用k-d树或最邻近点缓存进行加速[Besl 92] Normal shooting：source中取一点，沿其点法向量，到destination（曲面的）的交点，形成一个点对。[Chen 91] 投影法（projection）：沿destination mesh的深度相机的视角方向，将source的点投射到destination mesh上。该方法又称“reverse calibration”。 将source点投影到destination mesh，然后在destination 深度图像中执行搜索；搜索度量: point-to-point distance[Benjemaa 97],点对点距离 point-to-ray distance [Dorai 98], 点对线距离 or compatibility of intensity [Weik 97] or color [Pulli 97]。密度，颜色 基于法线夹角[Pulli 99]或颜色[Godin 94]的兼容度量方法（Compatibility metric） Fast ICP中不考虑颜色，密度信息。 分析： 收敛速率，场景：fractal 对于这一场景，Normal shooting的效果最好，其次是投影（projection）算法。相比之下，最接近点算法的性能相对较差。 我们假设这是因为最接近点算法对噪声更敏感，并且比其他算法更容易产生大量不正确的配对(下图)。 在存在噪声和异常值（图ab中的凸起为干扰）的情况下，当网格距离较远时，最接近点匹配算法可能会产生大量不正确的配对，从而减缓收敛速度。(b)“投影”匹配策略对噪音较不敏感。 从图上看，可以看出最邻近点法容易受到噪声的干扰，而投影法不受噪声的干扰。 收敛速度和时间，场景：fractal 比较各种匹配算法的“fractal” meshes的收敛速度和时间(参见图7)。 注意，这些时间不包括预计算(特别是前四种算法使用的k-d树的计算需要0.64秒) 下面匹配算法使用了kd-tree： closest-point closest compatible point Normal shooting Normal shoot compatibile 下面没有使用匹配算法kdtree project project and walk 从上图来看（没有包含kdtree计算时间，如果包含了对比起来投影算法更加有利），投影法的计算速度非常快，这是因为不仅投影法的收敛速度快，而且其算法复杂度为O(1),而其他的算法复杂度为O(logN)。 在雕刻十字面的场景下：（closest-point algorithms是唯一收敛的方法） (上图)在这里，最接近点算法是唯一收敛到正确解的算法。因此，我们的结论是，尽管对于“简单”场景，最接近点算法可能没有最快的收敛速度，但对于“简单”场景，它们是最健壮的。 匹配方法选择： 对于非常简单的场景使用：closest-point algorithms 其他场景使用：project c. 权重：给每个匹配的点对分配权重权重分配的策略有以下几种： Constant weight：均匀分配，即常数加权。 根据点对距离加权，点对间距大，权重就小，反之，权重就大。 根据向量的一致性（compability）进行加权，weight = n1 * n2 不确定性 这几种方法的收敛速度和效果都差别大。总体上来讲，向量一致（兼容）的方法 适应性和速度比其他方法好点。 分析： 对于场景wave 下图，比较wave meshes的收敛速率，为几种加权函数的选择。为了增加变量之间的差异，我们在网格中增加了一倍的噪声和异常值。 我们发现，即使添加额外的噪声，所有的加权策略都具有相似的性能， uncertainty 和 compatibility of normals 性能稍好 对于场景 incised plane scene 结果是与wave相似的，尽管在性能上有较大的差异。然而，我们在解释这个结果时必须谨慎，因为基于uncertainty 的权重会给模型中法线指向距离扫描器以外的点分配更高的权重。因此，对于这一场景，uncertainty 权重给切口内的点赋予了更高的权重，提高了收敛速度。 结论：我们的结论是，加权对收敛速度的影响一般较小，且高度依赖于数据，加权函数的选择应基于其他因素，如最终结果的准确性; d. 去除：去除不符合条件的点对这样做的目的通常是为了消除异常值，当执行最小二乘最小化时，这些异常值可能会产生很大的影响。 这个阶段的策略包括： 固定阈值法：当间距大于一个值时，就去除这个点对 固定比例法：每次迭代，去除最差的%n的点对 标准差法：将阈值设置为所有点对间距的标准差*2.5 去除曲面边界的点对，如下图，曲面边界点的点对是不合理的，在两个点集做部分匹配的时候。 这几种方法的收敛速度差别不大，而且收敛效果也差别不大。但是去除outlier点对这个步骤 对收敛结果 的作用还是明显的。 ef. 误差度量和最小化：基于以上点对，给出每个点对的误差计算方法误差度量的策略： 对应点之间距离的平方之和 最小化： based on singular value decomposition [Arun 87], quaternions [Horn 87], orthonormal matrices [Horn 88], and dual quaternions [Walker 91] have been proposed 点到面的距离平方和：从每个源点到包含目标点且方向垂直于目标法线的平面距离的平方和[Chen 911] 最小化： 在这种“点对平面”的情况下，没有可用的封闭形式的解决方案。最小二乘方程可以用一般的非线性方法(如Levenberg-Marquardt)求解。 点到点和点到面的外推法 为对齐（alignment）规划五种搜索方案 使用当前变换反复生成一组对应的点，并找到一个最小化误差度量的新变换[Chen 91]。（简单来说就是在所有对应点对中随机采样，采样出多组子集，选出一个误差度量最小的变换） 上述迭代最小化，结合变换空间的外推（extrapolation in transform space ），加速收敛[Besl 92] 在初始条件下，从多个扰动开始进行迭代最小化，然后选择最佳结果[Simon 96]。这避免了误差函数中的伪局部极小值，特别是在使用点对点误差度量时。 使用随机选择的点子集进行迭代最小化，然后使用鲁棒(最小二乘)度量选择最优结果[Masuda 96]。 采用模拟退火随机搜索最佳变换[Blais 95]。 由于我们的重点是收敛速度，而后三种方法往往比较慢，所以我们的比较将集中在上面描述的前两种方法(即，“经典”ICP ‘迭代，包括或不包括外推)。我们使用的外推算法是基于Besl和McKay所描述的算法，算法有两个小的变化，以提高效率和减少超调: 当尝试二次外推时，抛物线向下开口，我们使用最大的x截距，而不是抛物线的极值。 我们将外推量乘以一个阻尼因子，在实现中任意设置为/2。我们发现，虽然这偶尔会降低外推的好处，但它也增加了稳定性，消除了许多超调的问题。 比较其收敛速率和效果： 在fractal scene中，我们可以看到点对面误差度量的性能明显优于点对点度量，即使添加了外推 在 incised plane中：点对点算法不能达到正确的解决方案，因为使用点对点误差度量不允许平面彼此容易滑动。 结论：点到面和点到面外推法的度量方式效果更好。 Fast ICP分析了不同阶段里，各种因素或策略对算法性能和结果的影响。应可以根据不同的需求，来选取不同的算法对点集或曲面进行配准。 在算法效果差别不大的情况下，尽量选择简单的算法，来提高运行速度，如随机采样，常数加权，固定阈值等。 结论：文章内容：上述实验对几种icp变种进行了对比，着重于对收敛速度的影响。 介绍了一种新的采样方法：normal-space-sampling 有助于在小和稀疏特征曲面的场景收敛。 用投影法做对应点匹配收敛速度和运行速度都快 给出了一种等时变体（constant-time variant）的找对应点的方法，只用几十毫秒就能对齐两个meshes。 去除outliers作用还是明显的，各种方法区别不大 在误差度量和最小化中，点到面和点到面外推法的度量方式效果更好 本文并没有测试ICP变体的稳定性和鲁棒性。 结论：提出了一种基于投影的点对应生成算法。与Neugebauer类似，我们将这种匹配算法与点对面误差度量和标准的选择匹配最小化ICP迭代相结合。(30毫秒完成两幅大象扫描的融合) 由于没有kdtree（时间复杂度O log(N)）的预处理步骤，系统快了很多。 correspondences matching：提出了一种基于投影的点对应生成算法。（projection-based algorithm） error metric:点对面误差度量(point-to-plane error metric) ICP过程的其他阶段似乎对收敛速度影响不大，因此我们选择了最简单的阶段，即随机抽样、恒定权重和距离阈值用于剔除outliers ICP开源软件：Implementations MeshLab an open source mesh processing tool that includes a GNU General Public License implementation of the ICP algorithm. CloudCompare an open source point and model processing tool that includes an implementation of the ICP algorithm. Released under the GNU General Public License. PCL (Point Cloud Library) is an open-source framework for n-dimensional point clouds and 3D geometry processing. It includes several variants of the ICP algorithm.[8] Open source C++ implementations of the ICP algorithm are available in VTK, ITK and Open3D libraries. libpointmatcher is an implementation of point-to-point and point-to-plane ICP released under a BSD license.","link":"/2019/06/01/Registration/2.FastICP/"},{"title":"Generalized-ICP","text":"Generalized-ICP-论文解读 建议下载下来用Typora软件阅读markdown文件 一、Generalized-ICP简介作者：Aleksandr V. Segal 工程：https://github.com/avsegal/gicp 论文：Generalized-ICP 提出一个单一的概率框架：将”ICP”和”point-to-plane ICP”结合起来到一个单一的概率框架(single probabilistic framework) 对两个扫描都建模然后，我们使用这个框架从两个扫描(both scan)中对局部平面表面结构建模(model)，而不是像”point-to-plane”方法那样只对模型的scan进行建模。——&gt;可以看作是plane-to-plane 结果表明该方法优于“标准ICP”和”点对面”方法 容易调整maxdistance：此外，新方法对不正确的对应关系具有更强的鲁棒性，从而更容易调整大多数ICP变体中存在的最大匹配距离参数 可以选择添加其他概率模型：除了已证明的性能改进之外，该模型还允许将更有表现力的概率模型集成到ICP框架中 在保持ICP的速度和简单性的同时，通用ICP还允许添加异常项、测量噪声和其他概率技术来增强鲁棒性。 二、求解变换矩阵 利用标准正交矩阵求绝对定向的闭型解：论文[10]Closed-form solution of absolute orientation using orthonormal matrices； 大多数ICP变体使用封闭形式的解迭代计算对应的对齐。 使用一般的非线性优化技术来代替更具体的封闭形式方法：论文[9]Robust registration of 2D and 3D point sets； 这些技术的优势在于，它们允许”更加generic的 minimization functions”，而不仅仅是欧氏距离的和；上面的论文显示使用非线性优化与鲁棒统计显示更广泛的收敛盆地。 论文[2]“A Probabilistic Framework for Robust and Accurate Matching of Point Clouds” 通过假设第二次扫描是通过一个随机过程从第一次扫描生成的，从而应用概率模型。 论文[4]“Probabilistic Matching for 3D Scan Registration” 应用射线跟踪技术来最大化对齐的概率。 论文[8]“Probabilistic Scan Matching for Motion Estimation in Unstructured Environments”构建一组兼容的对应关系，然后在此分布上最大化对齐的概率 论文[17]“Scan matching in a probabilistic framework” 引入了一个完全概率框架，该框架考虑了运动模型，并允许估计注册的不确定性。该方法的一个有趣的方面是，在没有显式对应关系的情况下，使用广义霍夫变换的采样模拟来计算对齐，同时考虑了二维数据集的两个表面法线。 全局对齐：论文[18]“Mutliview Registration for Large Data Sets”; 大量的文献致力于解决多扫描的全局对齐问题([该]和许多其他)。许多方法(尤其是[该])使用成对匹配算法作为基本组件。这使得成对匹配的改进也适用于全局对齐问题。 三、基本ICP和point-toplane方法GeneralizedICP在总结ICP和Point-to-plane算法的基础上，介绍了这两种标准方法的自然推广。然后给出了实验结果，突出了广义icp的优点。 广义在总结ICP和Point-to-plane算法的基础上，介绍了这两种标准方法的自然推广。然后给出了实验结果，突出了广义icp的优点。 a.基本ICP的伪代码 b.Point-to-planeICP point-to-plane 变体通过利用表面法线信息来提高性能。 最初由陈和Medioni在论文[7]“Object Modeling by Registration of Multiple Range Images”介绍，在2.5D range data下，该技术作为标准ICP的一种更可靠、更精确的变体得到了广泛的应用。 1.标准ICP是使得下面目标函数最小化 2.Point-to-plane而该算法优化的是：point-to-plane算法使曲面法向误差最小化例如：向量在曲面法向量张成的子空间上的投影， 代替第11行新的目标函数为 四、Generalized-ICP0.MLE最(极)大似然估计MLE（Maximum Likelihood Estimation）。 最大似然估计，就是利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。 1.简介Generalized-ICP介于标准ICP和完全概率模型之间。基于MLE(最大似然估计)作为非线性优化步骤，并利用kd树计算离散对应关系。它的独特之处在于它提供了对称性，并结合了论文[7]“Object Modeling by Registration of Multiple Range Images”的结构假设。但是，由于最近的点查找是使用欧氏距离完成的，因此可以使用kd-tree在大型点云上实现快速性能。 对于完全概率的方法，这通常是不可能的，因为这些方法需要通过分配计算MAP估计值。相对于论文[8]“Probabilistic Scan Matching for Motion Estimation in Unstructured Environments”，我们认为数据应该被假定为局部平面，因为大多数为范围数据采样的环境是分段光滑表面。通过给最小化过程一个概率解释，我们展示了将技术扩展到包含来自两个扫描的结构信息是很容易的，而不是像通常在“点对面”ICP中所做的那样只包含一个扫描。结果表明，引入这种对称性提高了精度，减少了对参数的依赖。 我们的方法和论文[17]“”Scan matching in a probabilistic framework”之间的一个关键区别是所涉及的计算复杂性。论文[17]被设计用来处理平面扫描数据-建议的广义霍夫变换需要比较一个扫描中的每一点与另一个扫描中的每一点(或者在采样的情况下，按比例进行比较)。我们的方法使用kd树来查找最近的点，因此需要O(n log(n))显式的点比较。 目前还不清楚如何将[17]中的方法有效地推广到本文所考虑的数据集。此外，这些模型还存在着哲学上的差异 2.推导广义ICP的目标函数广义icp是建立在将概率模型附加到Alg. 1第11行（最小化）步骤的基础上的。该技术保持算法的其余部分不变，以降低复杂度和保持速度。值得注意的是，对应关系的计算仍然使用标准欧氏距离，而不是概率测度。这样做是为了允许在最近点的查找中使用kd-tree，从而保持ICP相对于其他“完全概率技术（fully probabilistic techniques）”的主要优势—速度和简单 这里说的是“kdtree查找近邻”比“完全概率技术”的速度快。 没有说kdtree查找近邻的计算速度和收敛速率是最快的。 在fasticp中，作者比较了配准步骤中的几种ICP的因素，在两个点集之间的点进行配对的步骤中： 收敛速率：投影（projection）算法效果较好。相比之下，最接近点算法的性能相对较差 收敛速度和时间：投影法的计算速度非常快，这是因为不仅投影法的收敛速度快，而且其算法复杂度为O(1),而其他的算法(用了kdtree查找最近邻的算法)复杂度为O(logN) 推导过程：因为只有第11行是相关的，我们将推导的范围限制在此上下文中。 已知有对应点集,,和=是按照他们的通过计算最近点作为对应来排的,a1对b1，a2对应b2…… 假设上述的点对都在距离阈值范围内。 在概率模型中，我们假设存在一个潜在的点集：他们分别由正态分布（高斯分布）和生成的。在这里，是与测点相关的协方差矩阵。（a^i和b^i为两个点集的均值？） 这不是NDT的思路吗？NDT其中一个思路是：把点集描述成正态分布，由于正态分布曲线是光滑的曲线，可以将离散的点计算出连续的PDF函数，更好的描述了scan surface。 如果我们假设完美的对应关系(几何上一致，没有由于遮挡或采样造成的误差)，以及正确的变换，我们知道有 对于任意刚性变换，，我们定义(变换后的对应点误差向量)= 然后考虑所在的分布。 误差向量也和数据和一样，服从正太分布 它的协方差为： 因为和被认为是来自独立的高斯函数，所以也服从高斯分布，通过公式（1） (因为假设了是完美的，所以分布中的均值为0) 上述步骤得到了以变换矩阵为变量的，误差向量的正态分布的概率密度函数。那么可以通过MLE来作为目标函数。 现在我们使用MLE(极大似然估计)通过设置 来迭代计算（最优化）。 极大似然估计作为目标函数由于乘积求导不易处理，将极大似然估计转为对数极大估计，取负号变成极小对数估计目标函数。 这个一个不带约束的问题，可以用梯度下降法和牛顿法求解？ 梯度下降法要求一阶泰勒展开，牛顿法要求二阶泰勒展开 推导结果： 以上可以简化为（我也不知道怎么简化的） 这定义了通用icp算法的关键步骤。 a.point-to-point是广义ICP的一种特殊情况 通过设置，可以将标准ICP算法视为一个特例 在这种情况下，(2)变成 这正是标准的ICP更新公式。—&gt;把标准的ICP视为特殊情况，把公式2视为一般情况，所以才有了广义ICP的说法！！！ 我们可以自由地为选择任何一组协方差。作为一个激励（motivating）的例子，我们注意到点对面算法也可以被认为是概率的。 b.point-to-plane是广义ICP的一种特殊情况 有了上面的推导，同理我们也可以认为point-to-plane 作为ICP的目标函数的方法也可以看成是概率的： 是“表面法线张成的空间”在处的投影 公式4 这使得 ”“ 与 ”定义的平面及其表面法线“ 之间的距离最小化。 由于是一个正交投影矩阵 有： 这意味着可以写成一个二次形式： 代入到公式4我们有 通过与(2)的相似性，可以看出point-to-planeICP是广义ICP的一种极限情况。在这种情况下 严格来说是不可逆的，因为它是秩亏的。然而，如果我们用一个可逆的近似，当时广义ICP接近point-to-plane。 我们可以直观地将这种极限行为解释为沿着平面法向量受到约束，而不知道它在平面内的位置。 下面内容未完待续 c.应用广义ICP到plane-to-plane为了提高相对于点对面模型的性能，增加模型的对称性，广义icp可以同时考虑两种扫描的表面信息。将这种附加结构合并到(7)中最自然的方法是包含关于第二次扫描的局部表面的信息。这捕获了这种情况的直观本质，但在数学上是不可行的，因为所涉及的矩阵是奇异的。相反，我们使用点对平面的直觉来激发概率模型。 点对面算法的本质是点云的结构比三维空间中的任意点集都要多;它实际上是由距离测量传感器采样的表面集合。这意味着我们处理的是一个采样的2-manifold（流形）在3-space（空间） 由于现实世界的曲面至少是分段可微的，我们可以假设我们的数据集是局部平面的。此外，由于我们从两个不同的角度对流形进行采样，所以我们一般不会对同一点进行采样(即对应关系永远不会是精确的)。从本质上讲，每个测量点只提供一个沿其表面法线的约束。为了建立这种结构的模型，我们认为每个采样点在其局部平面上具有高协方差，而在表面法线方向上协方差很小。对于e1为a的点协方差矩阵为 在这里是一个小常数表示沿着法线的协方差。这相当于知道法线上的位置(该位置有很高的置信度)，但不确定它在平面上的位置。我们把ai和bi模型都从这种分布中提取出来。 图1给出了算法在极端情况下的效果。在这种情况下，沿绿色扫描垂直部分的所有点都与红色扫描中的单个点不正确地关联。由于曲面方向不一致，平面对平面会自动折现这些匹配项:每个对应项的最终求和协方差矩阵是各向同性的，相对于精细定义的对应协方差矩阵，对目标函数的贡献很小。这种行为的另一种观点是作为每个通信的软约束.不一致的匹配允许红色扫描点沿着x轴移动，而绿色扫描点可以自由地沿着y轴移动。因此，不正确的对应关系对整体对齐形成了非常弱的、没有信息的约束。 计算表面协方差矩阵需要与两个扫描中的每个点相关联的表面法线。从点云中恢复地表法线的方法很多，法线的精度自然对算法的性能起着重要的作用。在我们的实现中，我们对每个扫描点最近的20个点的协方差矩阵使用PCA。在这种情况下，与最小特征值相关的特征向量对应于表面法线。该方法用于计算点对平面和广义icp的法线。Generalized-ICP,旋转矩阵构造这样的ǫ分量方差和表面normal.1 五、RESULTS我们比较了这三种算法，以测试该技术的性能。虽然标准ICP中存在有效的T封闭形式解，但为了简化比较，我们采用共轭梯度最小化方法(Conjugate Gradient)。 共轭梯度法是介于最速下降法与牛顿法之间的一个方法，它仅需利用一阶导数信息，但克服了最速下降法收敛慢的缺点，又避免了牛顿法需要存储和计算海塞矩阵并求逆的缺点，共轭梯度法不仅是解决大型线性方程组最有用的方法之一，也是解大型非线性最优化最有效的算法之一 在两次扫描之间引入一个已知的偏移量后，分析性能收敛到正确的解决方案。我们将标准ICP的测试次数限制在250次以内，其他两种算法的测试次数限制在50次以内，因为通常在此之前就已经实现了收敛(如果有的话)。 模拟(图3)和真实(图4)数据均被用于演示理论和实际性能。模拟数据集还允许在更大范围的环境中进行测试，并且完全了解地面真实情况。室外模拟环境与收集到的数据的主要区别在于遮挡的数量，以及地面更多的丘陵特征。真实世界的户外测试也展示了性能与更详细的特点和更具代表性的测量噪声。 模拟数据是由安装在旋转接头上的病态扫描仪进行光线跟踪而得到的。创建了两个3D环境，分别在室内(图2(a))和室外(图2(b))场景中测试性能。 室内环境以办公室走廊为基础，而室外环境则反映了建筑周围的典型景观。在这两种情况下，我们模拟了一个装备激光扫描仪的机器人沿着轨迹移动，并在轨迹上的定点进行测量。为了使测试更加真实，加入了高斯噪声。 还对来自一辆仪表车的日志的真实数据进行了测试。这些日志包括安装在车顶上的Velodyne测距仪记录的数据，当时这辆车在郊区环境中作了一个循环，并使用GPS和IMU数据进行了标注。这使得应用基于成对约束的SLAM技术生成地面真值定位成为可能","link":"/2019/06/10/Registration/GeneralizedICP/"},{"title":"cudanote7","text":"第十章 流 页锁定主机内存、CUDA流、GPU工作调度机制 GitHub 建议下载下来用Typora软件阅读markdown文件 作者github:littlebearsama 原文链接 (建议下载Typora来浏览markdown文件) 第十章 流通过CUDA流在GPU上用任务并行 页锁定主机内存两个主机内存分配函数： 标准C库函数malloc()在主机上分配内存 CUDA运行时提供自己独有的机制来分配主机内存：cudaHostAlloc()。 两个函数分配的内存之间的差异： malloc()将分配标准的，可分页的（Pagable）主机内存， cudaHostAlloc()将分配页锁定的主机内存（固定内存） 页锁定主机内存页锁定主机内存也称为固定内存（Pinned Memory）或者不可分内存。 对于固定内存，操作系统将不会对这块内存分页交换到磁盘上，从而确保了该内存始终驻留在物理内存中。因此，操作系统能够安全地使用某个程序访问该内存的物理地址，因为这块内存将不会被破坏或者重新定位。—&gt;物理地址固定不变。 由于知道内存的物理地址，因此可以通过“直接内存访问(Direct Memory Access,DMA)”技术来在GPU和主机之间复制数据。DMA操作在可分页内存中可能会延迟—&gt;DMA复制过程中使用固定内存非常重要，页锁定主机内存（固定内存）的性能比标准可分页的性能要高大约2倍。 实际上并不是说使用固定内存就好 固定内存是一把双刃剑。但是用固定内存时，你将失去虚拟内存的所有功能。应用程序中使用每个固定内存时都需要分配物理内存，因为这些内存不能交换到磁盘上。—&gt;意味着系统更快地耗尽内存。 使用情况：仅对cudaMemcpy()调用中的源内存或者目标内存，才使用也锁存内存，并且不再需要他们时立即释放，而不是等到程序关闭才释放。 页锁定内存的作用不仅限于性能的提升，后面章节会看到，在一些特殊情况中也需要使用页锁定内存。 调用： 12345678#define SIZE (64*1024*1024)int *a；int size = SIZE;//CUDA运行时申请固定内存 HANDLE_ERROR( cudaHostAlloc( (void**)&amp;a, size * sizeof( *a ), cudaHostAllocDefault ) ); 计算带宽123float MB = (float)100*SIZE*sizeof(int)/1024/1024;//SIZE=(64*1024*1024)printf( \"\\tMB/s during copy up: %3.1f\\n\", MB/(elapsedTime/1000) );//elapsedTime=用时 CUDA流 CUDA流表示一个操作GPU队列 该队列的操作将以指定的顺序执行。我们可以在流中添加一些操作，例如启动核函数，内存复制，以及事件的启动和结束等。 可以将流视为GPU上的一个任务，并且这些任务可以并行执行。 设备重叠功能的GPU支持设别重叠功能的GPU能在执行一个CUDA C核函数的同时，还能在设备与主机之间执行复制操作。可以使用多个流来实现这种计算与数据传输的重叠。 使用流123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122#include \"../common/book.h\"#define N (1024*1024)#define FULL_DATA_SIZE (N*20)//核函数N个线程，每次处理N个数__global__ void kernel( int *a, int *b, int *c ) { int idx = threadIdx.x + blockIdx.x * blockDim.x; if (idx &lt; N) { int idx1 = (idx + 1) % 256; int idx2 = (idx + 2) % 256; float as = (a[idx] + a[idx1] + a[idx2]) / 3.0f; float bs = (b[idx] + b[idx1] + b[idx2]) / 3.0f; c[idx] = (as + bs) / 2; }} int main( void ) { cudaDeviceProp prop; int whichDevice; HANDLE_ERROR( cudaGetDevice( &amp;whichDevice ) ); HANDLE_ERROR( cudaGetDeviceProperties( &amp;prop, whichDevice ) ); //判断：支持设别重叠功能 if (!prop.deviceOverlap) { printf( \"Device will not handle overlaps, so no speed up from streams\\n\" ); return 0; } //创建事件和流 cudaEvent_t start, stop; float elapsedTime; cudaStream_t stream; int *host_a, *host_b, *host_c; int *dev_a, *dev_b, *dev_c; // start the timers HANDLE_ERROR( cudaEventCreate( &amp;start ) ); HANDLE_ERROR( cudaEventCreate( &amp;stop ) ); // initialize the stream HANDLE_ERROR( cudaStreamCreate( &amp;stream ) ); // 分配设备内存，只申请了20分之一的数据量大小的内存 HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_a, N * sizeof(int) ) ); HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_b, N * sizeof(int) ) ); HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_c, N * sizeof(int) ) ); // 在这里申请固定内存不仅仅是为了让复制操作执行得更快 // 要以异步的方式在主机和设备之间复制数据必须是固定内存 // 申请内存大小为数据大小 HANDLE_ERROR( cudaHostAlloc( (void**)&amp;host_a, FULL_DATA_SIZE * sizeof(int), cudaHostAllocDefault ) ); HANDLE_ERROR( cudaHostAlloc( (void**)&amp;host_b, FULL_DATA_SIZE * sizeof(int), cudaHostAllocDefault ) ); HANDLE_ERROR( cudaHostAlloc( (void**)&amp;host_c, FULL_DATA_SIZE * sizeof(int), cudaHostAllocDefault ) ); // 填充申请的缓冲区host_a，host_b for (int i=0; i&lt;FULL_DATA_SIZE; i++) { host_a[i] = rand(); host_b[i] = rand(); } HANDLE_ERROR( cudaEventRecord( start, 0 ) ); // now loop over full data, in bite-sized chunks //我们不将输入缓冲区整体复制到GPU，而是将输入缓冲区划分成更小的块（分成20块），并在每个块上执行一个包含三个步骤的过程： //1.将一部分输入缓冲区复制到GPU ；2.在这部分缓冲区上运行核函数；3.然后将一部分输入缓冲区复制到GPU for (int i=0; i&lt;FULL_DATA_SIZE; i+= N) { // copy the locked memory to the device, async // 将固定内存以异步的方式复制到设备上 HANDLE_ERROR( cudaMemcpyAsync( dev_a, host_a+i, N * sizeof(int), cudaMemcpyHostToDevice, stream ) ); HANDLE_ERROR( cudaMemcpyAsync( dev_b, host_b+i, N * sizeof(int), cudaMemcpyHostToDevice, stream ) ); // 核函数带有流参数 // 刚好N个线程N个数据，线程不需要多次工作 kernel&lt;&lt;&lt;N/256,256,0,stream&gt;&gt;&gt;( dev_a, dev_b, dev_c ); // 将数据从设备复制到锁定内存 HANDLE_ERROR( cudaMemcpyAsync( host_c+i, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost, stream ) ); } // copy result chunk from locked to full buffer HANDLE_ERROR( cudaStreamSynchronize( stream ) ); HANDLE_ERROR( cudaEventRecord( stop, 0 ) ); HANDLE_ERROR( cudaEventSynchronize( stop ) ); HANDLE_ERROR( cudaEventElapsedTime( &amp;elapsedTime, start, stop ) ); printf( \"Time taken: %3.1f ms\\n\", elapsedTime ); // cleanup the streams and memory HANDLE_ERROR( cudaFreeHost( host_a ) ); HANDLE_ERROR( cudaFreeHost( host_b ) ); HANDLE_ERROR( cudaFreeHost( host_c ) ); HANDLE_ERROR( cudaFree( dev_a ) ); HANDLE_ERROR( cudaFree( dev_b ) ); HANDLE_ERROR( cudaFree( dev_c ) ); HANDLE_ERROR( cudaStreamDestroy( stream ) ); getchar(); return 0;}//Time taken: 25.4 ms 创建流和事件 分配好设备内存和主机内存 分块执行三个步骤 当for循环结束时，队列中应该包含了很多等待GPU执行的工作。如果想要确保GPU只能执行完了计算和内存复制等操作。那么就需要将GPU与主机同步。也就是说主机在继续执行之前要先等待GPU完成。调用cudaStreamSynchronize()并指定想要等待的流 主机与设备之间复制数据 cudaMemcpy()同步方式执行：意味着，当函数返回时，复制操作已经完成，并且在输出缓冲区包含了复制进去的内容。 新函数cudaMemcpyAsync()异步方式执行：与同步方式相反，在调用该函数时，只是放置一个请求，表示在流中执行一次内存复制操作，这个流是通过函数stream来指定的。当函数返回时，我们无法确保复制操作是否已经启动，更无法保证它是否已经结束。我们能够保证的是，复制操作肯定会当下一个被放入流中的操作之前执行。 任何一个传递给cudaMemcpyAsync()的主机内存指针都必须已经通过cudaHostAlloc()分配好内存。你只能已异步方式对固定内存进行复制操作。 带有流参数的核函数此时核函数的调用是异步的。 使用多个流 改进思想： 分块计算 内存复制和核函数执行的重叠 上图中，第0个流执行：核函数时，在第1个流中执行：输入缓冲区复制到GPU…… 在任何支持内存复制和核函数的执行相互重叠的设备上，当使用多个流是，应用程序的整体性能都会提升。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144#include \"../common/book.h\"#define N (1024*1024)#define FULL_DATA_SIZE (N*20)__global__ void kernel( int *a, int *b, int *c ) { int idx = threadIdx.x + blockIdx.x * blockDim.x; if (idx &lt; N) { int idx1 = (idx + 1) % 256; int idx2 = (idx + 2) % 256; float as = (a[idx] + a[idx1] + a[idx2]) / 3.0f; float bs = (b[idx] + b[idx1] + b[idx2]) / 3.0f; c[idx] = (as + bs) / 2; }}int main( void ) { cudaDeviceProp prop; int whichDevice; HANDLE_ERROR( cudaGetDevice( &amp;whichDevice ) ); HANDLE_ERROR( cudaGetDeviceProperties( &amp;prop, whichDevice ) ); if (!prop.deviceOverlap) { printf( \"Device will not handle overlaps, so no speed up from streams\\n\" ); return 0; } //事件 cudaEvent_t start, stop; float elapsedTime; //流 cudaStream_t stream0, stream1; int *host_a, *host_b, *host_c; int *dev_a0, *dev_b0, *dev_c0; int *dev_a1, *dev_b1, *dev_c1; HANDLE_ERROR( cudaEventCreate( &amp;start ) ); HANDLE_ERROR( cudaEventCreate( &amp;stop ) ); HANDLE_ERROR( cudaStreamCreate( &amp;stream0 ) ); HANDLE_ERROR( cudaStreamCreate( &amp;stream1 ) ); // 申请内存 HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_a0, N * sizeof(int) ) ); HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_b0, N * sizeof(int) ) ); HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_c0, N * sizeof(int) ) ); HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_a1, N * sizeof(int) ) ); HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_b1, N * sizeof(int) ) ); HANDLE_ERROR( cudaMalloc( (void**)&amp;dev_c1, N * sizeof(int) ) ); //申请页锁定内存 HANDLE_ERROR( cudaHostAlloc( (void**)&amp;host_a, FULL_DATA_SIZE * sizeof(int), cudaHostAllocDefault ) ); HANDLE_ERROR( cudaHostAlloc( (void**)&amp;host_b, FULL_DATA_SIZE * sizeof(int), cudaHostAllocDefault ) ); HANDLE_ERROR( cudaHostAlloc( (void**)&amp;host_c, FULL_DATA_SIZE * sizeof(int), cudaHostAllocDefault ) ); //初始化页锁定内存 for (int i=0; i&lt;FULL_DATA_SIZE; i++) { host_a[i] = rand(); host_b[i] = rand(); } HANDLE_ERROR( cudaEventRecord( start, 0 ) ); // now loop over full data, in bite-sized chunks for (int i=0; i&lt;FULL_DATA_SIZE; i+= N*2) { // stream0 HANDLE_ERROR( cudaMemcpyAsync( dev_a0, host_a+i, N * sizeof(int), cudaMemcpyHostToDevice, stream0 ) ); HANDLE_ERROR( cudaMemcpyAsync( dev_b0, host_b+i, N * sizeof(int), cudaMemcpyHostToDevice, stream0 ) ); kernel&lt;&lt;&lt;N/256,256,0,stream0&gt;&gt;&gt;( dev_a0, dev_b0, dev_c0 ); HANDLE_ERROR( cudaMemcpyAsync( host_c+i, dev_c0, N * sizeof(int), cudaMemcpyDeviceToHost, stream0 ) ); // stream1 HANDLE_ERROR( cudaMemcpyAsync( dev_a1, host_a+i+N, N * sizeof(int), cudaMemcpyHostToDevice, stream1 ) ); HANDLE_ERROR( cudaMemcpyAsync( dev_b1, host_b+i+N, N * sizeof(int), cudaMemcpyHostToDevice, stream1 ) ); kernel&lt;&lt;&lt;N/256,256,0,stream1&gt;&gt;&gt;( dev_a1, dev_b1, dev_c1 ); HANDLE_ERROR( cudaMemcpyAsync( host_c+i+N, dev_c1, N * sizeof(int), cudaMemcpyDeviceToHost, stream1 ) ); } //两个流都要将CPU与GPI同步。 HANDLE_ERROR( cudaStreamSynchronize( stream0 ) ); HANDLE_ERROR( cudaStreamSynchronize( stream1 ) ); // HANDLE_ERROR( cudaEventRecord( stop, 0 ) ); HANDLE_ERROR( cudaEventSynchronize( stop ) ); HANDLE_ERROR( cudaEventElapsedTime( &amp;elapsedTime, start, stop ) ); printf( \"Time taken: %3.1f ms\\n\", elapsedTime ); // cleanup the streams and memory HANDLE_ERROR( cudaFreeHost( host_a ) ); HANDLE_ERROR( cudaFreeHost( host_b ) ); HANDLE_ERROR( cudaFreeHost( host_c ) ); HANDLE_ERROR( cudaFree( dev_a0 ) ); HANDLE_ERROR( cudaFree( dev_b0 ) ); HANDLE_ERROR( cudaFree( dev_c0 ) ); HANDLE_ERROR( cudaFree( dev_a1 ) ); HANDLE_ERROR( cudaFree( dev_b1 ) ); HANDLE_ERROR( cudaFree( dev_c1 ) ); HANDLE_ERROR( cudaStreamDestroy( stream0 ) ); HANDLE_ERROR( cudaStreamDestroy( stream1 ) ); getchar(); return 0;} 因为使用了两个流，for循环中处理的数据量为原来的两倍，步长为原来的两倍，程序处理的总数据量不变。 处理数据量是相同的，结果是一个流与两个流使用的时间差不多。 一个流使用的时间是24.1ms～25.2ms， 两个流使用的时间是：23.1～23.9ms， 修改后代码使用时间为23.9ms～24.9ms 使用了流的确改善了执行时间，但是在一个流和多个流之间并没有明显的性能提高。 GPU工作调度机制 程序员可以将流视为有序的操作序列，其中既包含内存复制操作，又包含核函数调用。 然而，硬件中并没有流的概念，而是包含一个或多个引擎来执行内存复制操作，以及一个引擎来执行核函数。这些引擎彼此独立地对操作进行排队。 应用程序首先将第0个流的所有操作放入队列，然后是第一个流的所有操作。CUDA驱动程序负责按照这些操作的顺序把他们调度到硬件上执行，这就维持了流内部的依赖性。图10.3说明了这些依赖性，箭头表示复制操作要等核函数执行完成之后才能开始。 于是得到这些操作在硬件上执行的时间线： 图中显示，第0个流复制C阻塞了第1个流复制A,第一个流复制B，导致第0个流执行完核函数还要等待内存复制引擎完成流0复制C，流1复制A，流1复制B的三个操作才能执行流1核函数 由于第0个流中将c复制回主机的操作要等待核函数执行完成，因此第1个流中将a和b复制到GPU的操作虽然是完全独立的，但却被阻塞了，这是因为GPU引擎是按照指定的顺序来执行工作。记住，硬件在处理内存复制和核函数执行时分别采用了不同的引擎，因此我们需要知道，将操作放入流队列中的顺序将影响着CUDA驱动程序调度这些操作以及执行的方式。 高效使用多个流如果同时调度某个流的所有操作，那么很容易在无意中阻塞另一个流的复制操作或者核函数执行。要解决这个问题，在将操作放入流的队列时应采用宽度优先方式，而非深度优先方式。如下代码所示： 12345678910111213141516171819202122232425262728293031323334for (int i=0; i&lt;FULL_DATA_SIZE; i+= N*2) { // enqueue copies of a in stream0 and stream1 HANDLE_ERROR( cudaMemcpyAsync( dev_a0, host_a+i, N * sizeof(int), cudaMemcpyHostToDevice, stream0 ) ); HANDLE_ERROR( cudaMemcpyAsync( dev_a1, host_a+i+N, N * sizeof(int), cudaMemcpyHostToDevice, stream1 ) ); // enqueue copies of b in stream0 and stream1 HANDLE_ERROR( cudaMemcpyAsync( dev_b0, host_b+i, N * sizeof(int), cudaMemcpyHostToDevice, stream0 ) ); HANDLE_ERROR( cudaMemcpyAsync( dev_b1, host_b+i+N, N * sizeof(int), cudaMemcpyHostToDevice, stream1 ) ); // enqueue kernels in stream0 and stream1 kernel&lt;&lt;&lt;N/256,256,0,stream0&gt;&gt;&gt;( dev_a0, dev_b0, dev_c0 ); kernel&lt;&lt;&lt;N/256,256,0,stream1&gt;&gt;&gt;( dev_a1, dev_b1, dev_c1 ); // enqueue copies of c from device to locked memory HANDLE_ERROR( cudaMemcpyAsync( host_c+i, dev_c0, N * sizeof(int), cudaMemcpyDeviceToHost, stream0 ) ); HANDLE_ERROR( cudaMemcpyAsync( host_c+i+N, dev_c1, N * sizeof(int), cudaMemcpyDeviceToHost, stream1 ) ); } 如果内存复制操作的时间与核函数执行的时间大致相当，那么新的执行时间线将如图10.5所示，在新的调度顺序中，依赖性仍然能得到满足： 由于采用了宽度优先方式将操作放入各个流的队列中，因此第0个流对c的复制操作将不会阻塞第1个流对a和b的内存复制操作。这使得GPU能够并行的执行复制操作和核函数，从而使应用程序的运行速度显著加快。 实验结果表明，并没有改进性能，可能是高版本的CUDA运行时已经对流和复制引擎等进行了优化（个人猜想）","link":"/2019/05/24/cuda/cudanote7/"},{"title":"2018PPF-MEAM","text":"出自于论文“Point Pair Feature-Based Pose Estimation with Multiple Edge Appearance Models (PPF-MEAM) for Robotic Bin Picking” 针对多边的树脂工件的改进PPF","link":"/2019/08/15/6DPose/PPF/2018PPF-MEAM/"},{"title":"C++常见问题","text":"github Q1：什么是重载(overload)和多态(polymorphic)，区别是什么 Q2：重载(overload)和覆盖(overrid)的区别 Q3：内存分配方式 建议下载下来用Typora软件阅读markdown文件 Q1：什么是重载(overload)和多态(polymorphic)，区别是什么reference 多态是基于对抽象方法的覆盖来实现的，用统一的对外接口来完成不同的功能。重载也是用统一的对外接口来完成不同的功能。那么两者有什么区别呢？ 什么是重载（todo） 重载，是指允许存在多个同名方法，而这些方法的参数不同。重载的实现是：编译器根据方法不同的参数表，对同名方法的名称做修饰。对于编译器而言，这些同名方法就成了不同的方法。它们的调用地址在编译期就绑定了。 什么是多态 多态是指子类重新定义父类的虚方法（virtual,abstract）。当子类重新定义了父类的虚方法后，父类根据赋给它的不同的子类，动态调用属于子类的该方法，这样的方法调用在编译期间是无法确定的。 区别：不难看出，两者的区别在于编译器何时去寻找所要调用的具体方法： 对于重载而言，在方法调用之前，编译器就已经确定了所要调用的方法，这称为“早绑定”或“静态绑定”； 而对于多态，只有等到方法调用的那一刻*，编译器才会确定所要调用的具体方法，这称为“晚绑定”或“动态绑定”。* Q2：重载(overload)和覆盖(overrid)的区别 重载要求函数名相同，但是参数列表必须不同，返回值可以相同也可以不同。 覆盖要求函数名、参数列表、返回值必须相同。 在类中重载是同一个类中不同成员函数之间的关系 在类中覆盖则是子类和基类之间不同成员函数之间的关系 根据参数类型来判断调用的是哪一个和根据对象类型来决定调用哪一个 重载函数的调用是根据参数列表来决定调用哪一个函数 覆盖函数的调用是根据对象类型的不同决定调用哪一个 在类中对成员函数重载是不能够实现多态 在子类中对基类虚函数的覆盖可以实现多态 Q3：内存分配方式在C++中，内存分为五个区，他们分别是： 栈，就是那些由编译器在需要的时候分配，在不需要的时候自动清除的变量的存储区。里面的变量通常是局部变量、函数参数等。 堆，C语言和操作系统的术语，堆是操作系统所维护的一块特殊内存，它提供了动态分配的功能，当运行程序调用malloc()时就会从中分配，调用free()归还内存 自由存储区，是C++中通过new和delete动态分配和释放对象的抽象概念，通过new来申请的内存区域可称为自由存储区，通过delete归还内存。 全局/静态存储区，全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。 常量存储区，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改（当然，你要通过非正当手段也可以修改） 堆和自由存储区的区别： 自由存储是C++中通过new与delete动态分配和释放对象的抽象概念，而堆（heap）是C语言和操作系统的术语，是操作系统维护的一块动态分配内存。 一般new是通过malloc来实现的，当new通过malloc来实现时，可以说new分配的内存在自由存储区，也可以说new分配的内存在堆上。 new是可以重载的，当使用重载的new来实现内存分配时，且内部实现并非只有malloc()时，此时的内存空间就和堆不同了，这是一块组合的内存空间，C++中称为“自由存储区”，这是一个抽象的概念。 size_t和int的区别 size_t 无符号，在64位系统是8字节，在32位系统是4字节。 int 有符号，在64和32位系统都是4字节。 void * ：指向不确定类型的指针。","link":"/2019/06/05/C++/C++11/cppFAQ/"},{"title":"C++ 内存管理1","text":"","link":"/2020/07/13/C++/MemoryManagement/MemoryManagement1/"},{"title":"C++ STL1","text":"","link":"/2020/07/13/C++/STL/STL1/"},{"title":"C++ 泛型编程","text":"","link":"/2020/07/13/C++/GenericProgramming/Generic Programming1/"},{"title":"2010HoughvotePPF","text":"1.PPF在三维物体识别与位姿估计算法中表现优异，本文是论文“Model Globally, Match Locally: Efficient and Robust 3D Object Recognition”的解读 2.PPF是halcon中surface_matching算子实现原理 3.PPFoutline 流程1.计算全局模型描述 计算模型中所有点两两组合，计算由两个点法构成的四维特征向量。 由这些四维特征构成哈希表，稀疏的特征向量为键（key），点法为值（value）。 如下图所示： 两对点法之间组成的特征 可以简化成F=(F1,F2,F3,F4)。 该特征是非对称的，即m1和m2之间交换会有不同的特征向量F，主要是F2和F3元素交换。 将特征向量中每个元素分别按照角度和距离步长采样。（另外一种表述：用这些特征值划分到特定的区间中，于是将稀疏的特征，变成了由特定区间组成的向量。） 2.用Hash查询进行对应估计 计算场景点云中的所有点之间的点法特征。 用场景的特征在hash表中查询所有相似的模型描述子，对应的点法为可能的对应点法（此过程时间复杂度为O(1)）。 将场景的特征值也像刚刚描述的那样，划分到特定区间，然后用划分出来的特征向量来查询相似的点法。从而获得所有可能的点法对。 3.霍夫投票获得可能的位姿 假设场景点云中有一点在我们要检测的物体上，那么对应模型点云中也有一点，将这两个点及其法线对齐后，对象可以围绕法线旋转，使模型与场景对齐。于是有从模型空间到场景空间的刚体运动可以通过，对齐参数：来表示。由于可以由相似特征查询到相似的点对， 那么有： 对于每一项匹配上的，都可以计算出旋转角。例如，对于每个模型表面上可能的位姿的，通过使用公式(2)计算使得到的对应映射计算的旋转角，如下图（图3）所示。 此时，局部坐标有三个自由度(一个是旋转角度，两个是模型表面上的点)，而一般的三维刚性运动有六个自由度。所以下面进行对其参数的投票。 然后，用计算出来的，局部坐标系下的对齐参数进行投票。图4概述了投票过程。 给定一个固定的参考点，我们想要找到最优的局部坐标，使得场景中的物体点的数量最大化。这是使用投票方案，这是类似于广义霍夫变换和非常有效的，因为局部坐标只有三个自由度。一旦找到最优局部坐标，就可以恢复物体的全局姿态。!!!!!! A.累加器 对于投票方案，我们创建一个二维累加器阵列。行数等于模型采样点的个数。列数对应旋转角度的样本步骤的个数。这个累加器阵列表示一个固定参考点的局部坐标的离散空间。霍夫空间中累加值最大的（mr，α）为最优对齐参数 B.那么实际上是怎么投票的呢？ 参考点与其他在场景中的所有其他点，组成一对。然后在模型的曲面上搜索“距离和法线方向”与相似的。 对所有点进行处理后（与所有配对，然后去模型描述中进行搜索，搜索到的坐标在累加器中累加），累加器阵列中的峰值对应于最优局部坐标，从而计算出整体刚体运动。考虑到稳定的原因，使用所有获得相对最大峰值一定数量选票的峰值。投票数目大于某个值，才使用该坐标。 C.有效的投票循环（改进投票） 为了得到一个高效的目标检测算法，我们现在将展示如何有效地实现上述投票方案。 为了加速公式(2)中每个点对的求解的速度。我们将分为两部分，，这样和分别依赖于模型和场景上的点对。这样我们可以将旋转矩阵分解为，令来获得 位于由x轴和y轴的非负部分定义的半平面上， 对于模型或场景中的每个点对，t是唯一的。因此，可以为离线阶段的每个模型点对预先计算，并存储在模型描述符中。每个场景点对只需要计算一次，最终要求的角是两个值的简单差值。—&gt;这样，在线阶段就不用去求模型相关的参数了。 4.位姿聚类如果参考点位于要检测的物体的表面上，则上述的投票方案识别出物体的姿态。 （即在场景点云中物体点上的一个参考点就能通过ppf特征+hough投票来找到模型上对应点，以及旋转角α，即对齐参数。通过对齐参数就知道物体姿态） 因此需要多个参考点来确保其中一个位于搜索的对象上。如前一节所示，每个参考点返回一组可能的对象姿态，这些姿态对应于其累加器数组中的峰值。由于场景的采样率、模型的采样率和旋转在局部坐标系中的采样率不同，所获得的姿态只能近似于实际的真实情况。 现在我们引入一个额外的步骤，它可以过滤掉不正确的pose，并提高最终结果的准确性。 操作将检索到的姿态进行集群（clustered），使一个cluster中的所有姿态在平移和旋转方面的差异不超过预定义的阈值。一个集群的得分是包含的姿态的得分之和（即该cluster内所有姿态的投票数之和），一个姿态的得分是它在投票方案中获得的投票数。 在找到得分最高的组后，通过对组中包含的位姿进行平均，计算出得到的位姿，由于对象的多个实例（instance）可能出现在场景中，因此mothod可以返回多个cluster。位姿聚类通过去除分数较低的孤立位姿提高了算法的稳定性，平均步长提高了最终位姿的精度。 算法效果与细节特征向量采样细节： 设置特征空间采样的步长，这个步长与模型直径相关，=。省缺情况下，设置抽样率为0.05。 取 = 30 为法线方向。这允许法线方向之间的差异有12°的容忍值。12°*30=360° 对模型和场景点云进行抽样，这样使得所有点之间有一个的最小距离，将排在前1/5的点在子采样场景中的点作为参考点（查询点）。 对点云进行重采样后，通过在每个点附近拟合一个平面，重新计算法线。这一步确保法线与采样级别相对应，避免了细节问题如表面褶皱。 除特殊情况外，所有实验均采用相同的参数和相同的方法对场景和模型进行采样。 结果： 源码surface_matching 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108// Author: Tolga Birdal &lt;tbirdal AT gmail.com&gt;#include \"opencv2/surface_matching.hpp\"#include &lt;iostream&gt;#include \"opencv2/surface_matching/ppf_helpers.hpp\"#include \"opencv2/core/utility.hpp\"using namespace std;using namespace cv;using namespace ppf_match_3d;static void help(const string&amp; errorMessage){ cout &lt;&lt; \"Program init error : \"&lt;&lt; errorMessage &lt;&lt; endl; cout &lt;&lt; \"\\nUsage : ppf_matching [input model file] [input scene file]\"&lt;&lt; endl; cout &lt;&lt; \"\\nPlease start again with new parameters\"&lt;&lt; endl;}int main(int argc, char** argv){ // welcome message cout &lt;&lt; \"****************************************************\" &lt;&lt; endl; cout &lt;&lt; \"* Surface Matching demonstration : demonstrates the use of surface matching\" \" using point pair features.\" &lt;&lt; endl; cout &lt;&lt; \"* The sample loads a model and a scene, where the model lies in a different\" \" pose than the training.\\n* It then trains the model and searches for it in the\" \" input scene. The detected poses are further refined by ICP\\n* and printed to the \" \" standard output.\" &lt;&lt; endl; cout &lt;&lt; \"****************************************************\" &lt;&lt; endl; if (argc &lt; 3) { help(\"Not enough input arguments\"); exit(1); } #if (defined __x86_64__ || defined _M_X64) cout &lt;&lt; \"Running on 64 bits\" &lt;&lt; endl;#else cout &lt;&lt; \"Running on 32 bits\" &lt;&lt; endl;#endif #ifdef _OPENMP cout &lt;&lt; \"Running with OpenMP\" &lt;&lt; endl;#else cout &lt;&lt; \"Running without OpenMP and without TBB\" &lt;&lt; endl;#endif string modelFileName = (string)argv[1]; string sceneFileName = (string)argv[2]; Mat pc = loadPLYSimple(modelFileName.c_str(), 1); // Now train the model cout &lt;&lt; \"Training...\" &lt;&lt; endl; int64 tick1 = cv::getTickCount(); ppf_match_3d::PPF3DDetector detector(0.025, 0.05); detector.trainModel(pc); int64 tick2 = cv::getTickCount(); cout &lt;&lt; endl &lt;&lt; \"Training complete in \" &lt;&lt; (double)(tick2-tick1)/ cv::getTickFrequency() &lt;&lt; \" sec\" &lt;&lt; endl &lt;&lt; \"Loading model...\" &lt;&lt; endl; // Read the scene Mat pcTest = loadPLYSimple(sceneFileName.c_str(), 1); // Match the model to the scene and get the pose cout &lt;&lt; endl &lt;&lt; \"Starting matching...\" &lt;&lt; endl; vector&lt;Pose3DPtr&gt; results; tick1 = cv::getTickCount(); detector.match(pcTest, results, 1.0/40.0, 0.05); tick2 = cv::getTickCount(); cout &lt;&lt; endl &lt;&lt; \"PPF Elapsed Time \" &lt;&lt; (tick2-tick1)/cv::getTickFrequency() &lt;&lt; \" sec\" &lt;&lt; endl; // Get only first N results int N = 2; vector&lt;Pose3DPtr&gt; resultsSub(results.begin(),results.begin()+N); // Create an instance of ICP ICP icp(100, 0.005f, 2.5f, 8); int64 t1 = cv::getTickCount(); // Register for all selected poses cout &lt;&lt; endl &lt;&lt; \"Performing ICP on \" &lt;&lt; N &lt;&lt; \" poses...\" &lt;&lt; endl; icp.registerModelToScene(pc, pcTest, resultsSub); int64 t2 = cv::getTickCount(); cout &lt;&lt; endl &lt;&lt; \"ICP Elapsed Time \" &lt;&lt; (t2-t1)/cv::getTickFrequency() &lt;&lt; \" sec\" &lt;&lt; endl; cout &lt;&lt; \"Poses: \" &lt;&lt; endl; // debug first five poses for (size_t i=0; i&lt;resultsSub.size(); i++) { Pose3DPtr result = resultsSub[i]; cout &lt;&lt; \"Pose Result \" &lt;&lt; i &lt;&lt; endl; result-&gt;printPose(); if (i==0) { Mat pct = transformPCPose(pc, result-&gt;pose); writePLY(pct, \"para6700PCTrans.ply\"); } } return 0; }","link":"/2019/07/28/6DPose/PPF/2010HoughvotePPF/"},{"title":"2016HinterstoisserPPF","text":"论文：Going Further with Point Pair Features linemod作者改进2010的Drost-PPF，使得改进PPF在2016年的“state of the art”。在下面数据集中，本文方法只使用了深度数据，而[12][5][21]使用了彩色数据，还是在13种类别中，在8个类别里面获得了最高分。 Hintersttoisser 改进PPF原来PPF的问题： 背景的杂乱情况下产生虚假的选票，从而掩盖了正确选票的效果。 传感器噪声会干扰量化（特征计算） 本文提出了： 更好的下采样策略 对预处理和后处理步骤做了小小的修改 具体改进1.对输入的场景点云和模型进行的预处理Drost-PPF 对三维模型和输入数据进行预处理： 原版： Drost-PPF对“目标物体”还有“输入场景“”的点云进行了下采样。 这样做有两个好处： 加速后来的计算速度 并避免考虑太多“模棱两可的”点对:相互接近的点趋向于有相似的法线，并产生许多没有区别的PPFs。因此，Drost-PPF对这些点进行子采样，使两个3D点之间至少有一个选定的最小距离。 改进： 然而，当临近点的法线实际上不同时，这可能导致有用信息的丢失。因此，如果法线之间的夹角大于30度，即使它们之间的距离小于最小距离，我们也要保持点对，因为这个点对可能是有区别的。 2.对点对进行智能采样原版： 在Drost-PPF中进行了下采样，每个场景点和所有其他场景点进行配对计算特征。这样算法复杂度是任然是二次的。 为了减少运行时间，drost-ppf中建议只使用“每隔m个场景点取一个点”，m经常在实际情况中被设为5即每5个点取1个点。这样稍微改善了运行时间，但是算法还是二次时间复杂度。 以及由于我们从早就经过了下采样的点云中移除了信息，所以影响了匹配的表现。 改进： 中心思想：两点之间的距离大于物体大小，就知道这两点不可能属于同一个物体，根本就不必考虑场景内所有的点。于是可以d_obj做一个包围球，每个查询点只对球内的点进行特征计算，忽略所有与查询点之间距大于d_obj的任何点。 但是出现了问题： 对于某些物体来说，球面区域是一个非常糟糕的近似。特别是对于狭长的被拉长的物体，如果以平行于其最长维数的观察方向观察，从半径为d_obj的球体上采样，将在背景杂波上产生许多点。 在这些情况下，我们希望使用更小的采样体积，其中与所有其他场景点相比，场景点位于对象上的比例更大。然而，我们没有任何关于物体姿态的先验信息，而且这piar的第一个场景点可以位于物体上的任何位置。要定义一个比半径为dobj的球还小的体积，而不丢弃位于目标物体上的特定对象配置下的场景点对是不可能的。 因此，我们选择连续使用两个不同半径的投票球: 一个半径为的小球是物体包围盒“最小”的边长，而是物体包围盒的“中间大小”的边长。（黄色） 一个半径为（蓝色） 第一步：我们首先用“小球接受的pairs选票”填充累加器。我们从累加器中提取峰值，“每个”峰值对应一个关于物体三维姿态的假设，以及模型和场景点之间的对应关系，如Drost-PPF。 第二步：然后，我们继续用大球接受但被小球拒绝的pairs选票填充累加器。我们像之前一样继续，提取峰值，生成姿态和点对应的假设。 这样，在图2所示的位姿下，我们可以在第一遍得到背景杂波污染较小的峰值，在第二遍得到其他构型的峰值。 使用体素网格提高查询近邻点效率： 为了有效地查找被“半径为d的球”所接受的pairs(PPFs)， 我们使用一个“空间查找表”：对于给定的场景，我们用体素网格划分场景点。每个维度的体素数量都与场景点相适应，并且可以在x、y和z维度中更精确。 这个网格中的每个体素都有d大小，并存储其中场景点的索引。 对每个场景点都是这样，我们还存储了它所属的体素索引。 构建这个体素网格是一个O (n)的操作（遍历一遍所有点）。 为了提取给定的一个点的所有其他最大距离为d的场景点（d范围内的近邻点），我们首先查找场景参考点所属的体素，并提取存储在该体素和所有相邻体素中的所有场景点索引。我们检查找到的体素内的每一个场景点到当前查询场景点的距离是否小于或等于d。 因此，该方法的复杂度为O(nk)，与Drost-的二次复杂度相比，k通常至少比n小一个数量级Drost-PPF，同时保证考虑所有相关的点对。 3.考虑投票时传感器的噪声 下面有linemod的影子啊，将特征和相似度计算”扩散到周围“来抑制噪声。 1.扩散特征到特征空间中的邻域： 为了快速访问，PPFs被离散化。然而，传感器噪声会改变离散化bin，使某些PPFs无法正确匹配。通过在模型预处理过程中扩展查找表的内容。克服了这一问题，我们并没有将第一个模型点和旋转角度只存储在离散化PPF向量索引的bin中，而是将它们存储在可以被相邻离散化PPFs所索引的(80)邻域bin中。注：(有3^4 = 81 - 1个相邻箱体)。 2.投票时，将投票投给相邻的旋转角度： 在对点法线周围的量子化旋转角进行投票时，我们也遇到了类似的问题。为了克服这个问题，我们使用了与上面相同的策略，不仅投票给原始的量化旋转角，而且投票给它的相邻的旋转角度。 简单来说：将点对扩散到相邻的离散的PPF的bin中，以及将投票投到相邻的角度中 3.问题：（引入额外的投票） 第一个场景点(红色)和其他三个场景点(绿色、蓝色和紫色),构建了三个PPF。由于离散性和扩散性（ discretization and spreading），三个PPF都对应同一个。此外，F1和F3的特征离散化和F2的扩展可能会导致这三个特征都映射到同一个hash bin X，从而投票给相同的模型参考点和旋转角度组合好几次了，这就人为地增加了对这些模型点和旋转角度的特定组合的投票，并降低了性能，特别是在本图所示的投票来自背景的情况下。 然而，如图3所示（红+绿，红+紫，红+蓝），扩展也有一个缺点：由于特征+旋转空间的离散化（特征量化到bin中）和扩展（往相邻的特征bin中加入当前点对+往隔壁离散角度投票），很可能由相近的场景点组成的对具有相同的量化旋转角度，并映射到相同的look-up table bin.。因此，他们将在累加器空间中为相同的bin投票，从而在投票中引入偏差。 4.0解决： 避免多重投票的直接方法是: 使用三维二进制数组为每个场景点来“标记”（flag），第一维的点用i表示，第二维的点用j表示，第三维的点用k表示。如果第i个模型点 ，第j个模型点分别作为第一和第二点来投票，以及第三维是早就投票了的“绕旋转轴的第k量化角度”。通过这个三维数组登记了下来，这样就避免了重复。 对于场景的每个查询点，我们都要建一个数组，这样一个数组会非常大，因为它的大小是模型点数量的平方。（n个查询点与其他查询点的组合，有n^2大小的三维数组） 4.1解决：(使用量化PPF特征作为flag数组) 我们使用由点对生成的量化PPFs的作为索引的四维数组b,而不是由一对模型点和对应的旋转来索引“flag数组”。 b数组中的每个元素：b的每个元素都是初始化为0的32位整型数，每个位对应一个离散化的“场景旋转角度”。(是多少度就将相应位置1)，每次投票就，将计算出来的的对应位置1，这样就防止了相同的量化PPFs+旋转的多次投票。 注意，我们在这里使用场景绕法线旋转，因为它只依赖于场景点对。因此，对于存储在查找表的一个bin中的所有元素都是一样的，这允许我们利用它在b中执行标记b。 这个解决方案比上面讨论的直接方法更有效，因为由于PPFs的量化，实际上可能的条目数更少。b对于所有对象的大小都是常数，并且与PPFs的所有可能量化的数量成线性关系。 在我们的实现中，当模型点的数量超过650时，直接方法要花费更多的时间 22 * 22 * 22 * 40 =650×650 4.生成对象姿态和后处理“Generating Object Pose and Postprocessing” a.旧的位姿聚类方法为了从累加器中提取物体的位姿，Drost - ppf使用贪婪的clustering方法。他们从累加池中提取峰值，每个峰值对应一个物体位姿的hypothesis。对峰值的处理顺序按它们的投票数排，投票数多的先处理，并将它们分配给最接近的cluster(如果足够接近的话)，或者创建另一个cluster。 我们发现这种方法并不总是可靠的，特别是在有噪声传感器和背景杂波的情况下。这些结果导致了虚假投票，而累加器空间中的投票数并不一定是hypothesis质量的可靠指标。 b.新的位姿聚类方法因此，提出一个不同的cluster策略，通过使用一个投票球对投票过程中产生的姿态hypotheses进行自底向上clustering。我们允许”假设”(hypotheses)加入几个clusters，只要它们的位姿与cluster中心的一个相似。 我们还跟踪与每个hypotheses相关的模型点，并且只允许一个hypotheses在没有其他具有相同模型点的hypotheses之前投票给该cluster的情况下投票给该cluster。因此，我们避免了模糊和重复的几何结构，如平面引入偏差。 对于少数几个权重最大的clusters，我们使用投影ICP[11]对估计的位姿进行了细化。在实践中，我们考虑两个投票球中的每一个球的的前四组clusters。 c.如何拒绝在实际中没有对应物体的cluster？我们根据相应的3D位姿渲染对象，计数有多少像素深度接近的渲染的像素深度，远离相机是有多少像素是被遮挡的，又有多少|更接近,因此呈现不一致。距离我们较近的像素数量与总像素数量相比过大，则拒绝该cluster。 实际上，这个阈值被设置为10%。我们也丢弃那些被遮挡太严重的对象。 最后一次检查，我们计算场景中具有显著深度或正常变化的区域，并将它们与被拍摄对象的轮廓相比较：如果轮廓没有被depth或normals的变化足够覆盖，我们将丢弃匹配项。在实践中，我们使用与遮挡检查相同的阈值。 最后，I我们对所有剩余的cluster进行排序，根据它们与场景点的匹配程度，只返回最佳簇的姿态，或者在多实例检测的情况下，返回整个簇的列表 5.对数据集测试结果A.数据集1 Hinterstoisser, S., Lepetit, V., Ilic, S., Holzer, S., Bradski, G., Konolige, K., Navab,N.: Model Based Training, Detection and Pose Estimation of Texture-Less 3DObjects in Heavily Cluttered Scenes. In: Asian Conference on Computer Vision(2012) B.数据集2 Krull, A., Brachmann, E., Michel, F., Yang, M.Y., Gumhold, S., Rother, C.: Learn-ing Analysis-by-Synthesis for 6D Pose Estimation in RGB-D Images. In: Interna-tional Conference on Computer Vision (2015) SLAM++中使用了GPU版的PPF Salas-Moreno, R., Newcombe, R., Strasdat, H., Kelly, P., Davison, A.: SLAM++:Simultaneous Localisation and Mapping at the Level of Objects. In: Conference onComputer Vision and Pattern Recognition (2013)","link":"/2019/08/07/6DPose/PPF/2016HinterstoisserPPF/"},{"title":"C++ 笔记1","text":"第1~4章 基础 GitHub 建议下载下来用Typora软件阅读markdown文件 1～4基础 浮点运算的速度通常比整型运算慢， 对于标量运算float和double都不了没有明显差别 对于适量运算double比float慢得多 运算符重载（operator overloading）：使用相同符号进行多种操作 1.C++内置重载 9/5 int ； 9L/5L long ； 9.0/5.0 double ； 9.0f/5.0f float 2.C++扩展运算符重载 int guess(3.9832);结果：guess=3; 将浮点float转换为整型int时，采用截取（丢弃小数部分），而不是四舍五入 将一个值赋值给取值范围更大的类型通常不会导致什么问题，只是占用的字节更多而已。 列表初始化(使用大括号初始化)不允许窄缩（float--&gt;int）。 (long)thorn; long(thron);强制类型转换不会改变thorn变量本身，而是创建一个新的，指定类型的值。 auto让编译器能够根据初始值的类型推断变量的类型。 C++的基本类型 整数值(内存量及有无符号)： bool,char,signed char,unsigned char,short,unsigned short,int,unsigned int,long,unsigned long,(新)long long,unsigned long 浮点格式的值：float(32位),double(64位),long double（94～128位） 复合类型：数组；字符串：1.字符数组char array 2.string类；结构：struct；共同体：union；枚举：enum；指针：int* ,long*1.数组（array）123456short months[12];int yamcosts[3]={20,30.5};double earning[4]{1.2e4,1.6e4,1.4e4,1.7e4};float balances[100]{};//初始化全部元素值为0//字符串char boss[8]=\"Bozo\"//后面四个元素为\"\\0\"空字符 using using namespace XXX;这是指示 引入名称空间内所有的名称：将XXX名称空间，所有成员变成可见，作用域和using声明一致；例：using namespace std; using XXX;这是声明 引入名称空间或基类作用域内已经被声明的名称：一次只引入一个命名空间成员;using std::cout; 类之于对象，类型之于变量对象和变量都是用来描述一段内存的。 变量更强调的是变量名这个符号的含义，更强调名字与内存的联系，而不必关注这段内存是什么类型，有多少字节长度，只关注这个变量名a对应着某段内存。 而对象的描述更强调的是内存的类型而不在乎名字，也就是说,从对象的角度看内存，就需要清除这段内存的字节长度等信息，而不是关注这个对象在代码中是否有一个变量名来引用这段内存。2.struct结构 struct和class的区别 struct能包含成员函数吗？ 能！ struct能继承吗？ 能！！ struct能实现多态吗？ 能！！！ 既然这些它都能实现，那它和class还能有什么区别？最本质的一个区别就是默认的访问控制，体现在两个方面：默认继承访问权限和默认成员访问权限 1）默认的继承访问权限。struct是public的，class是private的。 2）struct作为数据结构的实现体，它默认的数据访问控制是public的，而class作为对象的实现体，它默认的成员变量访问控制是private的。 做个总结，从上面的区别，我们可以看出，struct更适合看成是一个数据结构的实现体，class更适合看成是一个对象的实现体。 3.共用体union 它能够存储不同的数据类型，但只能同时存储其中的一种类型。 这种特性使得当数据项使用两种或更多种格式（但不会同时使用）时，可节省空间。 使用场合：1.对内存的使用苛刻，如嵌入式系统编程 2.操作系统数据结构或硬件数据结构 4.枚举 enum 提供了一种创建符号常量的方式，这种方式可以替代const。 它还允许定义新的类型，但必须按严格的限制进行。123456789101112enum spectrum{red,orange,yellow,green,blue,violet,indigo,wltraciolet};//对应整数值0～7（声明定义）//在不进行强制类型转换的情况下，只能将定义使用的枚举量赋给这种枚举的变量。spectrum band；//声明定义band = blue;//初始化（赋值）//枚举量是整型，可悲提升为int型int color = blue;//设置枚举量的值；enum bits{one=1,two=2,four=4,eight=8};enum bigstep{first,second=100,third};//first=0,third=101//枚举的取值范围bits myflag;myflag=bits(6);//强制类型转换（整数值），保证bits()输入的参数小茹bits的上限，上限=(2^n-1)&gt;max,max在bits中等于8 一、指针和自由存储空间1.使用常规变量时，值是指定的量，而地址为派生量。指针与C++基本原理1.编译阶段：编译器将程序组合起来 2.运行阶段：程序正在运行时–》oop强调的是在运行阶段进行决策 考虑为数组分配内存的情况，C++采用的方法是：使用关键字new请求正确数量的内存以及使用指针来跟踪新分配内存的位置2.处理存储数据的新策略刚好相反，将地址视为指定的量，将之视为派生量*运算符被称为间接值运算符或叫解除引用运算符（对指针解除引用意味着获得指针指向的值）。 &amp;地址运算符 注意：int * p1,p2;p1是指针，p2是int变量；对于每个指针变量名，都需要一个* 定义与初始化12345int h = 5;int *pt =&amp; h;//或int *pt;pt = &amp;h; 应用*之前，一定要将指针初始化为一个确定的，适当的地址。就是说一定要初始化，否则*pt 将值会赋给一个未知内存。否者都还没引用，又怎么解除引用呢？ 要将数字值作为地址来使用，应通过强制类型转换将数字转换为适当的地址类型。1pt=(int *)0×B8000000; 使用new来分配内存变量：在编译时分配的有名称的内存。 指针的真正的用武之地在于，在运行阶段分配未命名的内存以及存储值，（C++中使用new运算符来实现）在这种情况下，只能通过指针来访问内存—&gt;所以new的出现都会有指针。 12typeName * pointer_name=new typeName;//使用new分配未命名的内存* pointer_name=1000;//对该未去命名的内存赋值 new从被称为堆（heap）或自由存储区(free store)的内存区域分配内存。delete pointer_name;//释放指针pointer_name指向的内存。释放pointer_name指向的内存，但不会删除pointer_name指针本身。例如，可以将pointer_name重新指向另外一个新分配的内存块。不要创建两个指向同一内存块的指针 对于大型数据对象来说，使用new，如数组、字符串、结构。 1.静态联编（static binding） 如果通过声明来创建数组，则程序被编译时将为它分配内存空间，不管程序最终是否使用数组，数组都在那里。它占用了内存，所以必须指定数组长度。 2.动态联编（dynamic binding） 意味着数组是在程序运行时创建的，这种数组叫作动态数组。 使用new创建动态数组–&gt;Vector模板类是替代品 1234//创建int * psome =new int[10];//释放delete[] psome;//方括号告诉程序，应释放整个数组。 指针和数组等价的原因在于指针算术 将整数变量加1后，其值将增加1， 将指针变量加1后，增加的量等于它指向类型的字节数。 指针与数组之间的转换 数组：arrayname[i]等价于*(arrayname+i) 指针：pointername[i]等价于*(pointername+i) 因此，很多情况下，可以使用相同的方式使用数组名和指针名 const char *bird =&quot;wren&quot;bird的值可以修改，但*bird值不可以修改。其实应该说是不能使用bird指针来修改！！！ 常量指针(先出现const 再出现指针 char *)：const修饰的是“char * bird”，里面的值是不可以改变的。可以使用指针bird访问字符串“wren”但不能修改字符串。 char * const p =&quot;wren&quot;; 指针常量(先出现指针char*，再出现const)：const修饰的是指针“p”，指针的值是不能改变的。使用new来创建动态结构运行时创建数组（结构）由于编译时创建数组（结构） 创建一个未命名的inflatable类型，并将其地址赋给一个指针。 1inflatable *ps=new inflatble 二、C++有三种管理数据内存的方式（不是说物理结构） 自动存储 静态存储 动态存储–&gt;有时也叫自由存储空间或堆 线程存储（C++11新增–&gt;第9章） 自动存储：自动变量（函数内部定义的常规变量）通常存储在栈中 —&gt;随函数被调用生产，随该函数结束而消亡 —&gt;自动变量是个局部变量，作用域为包含的代码块（{…}） 静态存储：使变量称为静态 1.在函数外面定义它 2.在声明变量是使用static关键字 static double free = 5650; 动态存储：使用new和delete（可能导致占用的自由存储去不连续）对数据的生命周期不完全受程序或函数的生存周期不完全受程序或函数的生存时间控制。 如果使用new运算符在自由存储（或堆）上创建变量后，没有调用delete。则即使包含指针的内存由于副作用或规则和对象生命周期的原因而被释放（将会无法访问自由存储空间中的结构，因为指向这些内存的指针无效。这将导致内存泄漏），在自由存储空间上动态内存分配的变量或结构也将继续存在。 三、类型组合数组名是一个指针 要用指向成员运算符123a_y_e trio[3];trio[0].year=2003;(trio+1)-&gt;year=2004; 1234567//创建指针数组const a_y_e *arp[3]={&amp;s01,&amp;s02,&amp;s03};std::cout&lt;&lt;arp[1]-&gt;year&lt;&lt;std::endl;//可创建指向上述收集自的指针：const a_y_e **ppa =arp;//麻烦//可以auto，让编译器自动推断auto ppa=arps; 四、数组的替代品 1.模板类vector–&gt;是一种动态数组–&gt;可以在运行时设置长度–&gt;它是使用new创建动态数组的替代品。 vector类自动通过new和delete来管理内存。vector&lt;typeName&gt; vt(n_elm); typeName:类型,vt:对象名,n_elm:个数：整型常量/变量 2.模板类array（C++11）–&gt;与数组一样，array对象长度也是固定的，也使用栈（静态内存分配），而不是自由存储去，因此其效率与数组相同，更方便，更安全。 12array&lt;int,5&gt;ai;array&lt;double,4&gt;ad={1.2,2.1,3.4,4.3};//列表初始化 五、C++的vector、array和数组的比较（都使用连续内存,而list内存空间是不连续的）在C++11中，STL中提拱了一个新的容器std::array，该容器在某些程度上替代了之前版本的std::vector的使用，更可以替代之前的自建数组的使用。那针对这三种不同的使用方式，先简单的做个比较： 相同点： 三者均可以使用下标运算符对元素进行操作，即vector和array都针对下标运算符[]进行了重载 三者在内存的方面都使用连续内存，即在vector和array的底层存储结构均使用数组 不同点： vector属于变长容器，即可以根据数据的插入删除重新构建容器容量；但array和数组属于定长容量。 vector和array提供了更好的数据访问机制，即可以使用front和back以及at访问方式，使得访问更加安全。而数组只能通过下标访问，在程序的设计过程中，更容易引发访问 错误。 vector和array提供了更好的遍历机制，即有正向迭代器和反向迭代器两种 vector和array提供了size和判空的获取机制，而数组只能通过遍历或者通过额外的变量记录数组的size vector和array提供了两个容器对象的内容交换，即swap的机制，而数组对于交换只能通过遍历的方式，逐个元素交换的方式使用 array提供了初始化所有成员的方法fill vector提供了可以动态插入和删除元素的机制，而array和数组则无法做到，或者说array和数组需要完成该功能则需要自己实现完成。**但是vector的插入删除效率不高（从中间插入和删除会造成内存块的拷贝），但能进行高效的随机存储，list能高效地进行插入和删除，但随机存取非常没有效率遍历成本高。 由于vector的动态内存变化的机制，在插入和删除时，需要考虑迭代的是否失效的问题。 基于上面的比较，在使用的过程中，可以将那些vector或者map当成数组使用的方式解放出来，可以直接使用array；也可以将普通使用数组但对自己使用的过程中的安全存在质疑的代码用array解放出来。","link":"/2019/05/23/C++/C++11/C++笔记1/"},{"title":"C++ 笔记4","text":"第10章 对象和类 GitHub 建议下载下来用Typora软件阅读markdown文件 10对象和类 类声明：以数据成员的方式描述数据部分，以成员函数（被称为方法）的方式描述公有接口–&gt;C++程序员将接口（类定义）放在头文件中 类方法定义：描述如何实现成员函数–&gt;并将实现（类方法代码）放在源代码文件中 细节： 使用#ifndef等来访问多次包含同一个文件 将类的首字母大写 控制访问关键字：private public protected C++对结构进行了扩展，使之具有与类相同的特性。他们之间唯一的区别是：结构的默认访问类型是public，类为private 通常，数据成员被放在私有部分中=&gt;数据隐藏；成员函数被放在公有部分中=&gt;公有接口实现类成员方法成员函数两个特殊的特征： 定义类成员函数时。使用作用域解析符（::）来标识函数所属的类； 类方法可以访问类的private组件。 123456789101112131415161718class Stock{ private: char company[30]; int shares; double share_val; double total_val; void set_tot(){total_val = shares * share_val;} public: Stock(); Stock(const char * co , int n = 0 , double pr = 0.0); ~Stock(){} void buy(int num , double price); void sell(int num , double price); void update(double price); void show() const; const Stock &amp; topval(const Stock &amp; s) const;}; set_tot()只是实现代码的一种方式，而不是公有接口的组成部分，因此这个类将其声明为私有成员函数（即编写这个类的人可以使用它，但编写带来来使用这个类的人不能使用）。 内联方法， 其定义位于类声明中的函数都将自动成为内联函数。因此Stock::set_tot()是一个内联函数。 在类声明之外定义内联函数 1234567891011class Stock{private:...void set_tot();public:...};inline void Stock::set_tot(){total_val = shares * share_val;} 内联函数有特殊规则，要求每个使用它们的文件都对其进行定义。确保内联定义对多个文件程序中的所有文件都可用的最简便方法是：将内联定义放在头文件中 如何将类方法应用于对象？（对象，数据和成员函数）所创建的每个新对象都有自己的存储空间，用于存储其内部变量和类成员。但同一个类的所有对象共享一组类方法，即每种方法只有一个副本。 要使用类，要创建类对象，可以声明类变量，也可以使用new为类对象分配存储空间。 实现了一个使用stock00接口和实现文件的程序后，将其与stock00.cpp一起编译，并确保stock00.h位于当前文件夹中 类成员函数(方法)可通过类对象来调用。为此，需要使用成员运算符句点。 类的构造函数和析构函数构造函数原因：数据部分的访问状态是私有的，这意味着程序不能直接访问数据成员（私有部分数据）。程序只能通过成员函数来访问数据成员，因此需要设计合适的成员函数才能将对象初始化。—类构造函数 声明和定义构造函数12//construtor prototype with some default argumentStock(const string &amp;co,long n=0,double pr=0.0);//原型 原型声明位于类声明的公有部分。 构造函数可能的一种定义 1234567891011121314Stock::Stock(const string &amp;co,long n,double pr){company = co;if(n&gt;0){std::cerr&lt;&lt;\"Number of shares can't be negative;\" &lt;&lt; company &lt;&lt;\" shares set to 0.\\n\"; shares = 0;}elseshares=n;share_val=pr;set_tot();} 注意“参数名co，n，pr不能与类成员相同.构造函数的参数表示不是类成员，而是赋给类成员的值。 区分参数名和类成员：一种常见的做法是在数据成员名中使用m_前缀 string m_company;;另外一种常见的做法是，在成员名中使用后缀_ string company_;使用构造函数 显式调用 1Stock food = Stock1(\"World cabbage\",250,1.25); 隐式调用 123Stock garment(\"Furry Mason\",50,2.5);//等价于Stock garment= Stock(\"Furry Mason\",50,2.5); 每次创建类对象（甚至使用new动态分配内存）时，C++都是用类结构函数。 1Stock *pstock= new Stock(\"Electroshock Games\",18,19.0);//对象没有名称，但可以使用指针来管理对象 默认构造函数未提供显示初始值是，用来创建对象的构造函数。例: 1Stock fluffy_the_cat;//use the default constructor 当且今当没有定义任何构造函数时，编译器才会提供默认构造函数。 为类定义了构造函数后，程序员就必须为它提供默认构造函数 如果提供了非默认构造函数（如Stock(const string &amp;co,long n,double pr);），但没有提供构造函数，下面声明将出错（禁止创建未初始化对象）1Stock stock1; 如何定义默认构造函数：方法1：给已有构造函数函数的所有参数提供默认值 1Stock(const string &amp;co=\"Error\",int n=0,double pr=0.0); 方法2：通过函数重载来定义另外一个构造函数—一个没有参数的构造函数 1Stock(); 为Stock类提供一个默认构造函数： 12345678//隐式初始化所有对象，提供初始值Stock::Stock(){company = \"no name\";shares = 0;share_val = 0.0;total_val = 0.0;} 使用默认构造函数： 123Stock first;//隐式地调用默认的构造函数Stock first = Stock();//显式地Stock * prelief=new Stock;//隐式地 然而不要被废默认构造函数的隐式形式所误导： 123Stock first(\"Concrete Conglomerate\");//调用构造函数Stcok second(); //声明一个函数Stock third； //调用默认构造函数 析构函数 对象过期是，程序将自动调用该特殊的成员函数。析构函数完成清理工作 如果构造函数使用new来分配内存，则析构函数将使用delete来释放这些内存。 什么时候调用析构函数？这由编译器决定，不应在代码中显示地调用析构函数 如果创建的是静态存储类对象，其析构函数将在程序结束时自动被调用。2 .如果创建的是自动存储类对象，则其析构函数将在程序执行完代码块时（该对象是在其中定义的）自动被调用。 如果对象是通过new创建的，则它将驻留在栈内存或自由存储区中，当使用delete来释放内存时，其析构函数将自动被调用。程序可以创建临时变量对象来完成特定操作，在这种情况下，程序将在结束对该对象的使用时自动调用其析构函数。 总的来说：类对象过期时（需要被销毁时），析构函数将自动被调用。因此必须有一个析构函数。如果程序员没有提供析构函数，编译器将隐式地声明一个默认构造函数。 C++列表初始化只要提供与某个构造函数的参数列表匹配的内容，并用大括号将它们括起。 123Stock hot_tip = {\"Derivatives Plus Plus\",100 ,45.0};//构造函数Stock jock {\"Sport Age Storage,Inc\"};//构造函数Stock temp{};//默认构造函数 前两个声明中，用大括号括起的列表与下面的构造函数匹配： 1Stock(const string &amp;co,long n=0,double pr=0.0);//原型 因此，用该构造函数来创建这两个对象。创建对象jock时，第二和第三个参数将默认值为0和0.0。第三个声明与默认构造函数匹配，因此将使用该构造函数创建对象temp。 const成员函数1void Stock::show() const;//promises not to change invoking object 以这种方式声明和定义的类成员函数被称为const成员函数。就像应景可能将const引用和指针作函数参数一样，只要类方法不修改调用对象，就应该将其声明为const this指针有的方法可能涉及两个对象，在这种情况下需要使用C++的this指针（比如运算符重载） 提出问题：如何实现：定义一个成员函数，查看两个Stocl对象，并返回股价高的那个对象的引用。 最直接的方法是，返回一个引用，该引用指向股价总值较高的对象，因此，用于比较的方法原型如下：1const Stock &amp; topval(const Stock &amp; s) const;//该函数隐式地访问一个对象，并返回其中一个对象 第一个const：由于返回函数返回两个const对象之一的引用，因此返回类型也应为const引用 第二个const：表明该函数不会修改被显式访问的对象 第三个const：表明该函数不会修改被隐式访问的对象 调用： 1top = stock1.topval(stock2);//隐式访问stock1，显式访问stock2 this 指针用来指向调用成员函数的对象（this被作为隐藏参数传递给方法）。 每个成员函数（包括构造函数和析构函数）都有一个this指针。this指针指向调用对象 如果方法需要引用整个调用对象，可一个使用表达式*this。 实现： 1234567const Stock &amp; topval(const Stock &amp; s) const{if(s.total_val&gt;total_val)return s;elsereturn *this;} 创建对象数组123456Stock stocks[4]={ Stock(\"NanoSmart\",12,20.0), Stock(\"Boffo Objects\",200,2.0), Stock(\"Monolothic Obelisks\",130,3.25), Stock(\"Fleep Enterprises\",60,6.5)}; 类作用域回顾： 全局（文件）作用域，局部（代码块）作用域 可以在全局变量所属的任何地方使用它，而局部变量只能在其所属的代码块中使用。函数名称的作用域也可以是全局的，但不能是局部的。 类作用域 在类中定义的名称（如类数据成员和类成员函数名）的作用域为整个类。 类作用域意味着不能从外部直接访问类成员，公有函数也是如此。也就是说，要用调用公有成员函数，必须通过对象。 使用类成员名时，必须根据上下文使用，直接成员运算符（.），间接成员运算符（-&gt;）或者作用域解析符（::） 作用域为类的常量下面是错误代码 123456class Bakery{private:const int Months=12;//错误代码double cots[Months];} 这是行不通的，因为声明类只是描述了对象的形式，并没有创建对象。因此在创建对象之前，并没有用于存储值的空间。 解决： 方法一：使用枚举123456class Bakery{private:enum{Months=12};double costs[Months];} 这种方式声明枚举并不会创建类数据成员。也就是说，所有对象都不包含枚举。另外，Months只是一个符号名称，在作用域为整个类的代码中遇到他时，编译器将用12来替换它。 方法二：使用关键字static123456class Bakery{private:static const int Months=12；double costs[Months];} 这将创建一个名为Months的常量，该常量与其他静态变量存储在一起，而不是存储在对象中。因此，只有一个Months常量，被所有Bakery对象共享。 作用域内枚举（C++11）传统的枚举存在一些问题，其中之一是两个枚举定义的枚举量可能发生冲突。 12enum egg{Small，Medium,Large，XLarge};enum t_shirt{Small,Medium,Large,Xlarge}; 这将无法通过编译因为egg Small和t_shirt Small位于相同的作用域内，他们将发生冲突。 新枚举12enum class egg{Small，Medium,Large，XLarge};enum class t_shirt{Small,Medium,Large,Xlarge}; 作用域为类后，不同枚举定义的枚举量就不会发生冲突了。 class也可以用关键字struct来代替 使用： 12egg choice = egg::Large;t_shirt Floyd=t_shirt::Large; 注意：作用域内枚举不能隐式地转换为整型，下面代码错误 1int ring = Floyd;//错误 但是必要时可以进行显式转换 1int Floyd = int(t_shirt::Small); 抽象数据类型ADT(Abstract Data Type) 以抽象的方式描述数据类型，而没有引入语言和细节","link":"/2019/05/24/C++/C++11/C++笔记4/"},{"title":"C++ 笔记5","text":"第11章 使用类 GitHub 建议下载下来用Typora软件阅读markdown文件 11使用类运算符重载 运算符重载或函数多态—定义多个名称相同但特征标（参数列表）不同的函数 运算符重载—允许赋予运算符多种含义 运算符函数：operator op(argument-list)示例： 1234567891011//有类方法：Time Sum(const Time &amp;t)const;//定义：Time Time::Sum(const Time &amp; t)const{Time sum;sum.minutes = minutes + t.minutes;sum.hours = hours + t.hours + sum.minutes/60;sum.minutes%=60;retrun sum;} 返回值是函数创建一个新的Time对象（sum），但由于sum对象是局部变量，在函数结束时将被删除，因此引用指向一个不存在的对象，返回类型Time意味着程序将在删除sum之前构造他的拷贝，调用函数将得到该拷贝 运算符重载，只需把上述函数名修改即可Sum()的名称改为operator+()1234567//调用：total=coding.Sum(fixing);//运算符重载后调用1. total=coding.operator+(fixing);2. total=coding+fixing;//t1,t2,t3,t4都是Time对象t4=t1+t2+t3; 重载限制下面是可重载的运算符列表： 运算符 分别 双目算术运算符 + (加)，-(减)，*(乘)，/(除)，% (取模) 关系运算符 ==(等于)，!= (不等于)，&lt; (小于)，&gt; (大于&gt;，&lt;=(小于等于)，&gt;=(大于等于) 逻辑运算符 ||(逻辑或)，&amp;&amp;(逻辑与)，!(逻辑非) 单目运算符 + (正)，-(负)，*(指针)，&amp;(取地址) 自增自减运算符 ++(自增)，–(自减) 位运算符 | (按位或)，&amp; (按位与)，~(按位取反)，^(按位异或),，&lt;&lt; (左移)，&gt;&gt;(右移) 赋值运算符 =, +=, -=, *=, /= , % = , &amp;=, |=, ^=, &lt;&lt;=, &gt;&gt;= 空间申请与释放 new, delete, new[ ] , delete[] 其他运算符 ()(函数调用)，-&gt;(成员访问)，,(逗号)，[](下标) 下面是不可重载的运算符列表： .：成员访问运算符 .*, -&gt;*：成员指针访问运算符 ::：域运算符 sizeof：长度运算符 ?:：条件运算符 重载的运算符(有些例外情况)不必是成员函数,但必须至少有一个操作数是用户定义的类型.这防止用户标准类型重载运算符 使用运算符时不能违反运算符原来的语句法则,例如,不恩那个将秋末运算符(%)重载成一个操作数。 不能创建新的运算符 不能重载下面的运算符 sizeof：sizeof运算符 .：成员运算符 ::：作用域解析运算符 ？:：条件运算符 typeid：一个RTTI运算符 const_cast：强制类型转换运算符 dynamic_cast：强制类型转换运算符 static_cast：强制类型转换运算符 reinterpret_cast：强制类型转换运算符 下面运算符只能通过成员运算符函数进行重载 =：赋值运算符 ()：函数调用运算符 []：下标运算符 -&gt;：通过指针访问类成员的运算符 友元函数C++控制类对象私有部分的访问。通常，公有方法提供唯一的访问途径。 C++提供了另外一种形式的访问权限：友元 友元函数 友元类（15章） 友元成员函数（15章） 友元函数：通过让函数成为类的友元，可以赋予该函数与类成员函数相同的访问权限。 问：为何需要友元？为类重载二元运算符是（带两个参数的运算符）常常需要友元函数。将Time对象乘以实数就属于这种情况之前我们有运算符重载： A = B * 2.75;//Time operator*(double n)const; 如果要实现 A=2.75 * B;//不对应成员函数 cannot correspond to a member function 因为2.75不是TIme类型的对象。左侧炒作书应是调用对象 解决： 告知每个人（包括程序员自己），只能按 B * 2.75这种格式编写。 非成员函数（非成员函数来重载运算符），非成员函数不是由对象调用的，它所使用的所有值（包括对象）都是显式参数。 有函数原型： 1Time operator * (double m,const Time &amp;t); 使用： 1A=2.75 * B;或 A=operator *(2.75,B); 问题：非成员函数不能访问类的私有数据，至少常规非成员函数不能访问 解决：友元函数（非成员函数，但其访问权限与成员函数相同。）创建友元函数 将其原型放在类声明中，并在原型声明前加上关键字friend* 声明：friend Time operator * (double m,const Time &amp; t);。该原型声明意味着下面两点： 虽然，operator* ()函数是在类中声明的，但它不是成员函数，因此不能使用成员运算符来调用； 虽然，operator* ()函数不是成员函数，但它与成员函数的访问权限相同。 定义：不要使用Time::限定符，不要再定义中使用关键字friend 12345678Time operator*(double m,const Time &amp; t){Time result;long totalminutes=t.hours*mult*60+t.minutes*mult;resut.hours = totalminutes/60;result.minutes=totalminutes%60;return result;} 注：不必是友元函数（不访问数据成员也能完成功能) 1234Time operator * (double m,const Time &amp; t){return t*m;//调用了Time operator*(double n)const} 重载&lt;&lt;运算符常用友元：重载座左移运算符 第一种重载版本 使用一个Time成员函数重载&lt;&lt; 1trip&lt;&lt;cout;//（trip是Time对象）这样会让人困惑 通过使用友元函数，可以像下面这样重载运算符： 1234void operator&lt;&lt;(ostream &amp; os,const Time&amp; t){os&lt;&lt;t.hours&lt;&lt;\"hours\"&lt;&lt;t.minutes&lt;&lt;\"minute\";} 该函数成为Time类的一个友元函数（operator&lt;&lt;()直接访问Time对象的私有成员），但不是ostream类的友元（从始至终都将ostream对象作为一个整体来使用）第二种重载版本按照上面的定义，下面语句会出错：1cout&lt;&lt;\"Trip Time:\"&lt;&lt;trip&lt;&lt;\"(Tuesday)\\n\"//不能这么做 应该修改友元函数返回ostream对象的引用即可： 12345ostream&amp; operator&lt;&lt;(ostream &amp; os,const Time&amp; t){os&lt;&lt;t.hours&lt;&lt;\"hours\"&lt;&lt;t.minutes&lt;&lt;\"minute\";return os;} 按照上面的定义，下面可以正常运行： 1cout&lt;&lt;\"Trip Time:\"&lt;&lt;trip&lt;&lt;\"(Tuesday)\\n\"//正常运行 类继承属性让ostream引用能指向ostream对象和ofstream对象12345#include&lt;fstream&gt;ofstram fout;fout.open(\"Savetime.txt\");Time trip(12,40);fout&lt;&lt;trip;//等价于operator&lt;&lt;(fout,trip); 类的自动类型转换和强制转换有构造函数Stonewt(double lbs);可以编写下列代码： 12stonewt mycat;//创建一个对象mycat=19.6；//使用了Stonewt(double lbs)构造函数创意了一个临时对象 上面使用了一个Stonewt(double lbs)构造函数创建了一个临时对象，然后将该对象内容复制到了mycat中，这一过程（19.6利用构造函数变成类对象）需要隐式转换，因为是自动进行的，而不需要显式强制转换。 —&gt;只接受一个参数类型的构造函数定义了从参数类型到类类型的转换 注意：只有接受一个参数的构造函数才能作为转换函数，然而，如果第二个参数提供默认值，它便可用于转换int 1Stonewt(int stn,double lbs=0); explicit这种自动特性并非总是合乎需要的，因为会导致意外的类型转换。 新增关键字explicit，用于关闭这种自动特性，也就是说，可以这样声明构造函数：1234567explicit Stonewt(double lbs);//关闭了上面的隐式转换，但允许显式转换，即显式强制类型转换Stonewt mycat;mycat =19.6;//错误代码mycat = Stonewt(19.6);//这里是调用构造函数mycat =(Stonewt)19.6;//这里是前置类型转换 总结 当构造函数只接受一个参数是，可以使用下面的格式来初始化类对象。1Stonewt incognito=2.75; 这等价于前面介绍过的另外两种格式：(这两种格式可用于接收多个参数的构造函数)Stonewt incognito(2.75);Stonewt incognito = Stonewt(2.75); 下面函数中，Stonewt和Stonewt&amp;形参都与Stonewt实参匹配 12345678void display(const Stonewt &amp; st,int n){for(int=0;i&lt;n;i++){cout&lt;&lt;\"WOW!\";st&gt;show_stn();}} 语句display(422,2);中 编译器先查找自动类型转换中42转Stone的构造函数Stonewt(int) 不存在Stonewt(int)的话，Stonewt(double)构造函数满足这种要求因为，编译器将int转换为double 类的转换函数 构造函数只用于某种类型到类类型的转换，要进行相反的转换，必须用到特殊的C++运算符—转换函数 转换函数必定是类方法 用户定义的强制类型转换，可以向使用强制类型转换那样使用它们。 123Stonewt wolf(285,7);double host = double(wolfe);//格式1double thinker=(double)wolfe;//格式2 也可以让编译器来决定如何做： 12Stonewt wolf(20,3);double star =wells;//隐式转换 创建转换函数opeator typeName(); 转换函数必定是类方法 转换函数不能指定返回类型 转换函数不能有参数 例如：转换函数为double类型的原型如下 1operator double();//不要返回类型也不要参数 如何定义 头文件中声明： 12operator int() const;operator double() const; cpp文件中定义： 123456789Stonewt::opeator int() const{return int (pounds+0.5);//四舍五入}Stonewt::opeator double() const{return pounds;//四舍五入} 二义性C++中，int和double值都可以被赋值给long变量，下面语句被编译器认为有二义性而拒绝了。 1234long gone = poppins;//注：poppins是Stonewt对象//但是还是可以进行强制类型转换long gone = (double)poppins;long gone =int (poppins); 避免隐式转换 方法1：C++98中，关键字explicit不能用于转换函数，但C++11消除了这种限制。因此，在C++11中，可将转换运算符声明为显示的：1234567class Stonewr{...//conversion functionsexplicit operator int() const;explicit operator double() const;}; 有了这些声明后，需要前置转换时，将调用这些运算符。 方法2：用一个功能相同的非转换函数替换转换函数即可，但仅在被显式调用时，该函数才会执行。也就是说，可以将：1Stonewt::operator int(){return int(pounds+0.5);} 替换为 1int Stonewt stone_to_int(){return int(pounds+0.5);} 这样下面语句为非法的： 1int plb=popins; 需要转换时只能调用stone_to_int()： 1int plb =poppins.stone_to_int();","link":"/2019/05/24/C++/C++11/C++笔记5/"},{"title":"C++ 笔记6","text":"第12章 类和动态内存分配 GitHub 建议下载下来用Typora软件阅读markdown文件 12类和动态内存分配 动态内存和类 –&gt;让程序运行时决定内存分配，而不是在编译时决定。 —-&gt;使用new和delete运算符来动态控制内存 ——&gt;在类中使用这些运算符将导致许多新的编程问题。这种情况下，析构函数将是必不可少的，而不再是可有可无的。 ——–&gt;有时候还必须重载赋值运算符。 C++为类自动提供了下面这些成员函数 1.默认构造函数，如果没有定义构造函数；记得自己定义了构造函数时，编译器不会再提供默认构造函数，记得自己再定义一个默认构造函数。带参数的构造函数也可以是默认构造函数，只要所有参数都有默认值。 2.默认析构函数，如果没有定义；用于销毁对象 3.复制（拷贝）构造函数，如果没有定义；用于将一个对象赋值到新创建的对象中（将一个对象初始化为另外一个对象）。用于初始化的过程中，而不是常规的赋值过程。 每当程序生成对象副本时（函数按值传递对象，函数返回对象时），编译器都将使用复制构造函数 编译器生成临时对象是，也将使用复制构造函数默认的复制构造函数的功能---&gt;逐个复制非静态成员（成员复制也叫浅复制,给两个对象的成员划上等号），复制的是成员的值；如果成员本身就是类对象，则将使用这个类的复制构造函数复制成员对象,静态成员变量不受影响，因为它们属于整个类，而不是各个对象 浅复制面对指针时会出现错误，在复制构造函数中浅复制的等价于sailor.len=sport.len;sailor.str=sport.str;前一个语句正确，后一个语句错误，因为成员char* str是指针，得到的是指向同一字符串的指针！！！ 当出现动态内存分配时，要定义一个现实复制构造函数—&gt;进行深度复制(deep copy) 123456StringBad::StringBad(const StringBad &amp; st){len=st.len;str=new char[len+1];std::strcpy(str,st.str);} 4.赋值运算符，如果没有定义；赋值运算符只能由类成员函数重载的运算符之一。将已有的对象赋值给另外一个对象时（将一个对象复制给另外一个对象），使用赋值运算符。原型：class_name &amp; class_name::operator==(const class_name &amp;);接受并返回一个指向类对象的引用。 与复制构造函数相似，赋值运算符的隐式实现也对成员进行逐个复制 解决：提供赋值运算符（进行深度复制）定义，其实现业余复制构造函数相似，但有一些差别 123456789101112131415161718192021222324//代码1：先申请内存，再deleteCMyString&amp; CMyString::operator=(const CMyString&amp; str){if(this==str){char *temp_pData=new char[strlen(str.m_pData)+1)];delete[]m_pData;m_pData=temp_pData;strcpy(m_pData,str.m_pData);}return *this;}//代码2：调用复制构造函数CMyString&amp; CMyString::operator=(const CMyString&amp; str){if(this==str){CMyString strTemp(str);//复制构造函数创建临时对象，临时对象失效时会自动调用析构函数char* pTemp=strTemp.m_pData;//创建一个指针指向临时对象的数据成员m_pDatastrTemp.m_pData=m_pData;//交换m_pData=pTemp;//交换}return *this;} 5.地址运算符，如果没有定义； 6.移动构造函数(move construtor)，如果没有定义； 7.移动赋值运算符(move assignment operator)。 静态类成员函数 1.静态函数：静态函数与普通函数不同，它只能在声明它的文件中可以见，不能被其他文件使用。定义静态函数的好处：静态函数不会被其他文件使用。其他文件中可以定义相同名字的函数，不会发生冲突。 2.静态类成员函数:与静态成员数据一样，我们可以创建一个静态成员函数，它为类的全部服务，而不是为某一个类的具体对象服务。静态成员函数与静态成员数据一样，都是在类的内部实现，属于类定义的一部分。普通成员函数一般都隐藏了一个this指针，this指针指向类的对象本身。 3.静态成员函数由于不是与任何对象相联系，因此不具有this指针，从这个意义上讲，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函数，它只能调用其余的静态成员函数静态成员函数总结： 1.出现在类体外的函数不能指定关键字static； 2.静态成员之间可以互相访问，包括静态成员函数访问静态数据成员和访问静态成员函数； 3.非静态成员函数可以任意地访问静态成员函数和静态数据成员； 4.静态成员函数不能访问非静态成员函数和非静态数据成员 5.由于没有this指针的额外开销，因此静态成员函数与类的全局函数相比，速度上会有少许的增长 6.调用静态成员函数，可以用成员访问操作符(.)和(-&gt;)为一个类的对象或指向类对象的指调用静态成员函数。 构造函数中使用new时应注意的事项 1.如果构造函数中使用new来初始化指针成员，则应在析构函数中使用delete。 2.new和delete必须相互兼容，new对应于delete，new[]对应于delete[] 3.如果有多个构造函数，则必须以相同的方式使用new，要么中括号，要么都不带。因为只有一个析构函数，所有的构造函数都必须与它兼容。然而，可以在一个构造函数中使用new来初始化指针，而在另外一个构造函数中初始化为空（0或nullptr），这是因为delete（无论是带括号，还是不带括号）可以用于空指针。 4.应定义一个复制构造函数，通过深度复制将一个对象初始化为另外一个对象。 5.应当定义一个赋值运算符，通过深度复制将一个对象复制给另外一个对象。 有关返回对象的引用 1.首先，返回对象将调用复制构造函数（给新创建的临时对象复制（初始化）），而返回引用不会 2.其次，返回引用指向的对象因该在调用函数执行时存在。 3.返回作为参数输入的常量引用，返回类型必须为const，这样才匹配。 使用指向对象的指针Class_name* ptr = new Class_name;调用默认构造函数 定位new运算符/常规new运算符123456789101112131415161718//使用new运算符创建一个512字节的内存缓冲区char* buffer =new char[512];//地址：(void*)buffer=00320AB0//创建两个指针；JustTesting *pc1,*pc2;//给两个指针赋值pc1=new (buffer)JustTesting;//使用了new定位符，pc1指向的内存在缓冲区 地址：pc1=00320AB0pc2=new JustTesting(\"help\",20);//使用了常规new运算符，pc2指向的内存在堆中//创建两个指针；JustTesting *pc3,*pc4;//给两个指针赋值pc3=new (buffer)JustTesting(\"Bad Idea\",6);//使用了new定位符，pc3指向的内存在缓冲区 地址：pc3=00320AB0//创建时，定位new运算符使用一个新对象覆盖pc1指向的内存单元。//问题1：显然，如果类动态地为其成员分配内存，该内存还没有释放，成员就没了，这将引发问题。pc4=new JustTesting(\"help\",10);//使用了常规new运算符，pc4指向的内存在堆中//释放内存delete pc2；//free heap1delete pc4；//free heap2delete[] buffer//free buffer 解决问题1，代码如下： 12pc1=new (buffer)JustTesting;pc3=new (buffer+sizeof(JustTesting))(\"Bad Idea\",6); 问题2： 将delete用于pc2，pc4时，将自动调用为pc2和pc4指向的对象调用析构函数；问题2：然而，将的delete[]用于buffer时，不会为使用定位new运算符创建的对象调用析构函数 解决问题2：显式调用析构函数 12pc3-&gt;~JustTesting;pc1-&gt;~JustTesting; 嵌套结构和类 在类声明的结构、类或枚举被认为是被嵌套在类中，其作用域为整个类 这种声明不会创建数据对象，而是指定了可以在类中使用的类型。 1.如果声明是在类的私有部分进行的，则只能在这个类中使用被声明的类型。 2.如果声明是在公有部分进行的，则可以从类的外部通过作用域解析运算符使用被声明的类型例如，如果Node是在Queue类的公有部分声明的，则可以在外部声明Queue::Node类型的变量。 默认初始化a.内置类型的变量初始化如果定义变量时没有指定初始值，则变量被默认初始化。默认值由变量类型和定义变量的位置决定。 如果是内置类型的变量未被显示初始化，它的值由定义位置决定。定义于任何函数体外的变量被初始化为0。 12//不在块中int i;//正确，i会被值初始化为0，也称为零初始化 定义于函数体内部的内置类型变量将不被初始化（uninitialized）。一个未被初始化的内置类型变量的值是未定义的，如果试图拷贝或其他形式的访问此类型将引发错误 123451 {//在一个块中2 int i;//默认初始化，不可直接使用3 int j=0;//值初始化4 j=1;//赋值5 } b.类类型的对象初始化类通过一个或几个特殊的成员函数来控制其对象的初始化过程，这些函数叫做构造函数（constructor）。构造函数的任务是初始化类对象的数据成员。由编译器提供的构造函数叫（合成的默认构造函数）。合成的默认构造函数将按照如下规则初始化类的数据成员。 如果存在类内初始值（C++11新特性），用它来初始化成员。 12345678class CC{public: CC() {} ~CC() {}private: int a = 7; // 类内初始化，C++11 可用} 否则，没有初始值的成员将被默认初始化。 成员列表初始化 使用成员初始化列表的构造函数将覆盖相应的类内初始化 对于简单数据成员，使用成员初始化列表和在函数体中使用复制没什么区别 对于本身就是类对象的成员来说，使用成员初始化列表的效率更高 如果Classy是一个类，而mem1，mem2，mem3都是这个类的数据成员，则类构造函数可以使用如下的语法来初始化数据成员。 1234Classy::Classy(int n,intm):mem1(n),mem2(0),men3(n*m+2){//...} 1.这种格式只能用于构造函数 2.必须用这种格式来初始化非静态const数据成员（至少在C++之前是这样的）； 3.必须用这种格式来初始化引用数据成员 数据成员被初始化顺序与它们出现在类声明中的顺序相同，与初始化器中的排列顺序无关","link":"/2019/05/24/C++/C++11/C++笔记6/"},{"title":"C++ 笔记7","text":"第13章 类继承 GitHub 建议下载下来用Typora软件阅读markdown文件 13类继承基类和派生类的特殊关系 1.派生类对象可以使用非私有的基类方法 2.基类指针（引用）可以在不进行显示转换的情况下指向（引用）派生类对象（反过来不行）；基类指针或引用只能用来调用基类方法，不能用来调用派生类方法。 3.不可以将基类对象和地址赋给派生类对象引用和指针。 派生类构造函数要点1.首先创建基类对象；2.派生类构造函数应通过成员初始化列表将基类信息传递给基类构造函数。3.派生类构造函数应初始化新增的数据成员。注意：可以通过初始化列表语法知名指明要使用的基类构造函数，否则使用默认的基类构造函数。派生类对象过期时，程序将首先调用派生类的析构函数，然后在调用基类的析构函数。 1234RetedPlayer::RetedPlayer(unsigned int r,const string &amp; fn,const string &amp;ln, bool ht)//:TableTennisPlayer()等价于调用默认构造函数{rating = r;} 虚方法 经常在基类中将派生类会重新定义的方法声明为虚方法。方法在基类中被声明为虚的后。它在派生类中将自动生成虚方法。然而，在派生类中使用关键字virtual来指出哪些函数是虚函数也不失为一个好方法。 如果要在派生类中重新定义基类的方法，通常将基类方法声明为虚。这样，程序根据对象类型而不是引用或指针类型来选择方法版本，为基类声明一个虚的析构函数也是一种惯例，为了确保释放派生类对象时，按正确的顺序调用析构函数。 虚函数的作用：基类指针（引用）指向（引用）派生类对象，会发生自动向上类型转换，即派生类升级为父类，虽然子类转换成了它的父类型，但却可正确调用属于子类而不属于父类的成员函数。这是虚函数的功劳。 派生类方法可以调用公有的基类方法在派生类方法中，标准技术是使用作用域解析运算符来调用基类方法，如果没有使用作用域解析符，有可能创建一个不会终止的递归函数。如果派生类没有重新定义基类方法，那么代码不必对该方法是用作用域解析符（即该方法只有在基类中有）。 静态联编和动态联编函数名联编（binding）：将代码中的函数调用解释为执行特定的代码块。 在C语言中，这非常简单，因为每个函数名都对应一个不同的函数。 在C++中，由于函数重载的缘故，这个任务更繁杂，编译器必须查看函数参数以及函数名才能确定使用哪个函数。 静态联编(static binding) 在编译过程中进行联编，又称为早期联编 动态联编(dynamic binding) 编译器在程序运行时确定将要调用的函数，又称为晚期联编什么时候使用静态联编，什么时候使用动态联编？ 编译器对虚方法使用静态联编，因为方法是非虚的，可以根据指针类型关联到方法。 编译器对虚方法使用动态联编，因为方法是虚的，程序运行时才知道指针指向的对象类型，才来选择方法。（引用同理）效率：为使程序能够在运行阶段进行决策，必须采取一些方法来跟踪基类指针和指向引用对象的对象类型，这增加了额外的处理开销 例如，如果类不会用作基类，则不需要动态联编。 同样，如果派生类不重新定义基类的任何方法，也不需要动态联编。 通常，编译器处理函数的方法是：给每个对象添加一个隐藏成员–指向函数地址数组的指针(vptr) 使用虚函数时，在内存和执行速度上有一定的成本，包括：a.每个对象为存储地址的空间；b.对于每个类，比那一期都将创建一个虚函数地址表（数组）vtbl；c.对于每个函数调用，都需要执行一项额外的操作，到表中查找地址。虽然非虚函数的效率比虚函数稍高，但不具有动态联编的功能 总结： 在基类方法的声明中使用关键字virtual可使该方法在基类以及所有的派生类（包括从派生类派生出来的类）中是虚的。 如果使用指向对象的引用或指针来调用虚方法，程序将使用为对象类型定义的方法，而不是用为引用或者指针类型定义的方法。这个成为动态联编或者晚期联编。这种行为非常重要。因为这样基类指针或引用可以指向派生类对象。 如果定义的类将被用作基类，则应该将那些在派生类中重新定义的类方法生命为虚的。 虚函数细节 1.构造函数不能是虚函数，派生类不能继承基类的构造函数，将类构造函数声明为虚没什么意义。 2.析构函数应当是虚函数，除非类不用作基类。 1.当子类指针指向子类是，析构函数会先调用子类析构再调用父类析构，释放所有内存。2.当父类指针指向子类时，只会调用父类析构函数，子类析构函数不会被调用，会造成内存泄漏。（基类析构函数声明为虚，可以使得父类指针能够调用子类虚的析构函数）所以我们需要虚析构函数，将父类的析构函数定位为虚，那么父类指针会先调用子类的析构函数，再调用父类析构，使得内存得到释放。 3.友元不能是虚函数，因为友元不是类成员，只有类成员才是虚函数。 4.如果派生类没有重新定义函数。将使用该函数的基类版本。 5.重新定义将隐藏方法不会生成函数的两个重载版本，而是隐藏基类版本。如果派生类位于派生链中，则使用最新的虚函数版本，例外的情况是基类版本是隐藏的。总之，重新定义基本的方法并不是重载。如果重新定义派生类中的函数，将不只是使用相同的函数参数列表覆盖其基类声明，无论参数列表是否相同，该操作将隐藏所有的同名方法。 两条经验规则 1.如果重新定义继承的方法，应确保与原来的原型完全相同，但是如果返回类型是积累的引用或指针，则可以修改为指向派生类的引用或指针（只适用于返回值而不适用于参数），这种例外是新出现的。这种特性被称为返回类型协变（convariance of return type），因此返回类型是随类类型变化的。 123456789101112//基类class Dwelling{public:virtual Dwelling &amp; build(int n);}//派生类class Hovel:public Dwelling{public:virtual Hovel &amp; build(int n);} 2.如果基类声明被重载了，则应该在派生类中重新定义所有基类版本。 123456789101112131415161718//基类class Dwelling{public://三个重载版本的showperksvirtual void showperks（int a）const；virtual void showperks（double a）const；virtual void showperks（ ）const；}//派生类class Hovel:public Dwelling{public://三个重新定义的的showperksvirtual void showperks（int a）const；virtual void showperks（double a）const；virtual void showperks（ ）const；} 如果只重新定义一个版本，则另外两个版本将被隐藏，派生类对象将无法使用它们，注意，如果不需要修改，则新定义可知调用基类版本： 1234void Hovel::showperk()const{Dwelling::showperks();} 访问控制：protected 1.关键字protected与private相似，在类外，只能用公有类成员来访问protected部分中的类成员。 2.private和protected之间只有在基类派生的类才会表现出来。派生类的成员可以直接访问基类的保护成员，但是不能直接访问基类的私有成员。提示： 1.最好对类的数据成员采用私有访问控制，不要使用保护访问控制。 2.对于成员函数来说，保护访问控制很有用，它让派生类能够访问公众不能使用的内部函数。 抽象基类（abstract base class）ABC-&gt;至少包含一个纯虚函数 在一个虚函数的声明语句的分号前加上 =0 ；就可以将一个虚函数变成纯虚函数，其中，=0只能出现在类内部的虚函数声明语句处。 纯虚函数只用声明，而不用定义，其存在就是为了提供接口，含有纯虚函数的类是抽象基类。我们不能直接创建一个抽象基类的对象，但可以创建其指针或者引用。 值得注意的是，你也可以为纯虚函数提供定义，不过函数体必须定义在类的外部。但此时哪怕在外部定义了，也是纯虚函数，不能构建对象。 派生类构造函数只直接初始化它的直接基类。多继承的虚继承除外。 抽象类应该注意的地方 抽象类不能实例化，所以抽象类中不能有构造函数。 纯虚函数应该在派生类中重写，否则派生类也是抽象类，不能实例化。 抽象基类的作用 C++通过使用纯虚函数（pure virtual function）提供未实现的函数。纯虚函数声明的结尾处为=0， 1virtual double Area() const=0;//=0指出类是一个抽象基类，在类中可以不定义该函数 可以将ABC看作是一种必须的接口。ABC要求具体派生类覆盖其纯虚函数—迫使派生类遵顼ABC设置的接口规则。简单来说是：因为在派生类中必须重写纯虚函数，否则不能实例化该派生类。所以，派生类中必定会有重新定义的该函数的接口。 从两个类(具体类concrete)（如：Ellipse和Circle类）中抽象出他们的共性，将这些特性放到一个ABC中。然后从该ABC派生出的Ellipse和Circle类。 这样，便可以使用基类指针数组同时管理Ellipse和Circle对象，即可以使用多态方法* 友元 就像友元关系不能传递一样，友元关系同样不能继承，基类的友元在访问派生类成员时不具有特殊性，类似的，派生类的友元也不能随意访问基类的成员。 继承和动态内存分配(todo) 只有当一个类被用来做基类的时候才会把析构函数写成虚函数。 当基类和派生类都采用动态内存分配是，派生类的析构函数，复制构造函数，赋值运算符都必须使用相应的基类方法来处理基类","link":"/2019/05/24/C++/C++11/C++笔记7/"},{"title":"C++ 笔记9","text":"第15章 友元、异常和其他 GitHub 建议下载下来用Typora软件阅读markdown文件 15友元、异常和其他友元类例子：模拟电视机和遥控器的简单程序 公有继承is-a关系并不适用。遥控器可以改变电视机的状态，这表明应将Remove类作为TV类的一个友元 友元声明 friend class Remote；—&gt;友元声明可以位于公有、私有或保护部分，其所在的位置无关紧要。该声明让整个类成为友元并不需要前向（实现）声明，因为友元语句本身已经指出Remote是一个类。 友元Remove可以使用TV类的所有成员 大多类方法都被定义为内联。代码中，除构造函数外，所有Remove方法都将一个TV对象引用作为参数，这表明遥控器必须针对特定的电视机 同一个遥控器可以控制不同的电视机 12345TV S42；TV S58(TV::ON);Remote grey;grey.set_chan(S42,10);grey.set_chan(S58,28); 友元成员函数 某一个类的成员函数作为另外一个类的友元函数 例子：将TV成员中Remote方法Remote::set_chan()，成为另外一个类的成员 12345class TV{friend void Remote::set_chan(TV&amp; t,int c);...}; 问题1：在编译器在TV类声明中看到Remote的一个方法被声明为TV类的友元之前，应先看到Remote类的声明和set_chan()方法的声明。 1234//排列次序应如下：class TV;//forward declarationclass Remote{...};class TV{...}; 问题2：Remote声明包含内联代码，例如：void onoff(TV &amp; t){t.onoff();}由于这将调用TV的一个方法，所以编译器此时必须看到一个TV的类声明，解决：使Remote声明中只包含方法声明，并将实际的定义放在TV类之后 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include&lt;iostream&gt; class B{public : B() { myValue=2; std::cout&lt;&lt;\"B init\"&lt;&lt;std::endl; } ~B() { std::cout&lt;&lt;\"B end\"&lt;&lt;std::endl; } //这样做可以 /*B operator+(const B av) { B a; a.myValue=myValue+av.myValue; return a; }*/ //也可以这么做 friend B operator+(const B b1,const B b2); //------------------------------------------------ int GetMyValue() { return myValue; } //重载&lt;&lt; friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os,B);private : int myValue;};B operator+(const B b1,const B b2){ B a; a.myValue=b1.myValue+b2.myValue; return a;}std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os,B b){ return os&lt;&lt;\"重载实现：\"&lt;&lt;b.myValue&lt;&lt;std::endl;}int main(){ B b1; std::cout&lt;&lt;b1; B b2; B b3=b1+b2; std::cout&lt;&lt;b3&lt;&lt;std::endl; std::cin.get(); return 0;} 内联函数的链接性是内部的，这意味着函数定义必须在使用函数的文件中，这个例子中内联定义位于头文件中，因此在使用函数的文件中包含头文件可确保将定义放在正确的地方。这可以将定义放在实现文件中，但必须删除关键字inline这样函数的链接性将是外部的 嵌套类 在另外一个类中声明的类被称为嵌套类（nested class） 包含类的成员函数可以创建和使用被嵌套的对象。而仅当声明位于公有部分，才能在包含类外面使用嵌套类，而且必须使用作用域解析运算符 访问权限：嵌套类、结构和美剧的作用域特征（三者相同） 声明位置 包含它的类是否可以使用它 从包含它的类派生而来的类是否可以使用它 在外部是否可以使用 私有部分 是 否 否 保护部分 是 是 否 公有部分 是 是 是，可以通过类限定符来使用 * 访问控制 1.类声明的位置决定了类的作用域或可见性 2.类可见后，访问控制规则（公有，保护，私有，友元）将决定程序对嵌套类成员的访问权限。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596//在下面的程序中，我们创建了一个模板类用于实现Queue容器的部分功能，并且在模板类中潜逃使用了一个Node类。// queuetp.h -- queue template with a nested class#ifndef QUEUETP_H_#define QUEUETP_H_template &lt;class Item&gt;class QueueTP{private: enum {Q_SIZE = 10}; // Node is a nested class definition class Node { public: Item item; Node * next; Node(const Item &amp; i) : item(i), next(0) {} }; Node * front; // pointer to front of Queue Node * rear; // pointer to rear of Queue int items; // current number of items in Queue const int qsize; // maximum number of items in Queue QueueTP(const QueueTP &amp; q) : qsize(0) {} QueueTP &amp; operator=(const QueueTP &amp; q) { return *this; }public: QueueTP(int qs = Q_SIZE); ~QueueTP(); bool isempty() const { return items == 0; } bool isfull() const { return items == qsize; } int queuecount() const { return items; } bool enqueue(const Item &amp;item); // add item to end bool dequeue(Item &amp;item); // remove item from front};// QueueTP methodstemplate &lt;class Item&gt;QueueTP&lt;Item&gt;::QueueTP(int qs) : qsize(qs){ front = rear = 0; items = 0;}template &lt;class Item&gt;QueueTP&lt;Item&gt;::~QueueTP(){ Node * temp; while (front != 0) // while queue is not yet empty { temp = front; front = front-&gt;next; delete temp; }}// Add item to queuetemplate &lt;class Item&gt;bool QueueTP&lt;Item&gt;::enqueue(const Item &amp; item){ if (isfull()) return false; Node * add = new Node(item); // create node // on failure, new throws std::bad_alloc exception items ++; if (front == 0) // if queue is empty front = add; // place item at front else rear-&gt;next = add; // else place at rear rear = add; return true;}// Place front item into item variable and remove from queuetemplate &lt;class Item&gt;bool QueueTP&lt;Item&gt;::dequeue(Item &amp; item){ if (front == 0) return false; item = front-&gt;item; // set item to first item in queue items --; Node * temp = front; // save location of first item front = front-&gt;next; // reset front to next item delete temp; // delete former first item if (items == 0) rear = 0; return true;}#endif // QUEUETP_H_ 异常 意外情况 1.程序可能会试图打开一个不可用的文件2.请求过多内存3.遭遇不能容忍的值 1.调用abort()–原型在cstdlib（或stdlib.h）中 其典型实现是向标准错误流（即cerr使用的错误流）发送信息abnormalprogram termination（程序异常中止），然后终止程序。它返回一个随实现而异的值，告诉操作系统，处理失败。 调用abort()将直接终止程序（调用时，不进行任何清理工作） 使用方法：1.判断触发异常的条件 2.满足条件时调用abort() 1.exit():在调用时，会做大部分清理工作，但是决不会销毁局部对象，因为没有stack unwinding。会进行的清理工作包括：销毁所有static和global对象，清空所有缓冲区，关闭所有I／O通道。终止前会调用经由atexit()登录的函数，atexit如果抛出异常，则调用terminate()。 2.abort():调用时，不进行任何清理工作。直接终止程序。 3.retrun:调用时，进行stack unwinding，调用局部对象析构函数，清理局部对象。如果在main中，则之后再交由系统调用exit()。 return返回，可析构main或函数中的局部变量，尤其要注意局部对象，如不析构可能造成内存泄露。exit返回不析构main或函数中的局部变量，但执行收工函数，故可析构全局变量（对象）。abort不析构main或函数中的局部变量，也不执行收工函数，故全局和局部对象都不析构。所以，用return更能避免内存泄露，在C++中用abort和exit都不是好习惯。 2.返回错误代码一种比异常终止更灵活的方法是，使用函数的返回值来指出问题 3.异常机制 C++异常是对程序运行过程中发生的异常情况（例如被0除）的一种响应。异常提供了将控制权从程序的一个部分传递到另外一部分的途径 异常机制由三个部分组成1.引发异常123456double hmean(double a,double b){if(a==-b)throw \"bad heam() arguments:a=-b not allowed\";//throw关键字表示引发异常（实际上是跳转）return 2.0*a*b/(a+b);} 2.使用异常处理程序（exception handler）来捕获异常3.使用try块：try块标识其中特定异常可能会被激活的代码，它后面跟一个或多个的catch块 例子：12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt; using std::cout;using std::cin;using std::cerr; int fun(int &amp; a, int &amp; b){if(b == 0){ throw \"hello there have zero sorry\\n\"; //引发异常}return a / b;} int main(){ int a; int b; while(true) { cin &gt;&gt; a; cin &gt;&gt; b; try //try里面是可能引发异常代码块 { cout &lt;&lt; \" a / b = \"&lt;&lt; fun(a,b) &lt;&lt; \"\\n\"; } catch(const char *str) 接收异常,处理异常 { cout &lt;&lt; str; cerr &lt;&lt;\"除数为0\\n\"; //cerr不会到输出缓冲中 这样在紧急情况下也可以使用 } } system(\"pause\"); return 1;} 1.try:try块标识符其中特定的异常可能被激活的代码块,他后面跟一个或者多个catch块. 2.catch:类似于函数定义,但并不是函数定义,关键字catch表明这是给一个处理程序,里面的const cahr* str会接受throw传过来错误信息. 3.throw:抛出异常信息,类似于执行返回语句,因为它将终止函数的执行,但是它不是将控制权交给调用程序,而是导致程序沿着函数调用序列后退,知道找到包含try块的函数. 注意： 1.如果程序在try块外面调用fun(),将无法处理异常。 2.throw出的异常类型可以是字符串，或其他C++类型：通常为类类型 3.执行throw语句类似于执行返回语句，因为它也将终止函数的执行。 4.执行完try中的语句后，如果没有引发任何异常，则程序跳过try块后面的catch块，直接执行后面的第一条语句。 5.如果函数引发了异常，而没有try块或没有匹配处理程序时，将会发生什么情况。在默认情况下，程序最终调用abort()函数！ 4.将对象用作异常类型 P6225.栈解开（栈解退）stack unwind C++如何处理函数调用和返回的？ 1.程序将调用函数的地址（返回地址）放入到栈中。当被调用的函数执行完毕后，程序将使用该地址来确定从哪里开始执行。 2.函数调用将函数参数放入到栈中。在栈中，这些函数参数被视为自动变量。如果被调用的函数创建的自动变量，则这些自动变量也将被添加到栈中 3.如果被调用的函数调用了另外一个函数，则后者的信息将被添加到栈中，依此类推。 假设函数出现异常（而不是返回）而终止，则程序也将释放栈中的内存，但不会释放栈中的第一个地址后停止，而是继续释放，直到找到一个位于try块中的返回地址。随后，控制权将转到块尾的异常处理程序，而不是函数调用后的第一条语句，这个过程被称为栈解退。 exception类（头文件exception.h/except.h第一了exception类）C++可以把它用作其他异常类的基类 1.stdexcept 异常类（头文件stdexcept定义了其他几个异常类。） 该文件定义了1.logic_error类 2.runtime_error类他们都是以公有的方式从exception派生而来的。 1.logic_error类错误类型（domain_error、invalid_argument、length_error、out_of_bounds）。每个类都有一个类似于logic_error的构造函数，让您能够提供一个供方法what()返回的字符串。 2.runtime_error类错误类型（range_error、overflow_error、underflow_error）。每个类都有一个类似于runtime_error的构造函数，让您能够提供一个供方法what()返回的字符串。 2.bad-alloc异常和new(头文件new) 对于使用new导致的内存分配问题，C++的最新处理方式是让new引发bad_alloc异常。头文件new包含bad_alloc类的生命，他是从exception类公有派生而来的。但在以前，当无法分配请求的内存量时，new返回一个空指针。 3.异常类和继承 1.可以像标准C++库所做的那样，从一个异常类派生出另外一个。 2.可以在类定义中嵌套异常类声明类组合异常。 3.这种嵌套声明本身可被继承，还可用作基类。 RTTI(运行阶段类型识别)(Run-Time Type Identification) 旨在为程序运行阶段确定对象的类型提供一种标准方式 RTTI的工作原理 C++有三个支持RTTI的元素 1.如果可能的话，dynamic_cast运算符将使用一个指向基类的指针来生成指向派生类的指针；否则，该运算符返回0—空指针。 2.typeid运算符返回指出对象类型的值 3.type_info结构存储了有关特定类型的信息。 1.dynamic_cast运算符是最常用的RTTI组件 他不能回答“指针指向的是哪类对象”这样的问题，但能回答“是否可以安全地将对象的地址赋给特定类型的指针”这样的问题 用法：Superb* pm = dynamic_cast&lt;Super*&gt;(pg);其中pg指向一个对象 提出这样的问题：指针pg类型是否可被安全地转换为Super* ?如果可以返回对象地址，否则返回一个空指针。 2.typeid运算符和type_info类。 typeid运算符使得能够确定两个对象是否为同类型,使用：如果pg指向的是一个Magnification对象，则下述表达式的结果为bool值true，否则为false； 12345typeid(Magnification)==typeid(*pg)type_info类的实现岁厂商而异，但包含一个name()成员，该函数返回一个随实现而异的字符串；通常（但并非一定）是类的名称。例如下面的语句想爱你是指针pg指向的对象所属的类定义的字符串：​```C++cout&lt;&lt;\"Now Processing type\"&lt;&lt;typeid(*pg).name()&lt;&lt;\".\\n\"; 类型转换运算符 4个类型转换运算符:dynamic_cast\\const_cast\\static_cast\\reinterpret_cast 1.dynamic_cast(expression) 该运算符的用途是，使得能够在类层次结构中进行向上转换（由于is-a关系，这样的类型转换是安全的），不允许其他转换。 2.const_cast(expression) 该运算符用于执行只有一种用途的类型转换，即改变之const或volatile其语法与dynamic_cast运算符相同。 3.static_cast(expression) 4.reinterpret_cast(expression) 用于天生危险的类型转换。","link":"/2019/05/24/C++/C++11/C++笔记9/"},{"title":"C++ 笔记2","text":"第5～8章 函数 GitHub 建议下载下来用Typora软件阅读markdown文件 一、函数函数—C++的编程模块（要提高编程效率，可更深入地学习STL和BOOST C++提供的功能） 1.提供函数定义 function definition 2.提供函数原型 function prototype 3.调用函数 function call 12345Void functionName(parameterlist){statement(s)teturn;} parameterlist:指定了传递给函数的参数类型和数量 void:没有返回值，对于有返回值的函数，必须有返回语句return 1.返回值类型有一定的限制：不能是数组，但可以是其他任何类型—整数，浮点数，指针，甚至可以是结构和对象。 2.函数通过将返回值复制到指定的CPU寄存器或内存单元中来将其返回。 1.为什么需要原型原型描述了函数到编译器的接口: 它将1.函数返回值类型（如果有的话） 以及2.参数的类型 和3.数量告诉编译器。（在原型的参数列表中，可以包含变量名，也可以不包含。原型中的变量名相当于占位符，因此不必与函数中的变量名相同） 确保：编译器正确处理1，编译器检查2，3 2.函数参数传递和按值传递 用于接收传递值的变量被称为形参（parameter），传递给函数的值被称为实参（argument）。 值传递：调用函数时，使用的是实参的副本，而不是原来的数据。 在函数中声明的变量（局部变量（自动变量））（包括参数）是该函数私有的，函数调用时：计算机将为这些变量分配内存；函数结束时：计算机将释放这些变量使用的内存。 3.函数和数组123int sum_arr(int arr[],int n);//arr=arrayname.n=sizeint sum_arr(int * arr,int n);//arr=arrayname.n=size//两者是等价的 a.数组与指针 在C++中，当且仅当用于函数头或者函数原型中，int * arr和int arr[]的含义才是相同的。它们意味着arr是一个int指针。 然而，数组表示法(int arr[])提醒用户，arr不仅指向int，还指向int数组的第一个int。 b.const保护数组（输入数组原数据不能改变） void show_array(const double ar[],int n);//声明形参时使用const关键字 该声明表明，指针or指向的是常量数据。这意味着不能使用or修改数据。这并不意味着原始数据必须是常量，只意味着不能使用该指针来修改原始数据。 如果该函数要修改数组的值，声明ar时不能使用const c.如何使用数组作为参数传递给函数对于处理数组的C++函数，必须将数组中的 1.数据类型 2.数组的起始位置 3.和数组元素中的数量提交给他 传统的C/C++方法是，将指向数组起始处的指针作为一个参数，将数组长度作为第二个参数（指针指出数组位置和数据类型） 第二种方法：指定元素区间（range）通过传递两个指针来完成：一个指针表示数组的开头，另外一个指针表示数组的尾部。例子： 12345678910int sum_arr(const int *begun,const int *end){const int *pt;int total=0;for(pt=begin;pt!=end;pt++)total=toatl+*pt;return total;}int cookies[ArSize]= {1,2,4,8,16,32,64,128};int sum=sum_arr(cookies,cookies+ArSize); 4.函数与C风格字符串假设要将字符串（实际传递的是字符串第一字符的地址）作为参数传递给函数，则表示字符串的方式有三种： 1.char数组T 2.用引号的字符串常量 3.被设置为字符串的地址的char指针。 5.函数和结构涉及函数时，结构变量的行为更接近基于基本的单值变量 1.按值传递–&gt;如果结构非常大，则复制结构将增加内存要求，且使用的是原始变量的副本 2.传递结构的地址，然后使用指针来访问结构的内容 1234567rect rplace;polar pplace;void rect_to_polar(const rect*pxy,polar*pda){...}rect_to_polar(&amp;rplace,&amp;pplace); 调用函数时，将结构的地址（&amp;pplace）而不是结构本身（pplace）传递给它；将形参声明为指向polar的指针，即polar*类型。由于函数不应该修改结构，因此使用了const修饰符，由于形参是指针不是结构，因此应使用间接成员运算符(-&gt;)，而不是成员运算符（.）。 3.按引传递用，传指针和传引用效率都高，一般主张是引用传递代码逻辑更加紧凑清晰。 递归—C++函数有一种有趣的特点–可以调用自己（除了main()）1.包含一个递归调用的递归 1234567void recurs(argumentlist){statement1if(test)recurs(arguments)statement2} 如果调用5次recurs就会运行5次statement1，运行1次statement2. 2.包含多个递归调用的递归 12345678void recurs(argumentlist){if(test)return;statement;recurs(argumentlist1);recurs(argumentlist2);} 3.从1加到n 12345678910class Solution{public:int Sum_Solution(int n){int ans=n;ans&amp;&amp;(ans+=Sum_Solution(n-1));return ans;}};//&amp;&amp;就是逻辑与，逻辑与有个短路特点，前面为假，后面不计算。 6.函数指针函数也有地址—存储其机器语言代码的内存的开始地址 获取函数的地址，只要使用函数名（后面不跟参数）即可。 例如think()是个函数 1234567891011process(think);//传递的是地址thought(think());//传递的是函数返回值//使用double pam(int);//原始函数声明double (*pf)(int);//函数指针声明pf=pam;//使用指针指向pam函数double x=pam(4);//使用函数名调用pam()double y=(*pf)(5);//使用指针调用pam()//也可以这样使用函数指针double y=pf(5); 进阶下面函数原型的特征表和返回类型相同123456789const double *f1(const double ar[],int n);const double *f2(const double [],int );const double *f3(const double *,int );//声明一个指针可以指向f1，f2，f3const double * (*p1)(const double *,int );//返回类型相同，函数的特征标相同//声明并初始化const double * (*p1)(const double *,int )=f1;//也可以使用自动类型推断auto p2=f2; 使用for循环通过指针依次条用每个函数 例子：声明包含三个函数指针的数组，并初始化 const double * (*pa[3])(const double *,int)={f1,f2,f3}; 问：为什么不使用自动类型推断？auto 答：因为自动类型推断只能用于单值初始化，而不能用初始化列表。 但可以声明相同类型的数组 auto pb=pa; 使用： 123456const double *px=pa[0](av.3);//两种表示法都可以const double *py=pb[1](av.3);//创建指向整个数组的指针。由于数组名pa是指向函数指针的指针auto pc=&amp;pa;//c++11//等价于const double * (*(*pd[3]))(const double *,int)=&amp;pa;//C++98 除了auto外，其他简化声明的工具，typedef进行简化点云库里常常用到,如:typedef pcl::PointNormal PointNT 12typedef const double * (*p_fun)(const double *,int );p_fun p1=f1; 二、函数探幽C++11新特性 函数内联 按引用传递变量 默认参数值 函数重载（多态） 模板函数 1.内联函数c++内联函数–&gt;提高程序运行速度：常规函数与内联函数的区别在于,C++编译器如何将它们组合到程序中 常规函数调用过程： 执行到函数调用指令程序在函数调用后立即存储该指令地址，并将函数参数复制到堆栈中(为此保留的代码)， 跳到标记起点内存单元， 执行函数代码（也许将返回值放入寄存器中）， 然后跳回地址被保存的指令处。 来回跳跃并记录跳跃位置意味着以前使用函数时，需要一定的开销。 情况：函数代码执行时间很短—内联调用就可以节省非内联调用的大部分时间（节省时间绝对值并不大） 代价：需要占用更多的内存：如果程序在是个不同地方调用一个内联函数，则该函数将包含该函数代码的10个副本 使用： 在函数声明前加上关键字inline； 在函数定义前加上关键字inline； 通常的做法是省略原型，将整个定义（即函数头和所有代码），放在本应提供原型的地方。 内联函数不能递归 如果函数占用多行（假设没有冗长的标识符），将其作为内联函数不太合适. 内联与宏C语言使用预处理语句#define来提供宏—内联代码的原始实现 1# define SQUARE(X) X*X 这不是通过传递参数实现的,而是通过文本替换实现的—X是”参数”的符号标记。所以宏不能按值传递 故有时候会出现错误 12c=10;d=SQUARE(C++);is replaced by d=C++*c++=11X12=122 2.按引用传递变量引用变量–&gt;是复合类型int &amp; rodents =rats;其中int &amp;是类型，该声明允许将rats和rodent互换—他们指向相同的值和内存单元。 必须在声明引用变量时进行初始化 引用更接近const指针(指向const数据的指针)，必须在创建时进行初始化，一旦与某个变量关联起来就一直效忠于它。12345int &amp; rodents=rats;//实际上是下述代码的伪装表示int * const pr=&amp;rats;//引用rodents扮演的角色与*pr相同。//*pr值是个地址，且该地址恒等于&amp;rat--&gt;rats的地址 引用的属性与特别之处应该尽可能使用constC++11新增了另外一种引用—右值引用。这种引用可指向右值，是使用&amp;&amp;声明的：第十八章将讨论如何使用右值引用来实现移动语义（move semantics）,以前的引用（使用&amp;声明的引用）现在称为左值引用 右值引用是对临时对象的一种引用，它是在初始化时完成的，但右值引用不代表引用临时对象后，就不能改变右值引用所引用对象的值，仍然可以初始化后改变临时对象的值 右值短暂，右值只能绑定到临时对象。所引用对象将要销毁或没有其他用户 初始化右值引用一定要用一个右值表达式绑定。 例子： 123double &amp;&amp;rref=std::sqrt(36.00);//在左值引用中不成立，即使用&amp;来实现也是不允许的double j=15.0;double&amp;&amp; jref=2.0*j+18.5;//同样使用左值引用是不能实现的。 将引用用于结构引用非常适合用于结构和类(C++用户定义类型)而不是基本的内置类型。 声明函数原型，在函数中将指向该结构的引用作为参数：void set_pc(free_throws &amp; tf);如果不希望函数修改传入的结构。可使用const；void display(free_throws &amp; tf); 返回引用：free_throws &amp;accumlate(free_throws&amp; traget,free_throws&amp; source);为何要返回引用？如果accumlate()返回一个结构，如：dup=accumlate(team,five) 而不是指向结构的引用。这将把整个结构复制到一个临时位置，再将这个拷贝复制给dup。但在返回值为引用时，直接把team复制到dup，其效率更高，复制两次和复制一次的区别。 应避免返回函数终止时，不在存在的内存单元引用。为避免这种问题，最简单的方法是，返回一个作为参数传递给函数的引用。作为参数的引用指向调用函数使用的数据，因此返回引用也将指向这些数据。 1234567free_throws&amp; accumlate(free_throws&amp; traget,free_throws&amp; source){traget.attempts+=source.attempts;traget.mode+=source.mode;set_pc(target);return target;} 另一种方法是用new来分配新的存储空间 1234567const free_throws&amp; clone(&amp;three){free_throws * pt;//创建无名的free_throws结构，并让指针pt指向该结构，因此*pt就是该结构，在不需要new分配的内存时，应使用delete来释放它们。 //auto_ptr模板以及unique_ptr可帮助程序员自动完成释放* pt=ft；return *pt;//实际上返回的是该结构的引用} 将引用用于对象和结构同理 对象继承和引用使得能够将特性从一个类传递给另外一个类的语言被称为继承 ostream–&gt;基类 ofstream–&gt;派生类 基类引用可以指向派生类对象，而无需强制类型转换 时使用引用参数使用引用参数到主要原因有两个： （1）程序员能够修改调用函数中的数据对象。 （2）通过传递引用而不是整个数据对象，可以提高程序的运行速度。 当数据对象较大时（如结构和类对象），第二个原因最重要。这些也是使用指针参数的原因。这是有道理的，因为引用参数实际上是基于指针的代码的另一个接口。那么什么时候应该使用引用，什么时候应该使用指针呢？什么时候应该按值传递呢？下面是一些指导原则： 对于使用传递到值而不做修改到函数： （1）如果数据对象很小，如内置数据类型或小型结构，则按值传递。 （2）如果数据对象是数组，则使用指针，因为这是唯一的选择，并将指针声明为指向const的指针。 （3）如果数据对象是较大的结构，则使用const指针或const引用，以提高程序的效率。这样可以节省复制结构所需要的时间和空间。 （4）如果数据对象是类对象，则使用const引用。类设计的语义常常要求使用引用，这是C++新增这项特性的主要原因。因此，传递类对象参数的标准方式是按引用传递。 对于修改调用函数中数据的函数： （1）如果数据对象是内置数据类型，则使用指针。如果看到诸如fixit(&amp;x)这样的代码（其中x是int），则很明显，该函数将修改x。 （2）如果数据对象是数组，则只能使用指针。 （3）如果数据对象是结构，则使用引用或指针。 （4）如果数据对象是类对象，则使用引用。 当然，这只是一些指导原则，很可能有充分到理由做出其他的选择。例如，对于基本类型，cin使用引用，因此可以使用cin&gt;&gt;n，而不是cin&gt;&gt;&amp;n。 3.默认参数值—当函数调用中省略了实参时自动使用的一个值如何设置默认值？**必须通过函数原型 char* left(const char* str,int n=1);原型声明 定义长这样 char * left(const char* str,int n){…} 对于带参数列表的函数，必须从左向右添加默认值：下面代码错误，int j应该也设默认值 1int chico(int n,int m=6,int j);//fault 通过默认参数，可以减少要定义的析构函数，方法以及方法重载的数量 4.函数重载 默认参数让你能够使用不同数目的参数调用的同一个函数。 而函数多态（函数重载）让你能够使用多个同名函数。 仅当函数基本上执行相同的任务，但使用不同形式的数据时，才应用函数重载 C++使用名称修饰（名称矫正）来跟踪每一个重载函数 未经过修饰：long MyFunction(int,float); 名称修饰（内部转换）：?MyFunctionFoo@@YAXH—&gt;将对参数数目和类型进行编码 重载与多态的区别 重载：是指允许存在多个同名方法，而这些方法的参数不同(特征标不同)。重载的实现是：编译器根据方法不同的参数表，对同名方法的名称做修饰，对于编译器而言，这些同名方法就成了不同的方法。他们的调用地址在编译器就绑定了。重载，是在编译阶段便已确定具体的代码，对同名不同参数的方法调用（静态联编） C++中，子类中若有同名函数则隐藏父类的同名函数，即子类如果有永明函数则不能继承父类的重载。 多态：是指子类重新定义父类的虚方法（virtual,abstract）。当子类重新定义了父类的虚方法后，父类根据赋给它的不同的子类，动态调用属于子类的方法，这样的方法调用在编译期间是无法确定的。（动态联编）。对于多态，只有等到方法调用的那一刻，编译器才会确定所要调用的具体方法。 重载与覆盖的区别 重载要求函数名相同，但是参数列列表必须不不同，返回值可以相同也可以不不同。覆盖要求函数名、参数列列表、返回值必须相同。 在类中重载是同一个类中不同成员函数之间的关系在类中覆盖则是⼦子类和基类之间不同成员函数之间的关系 重载函数的调用是根据参数列表来决定调用哪一个函数 覆盖函数的调用是根据对象类型的不不同决定调用哪一个 在类中对成员函数重载是不不能够实现多态 在子类中对基类虚函数的覆盖可以实现多态 5.模板函数—通用的函数描述 用于函数参数个数相同的类型不同的情况，如果参数个数不同，则不能那个使用函数模板 函数模板自动完成重载函数的过程。只需要使用泛型和具体算法来定义函数，编译器将为程序使用特定的参数类型生成正确的函数定义 函数模板允许以任意类型的方式来定义函数。例如，可以这样建立一个交换模板 12345678template &lt;typename AnyType&gt;void Swap(AnyType &amp;a,AnyType &amp;a){AnyType temp;temp=a;a=b;b=temp;} 模板不会创建任何函数，而只是告诉编译器如何定义函数 C++98没有关键字typename，使用的是template&lt;class AnyType&gt;void Swap(AnyType &amp;a,AnyType &amp;a){...} 函数模板不能缩短可执行程序，最终仍将由两个独立的函数定义，就像以手工方式定义了这些函数一样。最终的代码不包含任何模板，只包含了为程序生成的实际函。使用模板的寒除湿，它使生成多个函数定义更简单，更可靠更常见的情形是将模板放在头文件中，并在需要使用模板的文件中包含头文件 重载的模板对多个不同类型使用同一种算法（和常规重载一样，被重载的模板的函数特征标必须不同）。 1234template &lt;typename T&gt;void Swap(T&amp; a,T&amp; b);template &lt;typename T&gt;void Swap(T* a,T* b,int n); 模板的局限性：编写的模板很可能无法处理某些类型 如1.T为数组时，a=b不成立；T为结构时a&gt;b不成立 解决方案： C++允许重载运算符，以便能够将其用于特定的结构或类 为特定类型提供具体化的模板定义 显式具体化（explicit specialization）提供一个具体化函数定义，其中包含所需的代码，当编译器找到与函数调用匹配的具体化定义时，将使用该定义，不再寻找模板。 该内容在代码重用中有不再重复。 重载解析(overloading resolution)—编译器选择哪个版本的函数对于函数重载，函数模板和函数模板重载，C++需要一个定义良好的策略，来决定为函数调用哪一个函数定义，尤其是有多个参数时 过程： 创建候选函数列表。其中包含与被调用函数的名称相同的函数和模板函数。 使用候选函数列表创建可行函数列表。这些都是参数数目正确的函数，为此有一个隐式的转换序列，其中包括实参类型与相应的形参类型完全匹配的情况。例如，使用float参数的函数调用可以将该参数转换为double，从而与double形参匹配，而模板可以为float生成一个实例。 确定是否有最佳的可行函数。如果有，则使用它，否则该函数调用出错。 最佳到最差的顺序： 完全匹配，但常规函数优先于模板 提升转换（例如，char和shorts自动转换为int ,float自动转换为double）。 标准转换（例如，int转换为char,long转换为double）。 用户定义的转换，如类声明中定义的转换。 完全匹配：完全匹配允许的无关紧要转换 从实参到形参 到实参 Type Type &amp; Type &amp; Type Type[] * Type Type(argument-list) Type( * )(argument-list) Type const Type Type volatile Type Type* const Type Type* volatile Type ***","link":"/2019/05/23/C++/C++11/C++笔记2/"},{"title":"C++ 笔记8","text":"第14章 C++中的代码重用 GitHub 建议下载下来用Typora软件阅读markdown文件 14C++中的代码重用（公有继承，包含对象的类，私有继承，多重继承，类模板）包含（containment）：包含对象成员的类本身是另外一个类的对象。这种方法称为包含（containment），组合（composition），或层次化（laying） 私有继承（还是has-a关系）基类的公有成员和保护成员都将成为派生类的私有成员。和公有继承一样，基类的私有成员是会被派生类继承但是不能被派生类访问。基类方法将不会成为派生类对象公有接口的一部分，但可以在派生类中使用它们。 1.初始化基类组件 和包含不同，对于继承类的新版本的构造函数将使用成员初始化列表语法，它使用类名（std::string，std::valarry）而不是成员名来表示构造函数 1234567891011121314//Student类私有继承两个类派生而来,本来包含的时候两个基类分别是name和scoreclass Student:private std::string,private std::valarry&lt;double&gt;{public:......};//如果是包含的构造函数Student(const char *str,const double *pd,int n):name(str),score(pd,n){}//继承类的构造函数 Student(const char *str,const double *pd,int n):std::string(str),std::valarry&lt;double&gt;(pd,n){} 2.访问基类的方法 a.包含书用对象（对象名）来调用方法 b.私有继承时，将使用类名和作用域解析运算符来调用方法 1234567double Student::Average() const{if(ArrayDb::size()&gt;0）//ArrayDb typedef为std::valarry&lt;double&gt; return ArrayDb::sum()/ArrayDb::size();else return 0;} 3.访问基类对象 使用私有继承时，该string对象没有名称。那么，student类的代码如何访问内部string对象呢？ 强制类型转换! 本来子到父自动类型提升,不需要强制类型转换。父到子才需要强制类型转换。但是下面是强制类型转换，原因在第4点那里写着。 由于Student类是从string类派生而来的，因此可以通过强制类型转换，将Student对象转换为S=string对象 123456//成员方法：打印出学生的名字//因为不是包含，只能通过强制类型转换const string &amp; Student::Name()const{retrun (const string &amp;) *this;} 4.访问基类友的元函数 用类名显式地限定函数名不适合友元函数，因为友元不属于类。不能通过这种方法访问基类。 解决：通过显示地转换为基类来调用正确的函数 1234osstream &amp; operator&lt;&lt;(ostream &amp; os,const Student &amp; stu){os &lt;&lt; \"Score for \"&lt;&lt;(const String &amp;) stu &lt;&lt;\":\\n\";//显式地将stu转换为string对象引用，进而调用基类方法} 引用不会自动转换为string引用原因： a.在私有继承中，未进行显示类型转换的派生类引用或指针，无法赋值给基类的引用或指针。 b.即使这个例子使用的是公有继承，也必须使用显示类型转换。原因之一是，如果不使用类型转换，下述代码将无法与函数原型匹配从而导致递归调用，os&lt;&lt;stu c.由于这个类使用的是多重继承，编译器将无法确定应转换成哪个基类，如果两个基类都提供函数operator&lt;&lt;()。 5.使用包含还是私有继承？通常，应使用包含来建立has-a关系；如果新需要访问原有的保护成员，或重新定义虚函数，则应使用私有继承。 6.保护继承 基类的公有成员和保护成员都将成为派生类的保护成员。 共同点：和私有继承一样，基类的接口在派生类中也是可用的，但在继承和结构之外是不可用的。 区别：使用私有继承时，第三代类将不能使用基类的接口，这是因为公有方法在派生类中将变成私有方法；使用保护继承时，基类的公有方法在第二代将变成保护的，因此第三代派生类可以使用它们。 特征 公有继承 保护继承 私有继承 公有成员变成 派生类的公有成员 派生类的保护成员 派生类的私有成员 保护成员变成 派生类的保护成员 派生类的保护成员 派生类的私有成员 私有成员变成 只能通过基类接口访问 只能通过基类接口访问 只能通过基类接口访问 能否隐式向上转换 是 是（但只能在派生类中） 否 7.使用using重新定义访问权限使用派生或私有派生时，基类的公有成员将成为保护成员或私有成员，假设要让基类方法在派生类外面可用 方法1，定义一个使用该基类方法的派生类方法 1234double Student::sum() const{return std::valarray&lt;double&gt;::sum();} 方法2，将函数调用包装在另外一个函数调用中，即使用一个using声明（就像空间名称一样） 1234567class Student::private std::string,private std::valarray&lt;double&gt;{...public: using std::valarray&lt;double&gt;::min; using std::valarray&lt;double&gt;::max;} //using声明只适用于继承，而不适用于包含//using声明只使用成员名—没有圆括号，函数特征表和返回类型 多重继承必须使用关键字public来限定每一个基类，这是因为，除非特别指出，否则编译器将认为是私有派生。（class 默认访问类型是私有，strcut默认访问类型是公有） 多重继承带来的两个主要问题： 1.从两个不同的基类继承同名方法。 2.从两个或更多相关的基类那里继承同一个类的多个实例。 123class Singer:public Worker{...};class Waiter:public Worker{...};class SingerWaiter:public Singer,public Waiter{...}; Singer和Waiter都继承一个Worker组件，因此SingerWaiter将包含两份Worker的拷贝–&gt;通常可以将派生来对象的地址赋给基类指针，但是现在将出现二义性。（基类指针调用基类方法时不知道调用哪个基类方法），第二个问题：比如worker类中有一个对象成员，那么就会出现 虚基类（virtual base class） 虚基类使得从多个类（他们的基类相同）派生出的对象只继承一个基类对象。1234class Singer:virtual public Worker{...};//virtual可以和public调换位置class Waiter:public virtual Worker{...;//然后将SingingWaiter定义为class SingingWaiter：public Singer,public Waiter{...}; 现在,SingingWaiter对象只包含Worker对象的一个副本 为什么不抛弃将基类声明为虚的这种方式，使虚行为成为MI的准则呢？（为什么不讲虚行为设为默认，而要手动设置） 第一，一些情况下，可能需要基类的多个拷贝； 第二，将基类作为虚的要求程序完成额外的计算，为不需要的工具付出代价是不应当的； 第三，这样做是有缺点的，为了使虚基类能够工作，需要对C++规则进行调整，必须以不同的方式编写一些代码。另外，使用虚基类还可能需要修改已有的代码 虚基类的构造函数（需要修改） 对于非虚基类，唯一可以出现在初始化列表的构造函数是即是基类构造函数。 对于虚基类，需要对类构造函数采用一种新的方法。 基类是虚的时候,禁止信息通过中间类自动传递给基类,因此向下面构造函数将初始化成员panache和voice，但wk参数中的信息将不会传递给子对象Waiter。然而，编译器必须在构造派生对象之前构造基类对象组件；在下面情况下，编译器将使用Worker的默认构造函数（即类型为Worker的参数没有用！而且调用了Worker的默认构造函数） 1SingingWaiter(const Worker &amp;wk,int p=0;int v=Singer:other):Waiter(wk,p),Singer(wk,v){}//flawed 如果不希望默认构造函数来构造虚基类对象，则需要显式地调用所需的基类构造函数。 1SingingWaiter(const Worker &amp;wk,int p=0;int v=Singer:other):Worker(wk),Waiter(wk,p),Singer(wk,v){} 上述代码将显式地调用构造函数worker(const Worker&amp;)。请注意，这种调用是合法的，对于虚基类，必须这样做；但对于非虚基类，则是非法的。 有关MI的问题 多重继承可能导致函数调用的二义性。 假如每个祖先（Singer，waiter）都有Show()函数。那么如何调用 1.可以使用作用域解析符来澄清编程者的意图： 12SingingWaiter newhire(\"Elise Hawks\",2005,6,soprano);newhire.Singer::Show();//using Singer Version 2.然而，更好的方法是在SingingWaiter中重新定义Show(),并指出要使用哪个show。 1P559～P560 1.混合使用虚基类和非虚基类 如果基类是虚基类，派生类将包含基类的一个子对象； 如果基类不是虚基类，派生类将包含多个子对象 当虚基类和非虚基类混合是，情况将如何呢？123456//有下面情况class C:virtual public B{...};//B为虚基类class D:virtual public B{...};//B为虚基类class X: public B{...}; //B为非虚基类class Y: public B{...}; //B为非虚基类class M:public C,public D,public X,public Y{...}; 这种情况下，类M从虚派生祖先C和D那里共继承了一个B类子对象，并从每一个非虚派生祖先X和Y分别继承了一个B类子对象。因此它(M)包含三个B类子对象。 当类通过多条虚途径和非虚途径继承了某个特定的基类时，该类包含一个表示所有的虚途径的基类子对象和分别表示各条非虚途径的多个基类子对象。(本例子中是1+2=3) 2.虚基类和支配(使用虚基类将改变C++解释二义性的方式) 使用非虚基类是，规则很简单，如果类从不同的类那里继承了两个或更多的同名函数（数据或方法），则使用该成员名是，如果没有用类名进行限定，将导致二义性。 但如果使用的是虚基类，则这样做不一定会导致二义性。这种情况下，如果某个名称优先于（dominates）其他所有名称，则使用它时，即使不使用限定符，也不会导致二义性。12345678910111213141516171819202122232425262728293031class B{public:short q();...};class C:virtual public B{public:long q();int omg();...};class D:public C{...}class E:virtual public B{private:int omg();...};class F: public D,public E{...}; 1.类C中的q()定义优先于类B中的q()定义，因为类C是从类B派生而来的。因此F中的方法可以使用q()来表示C::q().（父子类之间有优先级，子类大于父类） 2.任何一个omg()定义都不优先于其他omg()定义，因为C和E都不是对方的基类。所以，在F中使用非限定的omg()将导致二义性。 3.虚二义性规则与访问规则（pravite,public,protected）无关，也就是说即使E::omg是私有的，不能在F类中直接访问，但使用omg()仍将导致二义性。 类模板类模板 类模板和模板函数都是以template开头（当然也可以使用class），后跟类型参数；类型参数不能为空，多个类型参数用逗号隔开。 1234template &lt;typename 类型参数1，typename 类型参数2，typename 类型参数3&gt;class 类名{//TODO} 类模板中定义的类型参数可以用在函数声明和函数定义中， 类模板中定义的类型参数可以用在类型类声明和类实现中， 类模板的目的同样是将数据的类型参数化。 12345678910111213141516template &lt;class Type&gt;class Stack{private: enum {MAX=10}; Type items[MAX]; int top;public: Stack(); ……}template &lt;class Type&gt;Stack&lt;Type&gt;::Stack(){ top=0;} Type:泛型标识符，这里的type被称为类型参数。这意味着它们类似于变量，但赋给它们的不是数字，而只能是类型 相比于函数模板，类模板必须显式的提供所需的类型。 模板不是函数，它们不能单独编译。模板必须与特定的模板实例化(instantiation)请求一起使用,为此，最简单的方法是将所有模板信息放在一个文件中，并在要使用这些模板的文件中包含该头文件。 123//类声明Stack&lt;int&gt;将使用int替换模板中所有的TypeStack&lt;int&gt;kernels;Stack&lt;string&gt;colonels; 深入探讨模板模板具体化（instantiation）和实例化（specialization） 模板以泛型的方式描述类，而具体化是使用具体的类型生成类声明。 类模板具体化生成类声明 类实例化生成类对象 1.隐式实例化(implicit instantiation)他们声明一个或多个对象，指出所需的类型，而编译器使用通用模板提供的处方生成具体的类定义； 12345Array&lt;int,100&gt;stuff;//隐式实例化//在编译器处理对象之间，不会生成隐式实例化，如下Array&lt;double,30&gt;*pt;//a pointer,no object needed yet//下面语句导致编译器生成类定义，并根据该定义创建一个对象昂pt=new Array&lt;double,30&gt;; 2.显式实例化(explicit instantiation) 当使用关键字template并指出所需类型来声明类时，编译器将生成类声明的实例化 1template class ArrayTP&lt;string,100&gt;; 这种情况下，虽然没有指出创建或提及类对象，编译器也将生成类声明（包含方法定义）。和隐式实例化也将根据通用模板来生成具体化。 3.显式具体化(explicit specialization)—是特定类型（用于替换模板中的泛型）的定义格式：template&lt;&gt;class Classname{…};有时候，可能需要在特殊类型实例化是，对模板进行修改，使其行为不同。在这种情况下，可以创建显式实例化。 12345//原来的类模板template &lt;typename T&gt;class sortedArray{...//details omitted}; 当具体化模板和通用模板都与实例化请求匹配时，编译器将使用具体化版本。 12345//新的表示法提供一个专供const char*类型使用的SortedArray模板template&lt;&gt;class SortedArray&lt;const char*&gt;{...//details omitted}; 4.部分具体化(partical specialization) 部分限制模板的通用性 1234//general template 一般模板 template&lt;class T1,class T2&gt;class Pair{...};//specialization with T2 set to int部分具体化 template&lt;class T1&gt;class Pair&lt;T1,int&gt;{...}; 如果有多个模板可供选择，编译器将使用具体化程度最高的模板 123Pair&lt;double,double&gt;p1;//使用了一般的Pair类模板Pair&lt;double,int&gt;p2;//使用了部分具体化Pair&lt;T1,int&gt;Pair&lt;int,int&gt;p3//使用了显式实例化Pair&lt;int,int&gt; 也可以通过为指针提供特殊版本来部分具体化现有模板： 1234template&lt;class T&gt;class Feen{...};//一般版本的类模板template&lt;class T*&gt;class Feen{...};//部分具体化 将模板用作参数template&lt;template&lt;typename T&gt;class Thing&gt;class Crab 模板类和友元 模板类声明也可以有友元。模板的友元分为3类： 非模板友元： 约束(bound)模板友元，即友元的类型取决于类被实例化时的类型； 非约束(unbund)模板友元，即友元的所有具体化都是类的每一个具体化的友元。 模板类的非模板友元函数 在模板类中奖一个常规函数声明为友元：1234567template &lt;class T&gt;class HasFriend{public:friend void counts();...}; 上述声明指定counts()函数称为模板所有实例化的友元 counts()函数不是通过对象调用（它是友元不是成员函数），也没有对象参数，那么如何访问HasFriend对象？ 1.它可以访问全局对象 2.它可以使用全局指针访问非全局对象 3.可以创建自己的对象 4.可以访问独立于对象的模板类的静态成员函数 模板类的约束模板友元 1.首先，在类定义的前面声明每个模板函数 templatevoid counts();templatevoid report(T &amp;); 2.然后，在函数中再次将模板声明为友元。这些语句根据类模板参数的类型声明 1234567template&lt;typename TT&gt;class HasFriendT{...friend coid counts&lt;TT&gt;();friend coid report&lt;&gt;(HasFriendT&lt;TT&gt; &amp;);}; 3.为友元提供模板定义 模板类的非约束模板友元函数 前一节中的约束模板友元函数在类外面声明的模板的具体化。int类具体化获得int函数具体化，依此类推。通过类内部声明模板，可以创建非约束友元函数，即每个函数具体化都是每个类具体化的友元。对于非约束友元，友元模板类型参数与模板类类型参数是不同的：123456template&lt;typename T&gt;class ManyFriend{...template&lt;typename C,typename D&gt;friend void show2(C &amp;,D &amp;);}; 模板别名(C++11) 1.如果能为类型指定别名，浙江爱你个很方便，在模板设计中尤为如此。可使用typedef为模板具体化指定别名 1234567typedef std::array&lt;double,12&gt; arrd;typedef std::array&lt;int,12&gt; arri;typedef std::array&lt;std::string,12&gt; arrst;//使用arrd gallones；arri days;arrst months; 2.C++11新增了一项功能—使用模板提供一系列别名 12template&lt;typename T&gt;using arrtype=std::array&lt;T,12&gt;;//template aliases 这将arrtype定义为一个模板别名，可以用它来指定类型 123arrtype&lt;double&gt; gallones;arrtype&lt;int&gt; days;arrtype&lt;std::string&gt; months; C++11允许将语法using=用于非模板。用于非模板是，这种语法与常规typedef等价：12typedef const char *pc1; //typedef syntax/ 常规typedef语法using pc2=const char*; //using = syntax/ using =语法 可变参数模板(variadic template)18章","link":"/2019/05/24/C++/C++11/C++笔记8/"},{"title":"C++ 笔记3","text":"第9章 内存模型和名称空间 GitHub 建议下载下来用Typora软件阅读markdown文件 9内存模型和名称空间（4）原来的程序分为三个部分 头文件：包含结构声明和使用这些结构的函数的原型//结构声明与函数原型 源代码文件：包含与结构有关的函数代码 //函数 源代码文件：包含调用与结构相关的函数的代码 //调用函数 这种组织方式也与oop方式一致。 一个文件（头文件）包含用户定义类型的定义； 另外一个文件包含操纵用户定义类型的函数代码； 这两个文件组成了一个软件包，可用于各种程序中。 请不要将函数定义或变量声明放在头文件中，如果其他文件都包含这个头文件，那么同一个函数就会有多次定义，变量也同理，会出错。 头文件中常包含的内容： 函数原型。 使用#define或const定义的符号常量（头文件中不可以创建变量） 结构声明=&gt;因为它们不创建变量 模板声明=&gt;模板声明不是将被编译的代码，他们指示编译器如何生成源代码中的函数调用相匹配的函数定义。 内联函数–&gt;只有它可以在头文件定义函数。 被声明为const的数据和内联函数有特殊的链接属性 注意：在IDE中 不要将头文件加入到项目列表中 也不要在源代码文件中使用#include来包含其他源代码文件 在同一文件中只能将同一个头文件包含一次。–&gt;使用预编译指令 1234#ifndef COORDIN_H_...#endif 但是这种方法并不能防止编译器将头文件包含两次，而只是让它忽略第一次包含之外的所有内容。大多数标注C和C++头文件都是用各种防护(guarding)方案。否则，可能在一个文件中定义同一个结构两次，这将导致编译错误。 编译在UNIX系统中编译由多个文件组成的C++程序 编译两个源代码文件的UNIX命令： CC file1.cpp file2.cpp 预处理将包含的文件与源代码文件合并： 临时文件： temp1.cpp temp2.cpp 编译器创建每个源代码文件的目标代码文件：file1.o file2.o 链接程序将目标代码文件(file1.o file2.o)、库代码(Library code)和启动代码(startup code)合并，生成可执行文件：a.out 多个库的链接 由不同编译器创建的二进制模块（对象代码文件）很可能无法正确地链接。 原因：两个编译器为同一个函数生成不同的名称修饰 名称的不同将使链接器无法将一个编译器生成的函数调用与另外一个编译器生成的函数定义匹配。在链接编译模块时，请确保所有对象文件或库都是由同一编译器生成的。 链接错误解决的方法：如果有源代码，通常可以用自己的编译器重新编译来消除错误。 存储持续性，作用域与和链接性C++中的四种存储方案 自动存储持续性 :在函数定义中声明的变量（包括函数参数）的存储持续性为自动的。它们在程序开始执行其所属的函数或代码块时被创建，在执行完函数或代码块时，它们使用的内存被释放。 静态存储持续性 :在函数定义外定义的变量（又称为外部变量）和使用关键字static定义的变量的存储持续性都为静态。（请注意）它们在整个运行过程中都存在。 线程存储持续性(C++11) :当前，多核处理器很常见，这些CPU可同时处理多个执行任务。这让程序能够将计算放在可并行处理的不同线程中。如果变量是使用关键字thread_local声明的，则其生命周期与所属的线程一样长。 动态存储持续性 :用new运算符分配的内存将一直存在，直到使用delete运算符将其释放或程序结束为止。这种内存的存储持续性为动态，有时被称为自由存储(free store)或堆(heap)。 作用域和链接性 作用域(scope) 描述了名称在文件的多大范围内可见。例如，函数中定义的变量可在该函数中使用，但不能在其他函数中使用；而在文件中的函数定义之前定义的变量则可在所有函数中使用。 作用域：局部与全局–&gt;(代码块/文件) 作用域为局部的变量只在定义它的代码块中可用。（代码块：由花括号括起的一系列语句，比如：函数体） 作用域为全局（也叫文件作用域）的变量在定义位置到文件结尾都可以用。 链接性(linkage) 描述了名称如何在不同单元间共享。链接性为外部的名称可在文件间共享，链接性为内部的名称只能由一个文件中的函数共享，自动变量的名称没有链接性，因为它们不能共享。 C++内存空间分布1.命令行参数和环境变量 shell在执行程序的时候调用exec函数将命令行参数传递给要执行的程序。 使程序了解进程环境，在执行时分配空间。 2.bss段（Block Start by Symbol） 存放未初始化的全局变量或者静态变量。 3.data段 存放具有明确初始值的全局变量或者静态变量。 存在于程序镜像文件中，由 exec 函数从程序镜像文件中读入内存。 4.text段 CPU执行的机器指令。 堆栈简要概述栈：系统自动开辟空间，自动分配自动回收，在作用域运行完成后（函数返回时）就会被回收。 堆：由程序员自己申请空间，释放空间，不释放会出现内存泄漏。 栈 1.栈是连续的向下扩展的数据结构，总共只有1M或者2M的空间。空间不足就会异常提示栈溢出。 2.存储自动变量, 函数调用者信息, 包括函数参数(可变参数列表的压栈方向是从右向左), 函数内局部变量, 函数返回值, 函数调用时的返回地址。 堆 1.堆是不连续的向上扩展的数据结构，大小受限于计算机系统虚拟内存的大小。 2.操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。 对于大多数系统，会在这块内存空间中的首地址处（一般为一个字节的大小）记录本次分配的大小，这样，代码中的 delete语句才能正确的释放本内存空间。 由于找到的堆结点的空间大小可能大于申请的大小，系统会自动的将多余的那部分（即内存碎片）重新放入空闲链表中。这就涉及到申请效率的问题。 引入名称空间之前下面列出5种变量存储方式（引用名称空间之前） 存储描述 持续性（变量寿命） 作用域（变量可见性） 链接性（变量名字共享性） 如何声明 自动 自动 代码块 无 在代码块中 寄存器 自动 代码块 无 在代码块中，使用关键字register 静态,无链接性 静态 代码块 无 在代码块中，使用关键字static 静态,外部链接性 静态 文件 外部 不在任何函数内 静态,内部链接性 静态 文件 内部 不在任何函数内，使用关键字static 自动存储持续性 在默认情况下，在函数中声明的函数参数和变量的存储持续性为自动，作用域为局部，没有链接性（自动变量不能共享）。 自动变量的初始化：可以使用任何声明时其值已知的表达式来初始化自动变量int x=5;int y=2*x; 自动变量和栈：自动变量的数目随函数的开始和结束而增减，因此程序必须在运行是对自动变量进行管理。常用方法是流出一段内存，并将其视为栈。程序使用两个指针来跟踪栈，一个指向栈底，栈的开始位置。另外一个指针指向栈顶，下一个可用内存单元。栈是LIFO（后进先出）的，即最后加入到栈中的变量首先被弹出。 寄存器变量–&gt;旨在提高访问变量的速度 关键字register最初由C语言引入的，它建议编译器使用CPU寄存器来存储自动变量 1register int count_fast;//request for a register variable 鉴于关键字register只能用于原来就是自动的变量，使用它的唯一原因是，指出程序员想使用一个自动变量，这个变量名可能与外部变量相同 静态持续变量 C++也为静态存储持续性提供了三种链接性 1.外部链接性（可在其他文件中访问） 2.内部链接性（只能在当前文件中访问） 3.无链接性（只能在当前函数或代码块中访问） 这三种链接性都在整个程序执行期间一直存在，与自动变量相比，他们的寿命更长。由于静态变量的数目在程序运行期间是不变的，因此程序不需要使用特殊的装置（如栈）来管理它们，编译器将分配固定的内存块来存储所有的静态变量，这些变量在整个程序执行期间一直存在。另外，如果没有显示地初始化静态变量，编译器将把它设置为0。在默认情况下，静态数组和结构将每个元素或成员的所有位都设置为0。被称为0初始化 例子： 123456789101112int NUM_ZDS_GLOBAL = 80; //#1static int NUM_ZDS_ONEFILE = 50; //#2int main(){…}void fun1(int n){static int nCount = 0; //#3int nNum = 0; //#4}void fun2(int q){ …} #1、#2、#3在整个程序运行期间都存在。在fun1中声明的#3的作用域为局部，没有链接性，这意味着只能在fun1函数中使用它，就像自动变量#4一样。但是，与#4不同的是，即使在fun1没有被执行的时候，#3也保留在内存中。 静态变量初始化 123456#include&lt;cmath&gt;int x; //零初始化 int y=5; //常量表达式初始化long z=13*13; //常量表达式初始化const double pi=4.0*atan(1.0);//动态初始化，要初始化pi，必须调用函数atan()，这需要等到函数被链接上且程序执行时。（这也是常量表达式初始化）//C++新增关键字constexpr，这增加了创建常量表达是的方式 1.静态持续性，外部链接性==&gt;普通全局变量链接性为外部的变量通常称为外部变量，它们的存储持续性为静态，作用域为整个文件。 外部变量是函数外部定义的，因此对所有函数而言都是外部的。 例如，可以在main()前面或头文件中定义他们。可以在文件中位于外部定义后面的任何函数中使用它。 因此外部变量也称为全局变量。 全局变量是在所有函数体的外部定义的，程序的所在部分（甚至其它文件中的代码）都可以使用。全局变量不受作用域的影响（也就是说，全局变量的生命期一直到程序的结束）。如果在一个文件中使用extern关键字来声明另一个文件中存在的全局变量，那么这个文件可以使用这个数据。 单定义规则一方面，在每个使用外部变量的文件中，都必须声明它；另外一方面，C++有“单定义规则”，该规则指出，变量只有一次定义。 为满足这种需求，C++提供了两种变量声明。 一种是定义声明（defining declaration）或简称为定义（definition），它给变量分配存储空间。 一种是引用声明（referencing declaration）或简称为声明（declaration），它不给内存变量分配存储空间。 引用声明使用关键字extern，且不进行初始化；否则，声明未定义，导致分配内存空间：例 123double up;//definition,up is 0 定义extern int bllem;//blem defined elsewhere 声明，blem变量在某处定义了extern char gr = 'z';//definition because initialized 定义 注意： 单定义规则并非意味着不能有多个变量名称相同 如果函数中声明了一个与外部变量同名的变量，结果将如何呢？ 12345678910111213141516//external1.cpp 文件1double warning=0.3;//warning defined 定义//support.cpp 文件2extern double warning;//use warning from another file 使用外部定义的变量warning......void update(double dt){extern double warning;//optional redeclaration......}void local(){//定义域全局变量名相同的局部变量都，局部变量将隐藏全局变量double warning=0.8;//new variable hides external one......} 通常情况下，应使用局部变量，然而全局变量也有它们的用处。例如，可以让多个函数可以使用同一个数据块（如月份，名数组或原子量数组）。外部存储尤其适用于表示常量数据，因为这样可以使用关键字const来防止数据修改。 2.静态持续性，内部链接性==&gt;Static全局变量 全局变量（外部变量）的说明之前再冠以static就构成了静态的全局变量。全局变量本身就是静态存储方式，静态全局变量当然也是静态存储方式。 这两者在存储方式上并无不同。这两者的区别在于非静态全局变量的作用域是整个源程序，当一个源程序由多个原文件组成时，非静态的全局变量在各个源文件中都是有效的。而静态全局变量则限制了其作用域，即只在定义该变量的源文件内有效，在同一源程序的其它源文件中不能使用它。 由于静态全局变量的作用域限于一个源文件内，只能为该源文件内的函数公用，因此可以避免在其他源文件中引起错误。 static全局变量与普通的全局变量的区别是static全局变量只初始化一次，防止在其他文件单元被引用。 3.静态持续性，无链接性==&gt;静态局部变量这种变量是这样创建的，将static限定符用于代码块中定义的变量。 在两次函数调用之间，静态局部变量的值将保持不变，它同时拥有静态变量和局部变量的特性，即： 编译时自动初始化 会被放到静态内存的静态区 只能在局部被访问 作用：有时候我们需要在两次调用之间对变量进行保存，通常的想法是定义一个全局变量来实现。但这样一来变量就不属于函数本身了，而受全局变量的控制。静态局部变量正好可以解决这个问题，静态局部变量保存在全局数据区，而不是保存在栈中，每次的值保持到下一次调用，直到下一次赋新值 说明符和限定符存储说明符(storage class specifier) auto(在C++11中不再是说明符)：在C++11之前，可以在声明中使用关键字auto来指出变量为自动变量；但在C++11中，auto用于自动类型推断。 register：用于在声明中指示寄存器存储，在C++11中，它只是显式地指出变量是自动的。 static:关键字static被用在作用域为整个文件的声明中时，表示内部链接性；被用于局部声明中，表示局部变量的存储持续性为静态的。 thread_local(C++11新增)：可以用static或extern结合使用，关键字thread_local指出变量持续性与其所属的持续性相同。thread_local变量之于线程，由于常规静态变量至于整个程序。 mutable：关键字mutable的含义根据const来解释 mutable:可以用来指出，即使结构（或类）变量为const，其某个成员也可以被修改。 12345678910struct data{char name[30];mutable int accesses;...}const data veep={\"claybourne clodde\",0,...};strcpy(veep.name,\"ytttt\"); //not allowedveep.accessses++; //allowed CV限定符（cv-qualifier） const:它表明，内存被初始化后，程序便不能再对他进行修改。 volatile: volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问 再谈const const限定对默认存储类型稍有影响。在默认情况下，全局变量的链接性为外部的，但const全局变量的链接性为内部的 1234const int fingers = 10;//same as static const init fingers=10;int main(){...} 原因：C++这样子修改了常量类型的规则，让程序员更轻松 假如，假设将一组常量放在头文件中，并在同一程序的多个文件中使用该头文件。那么预处理器将头文件中的内容包含到每个源文件后，所有的源文件都将包含类似下面的定义： 12const int fingers=10;const char* warning =\"wak!\"; 如果全局const声明的链接性像常规变量那样是外部的，则根据单定义规则，这将出错（二义性）。也就是说只能有一个文件可以包含前面的声明，而其他文件必须使用extern关键字来提供引用声明。另外只有未使用extern关键字的生命才能进行初始化。 然而，由于外部定义的const数据的链接性为内部的，因此可以在所有文件中使用相同的声明。 内部链接性意味着每个文件都有自己一组常量，而不是所有文件共享一组常量。每个定义都是其所属文件所私有的，这就是能够将常量定义放在头文件中的原因。 函数和链接性 和C语言一样，C++不允许在一个函数中定义另外一个函数=&gt;因此所有函数的存储持续性都自动为静态的，即整个程序执行期间都一直存在。 在默认情况喜爱，函数的链接性为外部的，即可以在文件间共享。 实际上可以使用extern关键字来指出函数是在另外一个文件中定义的，不过这是可选的。 使用关键字static将函数链接性改为内部链接性，使其只能在本文件中使用，必须在原型和函数定义中同时使用该关键字。 单定义规则也适用于非内联函数，因此对于每个非内联函数，程序只能包含一个定义。对于链接性味外部的函数来说，这意味着在多文件程序中，只能有一个文件包含该函数的定义，但使用该函数的每个文件都应包含其函数原型。 内联函数不受这种规则的约束，这允许程序员能够将内联函数的定义放在头文件中，这样包含了头文件的每个文件都有内联函数的定义。然而，C++要求同一个函数的所有内联定义都必须相同。 C++在哪里寻找函数？假设在程序的某个文件中调用一个函数，C++将到哪里寻找函数定义？ 如果该文件中的函数原型指出该函数是静态的，则编译器将只在该文件中查找函数定义； 否则，编译器（包括链接程序）将在所有文件中查找。 如果在程序文件中找不到，编译器将在库中搜索。这意味着，如果定义了一个与库函数同名的函数，编译器将使用程序员定义的版本，而不是库函数。 语言链接性链接程序要求每个不同的函数都有不同的符号名。在C语言中，一个名词只对应一个函数，因此这很容易实现。为满足内部需要，C语言编译器可能将spiff这样的函数名翻译为_spiff。这种方法称为C语言链接性（C language linkage）。但在C++中，同一个名称可能对应多个函数，必须将这些函数翻译为不同的符号名称。因此，C++编译器执行名称纠正或名称修饰，为重载函数生成不同的符号名称。例如，spiff（int）转换为—_spiff_i，而将spiff(double, double)转换为_spiff_d_d。这种方法称为C++语言的链接性（C++ language linkage）。 如果要在C++程序中使用C语言预编译的函数，将出现什么情况呢？例如，假设有如下代码：spiff(22);它在C库文件中的符号名称为_spiff,但对于我们的C++链接程序来说，C++查询约定是查找符号民称_spiff_i。为解决这样的问题，可以用函数原型来指出要使用何种约定： 123extern “C” void spiff(int);//使用C语言链接性extern void spoff(int);//使用C++语言的链接性(通过默认方式指出)extern “C++” void spaff(int);//使用C++语言的链接性（通过显式指出） C和C++链接性是C++标准制定的说明符，但实现可以提供其他语言链接性说明符。 存储方案和动态分配使用C++运算符new（或C函数malloc()）分配的内存，这种内存被称为动态内存，动态内存由运算符new和delete控制，而不是由作用域和链接性规则控制。因此，可以在一个函数中分配动态内存，而在另外一个函数中将其释放。其分配方式要取决于new和delete在何时以何种方式被使用。通常编译器使用三块独立的内存： 一块用于静态变量（可能再细分） 一块用于自动变量 另外一块用于动态存储 虽然存储方案概念不是用于动态内存，但适用于用来跟踪动态内存的自动和静态指针变量（自动指针变量，静态指针变量），指针变量还是有作用域和链接性的 new运算符如果要为内置的标量类型（int、double）分配存储空间并初始化，可在类型名后面加上初始值，并将其用括号括起。 1int *pi = new int(6); 要初始化常规结构或数组，需要使用大括号的列表初始化，这要求编译器支持C++11。 123struct where{double x, double y, double z};where *one = new where{2.5, 5.3, 7.2};int *ar = new int[4] {2, 4, 7, 6}; 在C++11中，还可将初始化列表用于单值变量： 1int *pin = new int {6}; new失败时 在最初的10年中，C++让new失败时返回空指针，但现在将引发std::bad_alloc异常。 new：运算符、函数和替换函数运算符与函数： 1234567891011//分配函数（allcation function）；void *operator new(std::size_t);//函数void *operator new[](std::size_t);//函数//释放函数（deallocation function）；void *operator delete(void *);//函数void *operator delete[](void *);//函数int *pi=new int;//运算符int *pi=new(sizeof(int));//函数int *pi=new int[40];//运算符int *pi=new(40*sizeof(int));//函数 替换函数： 有趣的是，C++将这些函数（分配函数，释放函数）称为可替换的（replaceable）。这意味着如果您有足够的知识和意愿，可为new和delete提供替换函数，并根据需要对其进行定制。例如，可定义作用域为类的替换函数，并对其进行定制，以满足该类的内存分配需求。在代码中，仍将使用new运算符，但它将调用您定义的new()函数。 定位new运算符通常，new负责在堆（heap）中找到一个足以能够满足要求的内存块。new运算符还有另一种变体，被称为定位（placement）new运算符，它让您能够指定要使用的位置。程序员可能使用这种特性来设置其内存管理规程、处理需要通过特定地址进行访问的硬件或在特定位置创建对象。 要使用定位new特性，首先需要包含头文件new，它提供了这种版本的new运算符的原型；然后将new运算符用于提供了所需地址的参数。除需要指定参数外，句法与常规new运算符相同。具体地说，使用定位new运算符时，变量后面可以有方括号，也可以没有。下面的代码段演示了new运算符的4种用法： 1234567891011121314#include &lt;new&gt;char buffer1[50];//静态数组char buffer2[500];struct chaff{char dross[20];int slag;};chaff *p1, *p2;int *p3, *p4;p1=new chaff; //place structure in heapp3=new int[20]; //place int array in heapp2=new (buffer1) chaff; //place structure in buffer1p4=new (buffer2) int[20]; //place int array in buffer2 上述代码从buffer1中分配空间给结构chaff，从buffer2中分配空间给一个包含20个元素的int数组。 定位new运算符的其他形式就像常规new调用一个接受一个参数的new函数一样，标准定位new调用一个接收两个参数的new函数。 123int * p1=new int;//调用 new(sizeof(int))int * p2=new(buffer) int;//调用 new(sizeof(int),buffer)int * p3=new(buffer) int[40];//调用new(40*sizeof(int),buffer) 定位new运算符不可替换，但可重载。至少需要接收两个参数，其中第一个总是std::size_t，指定了请求的字节数。这样的重载函数都被定义为new。 名称空间在C++中，名称可以是变量，函数，结构，枚举，类以及类的结构成员 两个概念：声明区域、潜在作用域声明区域(declaration region) 可以在其中进行声明的区域 在函数外面声明全局变量=&gt;对这种变量，其声明区域为其声明所在的文件。对于在函数声明的变量=&gt;其声明区域为其声明所在的代码块。 潜在作用域（potential scope） 变量潜在作用域从声明点开始，到其声明区域的结尾。因此潜在作用域比声明区域小，这是由于变量必须定义后才能使用。 变量并非在其潜在作用域的任何位置都是可见的。 例如，它可能被另外一个嵌套声明区域中声明的同名变量隐藏 例如，在函数声明的局部变量（对于这种变量，声明区域为整个函数）将隐藏在同一文件中声明的全局变量（对于这种变量，声明区域为整个文件）。 变量对程序而言可见的范围被称为作用域（scope）。 新的名称空间(命名的名称空间)即通过定义一种新的声明区域来创建命名的名称空间，这样做的目的之一是提供一个声明名称的区域。一个名称空间中的名称不会和另一个名称空间中的名称发生冲突，同时允许程序的其他部分使用该名称空间中声明的东西。 关键字namespace 名称空间可以是全局的，也可以位于另一个名称空间中，但是不能位于代码块中。因此在默认情况下，在名称空间中声明的名称的链接性为外部的（除非它引用了常量）。 除用户定义的名称空间，还存在另外一个名称空间全局名称空间(global namespace)。它对应文件级声明区域，因此前面所说的全局变量现在被描述为位于全局名称空间中 using 声明和using编译指令 using声明使特定的标识符可用: 1 using std::cout;//将cout添加到它所属的声明区域中，即使得cout能够在main函数中直接使用 using编译指令使整个名称空间可用： 1 using namespace std;//使得std空间中所有的名称都可以直接使用 using编译指令和using声明之比较 使用using声明时，就好像声明了相应的名称一样，如果某个名称已经在函数中声明了，则不能用using声明导入相同的名称。 然而，使用using编译指令时，将进行名称解析，就像在包含using声明和名称空间本身的最小声明区域中声明了名称一样。如果使用using编译指令倒入一个已经在函数中声明的名称，则局部名称将隐藏名称空间名，就像隐藏同名的全局变量一样。 一般来说，使用using声明要比使用using编译指令更加安全，这是由于它只能导入指定的名称，如果该名称与局部名称发生冲突，编译器将发出指示。 using编译指令导入所有的名称，包括可能并不需要的名称，如果与局部名称发生冲突，则局部名称将覆盖名称空间版本而编译器不发出警告！ 另外，名称空间的开放性意味着名称空间的名称可能分散在多个地方，这使得难以准确知道添加了哪些名称。所以我们平时自己写程序时先怼一个using namespace std;上去可能并不是一个很好的决定。","link":"/2019/05/23/C++/C++11/Cppnote3/"},{"title":"C++ 笔记(总)","text":"C++ Primer Plus(第六版)笔记 GitHub 建议下载下来用Typora软件阅读markdown文件 1～4基础 浮点运算的速度通常比整型运算慢， 对于标量运算float和double都不了没有明显差别 对于矢量运算double比float慢得多 运算符重载（operator overloading）：使用相同符号进行多种操作 1.C++内置重载 9/5 int ； 9L/5L long ； 9.0/5.0 double ； 9.0f/5.0f float 2.C++扩展运算符重载 int guess(3.9832);结果：guess=3; 将浮点float转换为整型int时，采用截取（丢弃小数部分），而不是四舍五入 将一个值赋值给取值范围更大的类型通常不会导致什么问题，只是占用的字节更多而已。 列表初始化(使用大括号初始化)不允许窄缩（float--&gt;int）。 (long)thorn; long(thron);强制类型转换不会改变thorn变量本身，而是创建一个新的，指定类型的值。 auto让编译器能够根据初始值的类型推断变量的类型。 C++的基本类型 整数值(内存量及有无符号)： bool,char,signed char,unsigned char,short,unsigned short,int,unsigned int,long,unsigned long,(新)long long,unsigned long 浮点格式的值：float(32位),double(64位),long double（94～128位） 复合类型：数组；字符串：1.字符数组char array 2.string类；结构：struct；共同体：union；枚举：enum；指针：int* ,long*数组（array）123456short months[12];int yamcosts[3]={20,30.5};double earning[4]{1.2e4,1.6e4,1.4e4,1.7e4};float balances[100]{};//初始化全部元素值为0//字符串char boss[8]=\"Bozo\"//后面四个元素为\"\\0\"空字符 using using namespace XXX;这是指示 引入名称空间内所有的名称：将XXX名称空间，所有成员变成可见，作用域和using声明一致；例：using namespace std; using XXX;这是声明 引入名称空间或基类作用域内已经被声明的名称：一次只引入一个命名空间成员;using std::cout; 类之于对象，类型之于变量对象和变量都是用来描述一段内存的。 变量更强调的是变量名这个符号的含义，更强调名字与内存的联系，而不必关注这段内存是什么类型，有多少字节长度，只关注这个变量名a对应着某段内存。 而对象的描述更强调的是内存的类型而不在乎名字，也就是说,从对象的角度看内存，就需要清除这段内存的字节长度等信息，而不是关注这个对象在代码中是否有一个变量名来引用这段内存。struct结构 struct和class的区别 struct能包含成员函数吗？ 能！ struct能继承吗？ 能！！ struct能实现多态吗？ 能！！！ 既然这些它都能实现，那它和class还能有什么区别？最本质的一个区别就是默认的访问控制，体现在两个方面：默认继承访问权限和默认成员访问权限 1）默认的继承访问权限。struct是public的，class是private的。 2）struct作为数据结构的实现体，它默认的数据访问控制是public的，而class作为对象的实现体，它默认的成员变量访问控制是private的。 做个总结，从上面的区别，我们可以看出，struct更适合看成是一个数据结构的实现体，class更适合看成是一个对象的实现体。 共用体union 它能够存储不同的数据类型，但只能同时存储其中的一种类型。 这种特性使得当数据项使用两种或更多种格式（但不会同时使用）时，可节省空间。 使用场合：1.对内存的使用苛刻，如嵌入式系统编程 2.操作系统数据结构或硬件数据结构 枚举 enum 提供了一种创建符号常量的方式，这种方式可以替代const。 它还允许定义新的类型，但必须按严格的限制进行。123456789101112enum spectrum{red,orange,yellow,green,blue,violet,indigo,wltraciolet};//对应整数值0～7（声明定义）//在不进行强制类型转换的情况下，只能将定义使用的枚举量赋给这种枚举的变量。spectrum band；//声明定义band = blue;//初始化（赋值）//枚举量是整型，可悲提升为int型int color = blue;//设置枚举量的值；enum bits{one=1,two=2,four=4,eight=8};enum bigstep{first,second=100,third};//first=0,third=101//枚举的取值范围bits myflag;myflag=bits(6);//强制类型转换（整数值），保证bits()输入的参数小茹bits的上限，上限=(2^n-1)&gt;max,max在bits中等于8 指针和自由存储空间1.使用常规变量时，值是指定的量，而地址为派生量。指针与C++基本原理1.编译阶段：编译器将程序组合起来 2.运行阶段：程序正在运行时–》oop强调的是在运行阶段进行决策 考虑为数组分配内存的情况，C++采用的方法是：使用关键字new请求正确数量的内存以及使用指针来跟踪新分配内存的位置2.处理存储数据的新策略刚好相反，将地址视为指定的量，将之视为派生量*运算符被称为间接值运算符或叫解除引用运算符（对指针解除引用意味着获得指针指向的值）。 &amp;地址运算符 注意：int * p1,p2;p1是指针，p2是int变量；对于每个指针变量名，都需要一个* 定义与初始化12345int h = 5;int *pt =&amp; h;//或int *pt;pt = &amp;h; 应用*之前，一定要将指针初始化为一个确定的，适当的地址。就是说一定要初始化，否则*pt 将值会赋给一个未知内存。否者都还没引用，又怎么接触引用呢？ 要将数字值作为地址来使用，应通过强制类型转换将数字转换为适当的地址类型。1pt=(int *)0×B8000000; 使用new来分配内存变量：在编译时分配的有名称的内存。 指针的真正的用武之地在于，在运行阶段分配未命名的内存以及存储值，（C++中使用new运算符来实现）在这种情况下，只能通过指针来访问内存—&gt;所以new的出现都会有指针。 12typeName * pointer_name=new typeName;//使用new分配未命名的内存* pointer_name=1000;//对该未去命名的内存赋值 new从被称为堆（heap）或自由存储区(free store)的内存区域分配内存。delete pointer_name;//释放指针pointer_name指向的内存。释放pointer_name指向的内存，但不会删除pointer_name指针本身。例如，可以将pointer_name重新指向另外一个新分配的内存块。不要创建两个指向同一内存块的指针 对于大型数据对象来说，使用new，如数组、字符串、结构。 1.静态联编（static binding） 如果通过声明来创建数组，则程序被编译时将为它分配内存空间，不管程序最终是否使用数组，数组都在那里。它占用了内存，所以必须指定数组长度。 2.动态联编（dynamic binding） 意味着数组是在程序运行时创建的，这种数组叫作的哦你太数组。 使用new创建动态数组–&gt;Vector模板类是替代品 1234//创建int * psome =new int[10];//释放delete[] psome;//方括号告诉程序，应释放整个数组。 指针和数组等价的原因在于指针算术 将整数变量加1后，其值将增加1， 将指针变量加1后，增加的量等于它指向类型的字节数。 指针与数组之间的转换 数组：arrayname[i]等价于*(arrayname+i) 指针：pointername[i]等价于*(pointername+i) 因此，很多情况下，可以使用相同的方式使用数组名和指针名 const char *bird ='&quot;wren&quot;bird的值可以修改，但*bird值不可以修改。其实应该说是不能使用bird指针来修改！！！ 常量指针：const修饰的是“char * bird”，里面的值是不可以改变的。可以使用指针bird访问字符串“wren”但不能修改字符串。 char * const p =&quot;wren&quot;; 指针常量：const修饰的是指针“p”，指针的值是不能改变的。使用new来创建动态结构运行时创建数组（结构）由于编译时创建数组（结构） 创建一个未命名的inflatable类型，并将其地址赋给一个指针。 1inflatable *ps=new inflatble C++有三种管理数据内存的方式（不是说物理结构） 自动存储 静态存储 动态存储–&gt;有时也叫自由存储空间或堆 线程存储（C++11新增–&gt;第9章） 自动存储：自动变量（函数内部定义的常规变量）通常存储在栈中 —&gt;随函数被调用生产，随该函数结束而消亡 —&gt;自动变量是个局部变量，作用域为包含的代码块（{…}） 静态存储：使变量称为静态 1.在函数外面定义它 2.在声明变量是使用static关键字 static double free = 5650; 动态存储：使用new和delete（可能导致占用的自由存储去不连续）对数据的生命周期不完全受程序或函数的生存周期不完全受程序或函数的生存时间控制。 如果使用new运算符在自由存储（或堆）上创建变量后，没有调用delete。则即使包含指针的内存由于副作用或规则和对象生命周期的原因而被释放（将会无法访问自由存储空间中的结构，因为指向这些内存的指针无效。这将导致内存泄漏），在自由存储空间上动态内存分配的变量或结构也将继续存在。 类型组合数组名是一个指针 要用指向成员运算符123a_y_e trio[3];trio[0].year=2003;(trio+1)-&gt;year=2004; 1234567//创建指针数组const a_y_e *arp[3]={&amp;s01,&amp;s02,&amp;s03};std::cout&lt;&lt;arp[1]-&gt;year&lt;&lt;std::endl;//可创建指向上述收集自的指针：const a_y_e **ppa =arp;//麻烦//可以auto，让编译器自动推断auto ppa=arps; 数组的替代品 1.模板类vector–&gt;是一种动态数组–&gt;可以在运行时设置长度–&gt;它是使用new创建动态数组的替代品。 vector类自动通过new和delete来管理内存。vector&lt;typeName&gt; vt(n_elm); typeName:类型,vt:对象名,n_elm:个数：整型常量/变量 2.模板类array（C++11）–&gt;与数组一样，array对象长度也是固定的，也使用栈（静态内存分配），而不是自由存储去，因此其效率与数组相同，更方便，更安全。 12array&lt;int,5&gt;ai;array&lt;double,4&gt;ad={1.2,2.1,3.4,4.3};//列表初始化 C++的vector、array和数组的比较（都使用连续内存,而list内存空间是不连续的）在C++11中，STL中提拱了一个新的容器std::array，该容器在某些程度上替代了之前版本的std::vector的使用，更可以替代之前的自建数组的使用。那针对这三种不同的使用方式，先简单的做个比较： 相同点： 三者均可以使用下标运算符对元素进行操作，即vector和array都针对下标运算符[]进行了重载 三者在内存的方面都使用连续内存，即在vector和array的底层存储结构均使用数组 不同点： vector属于变长容器，即可以根据数据的插入删除重新构建容器容量；但array和数组属于定长容量。 vector和array提供了更好的数据访问机制，即可以使用front和back以及at访问方式，使得访问更加安全。而数组只能通过下标访问，在程序的设计过程中，更容易引发访问 错误。 vector和array提供了更好的遍历机制，即有正向迭代器和反向迭代器两种 vector和array提供了size和判空的获取机制，而数组只能通过遍历或者通过额外的变量记录数组的size vector和array提供了两个容器对象的内容交换，即swap的机制，而数组对于交换只能通过遍历的方式，逐个元素交换的方式使用 array提供了初始化所有成员的方法fill vector提供了可以动态插入和删除元素的机制，而array和数组则无法做到，或者说array和数组需要完成该功能则需要自己实现完成。**但是vector的插入删除效率不高（从中间插入和删除会造成内存块的拷贝），但能进行高效的随机存储，list能高效地进行插入和删除，但随机存取非常没有效率遍历成本高。 由于vector的动态内存变化的机制，在插入和删除时，需要考虑迭代的是否失效的问题。 基于上面的比较，在使用的过程中，可以将那些vector或者map当成数组使用的方式解放出来，可以直接使用array；也可以将普通使用数组但对自己使用的过程中的安全存在质疑的代码用array解放出来。 函数函数—C++的编程模块（要提高编程效率，可更深入地学习STL和BOOST C++提供的功能） 1.提供函数定义 function definition 2.提供函数原型 function prototype 3.调用函数 function call 12345Void functionName(parameterlist){statement(s)teturn;} parameterlist:指定了传递给函数的参数类型和数量 void:没有返回值，对于有返回值的函数，必须有返回语句return 1.返回值类型有一定的喜爱内置：不能是数组，但可以是其他任何类型—整数，浮点数，指针，甚至可以是结构和对象。 2.函数通过将返回值复制到指定的CPU寄存器或内存单元中来将其返回。 为什么需要原型原型描述了函数到编译器的接口，它将1.函数返回值类型（如果有的话）以及2.参数的类型和3.数量告诉编译器。（在原型的参数列表中，可以包含变量名，也可以不包含。原型中的变量名相当于占位符，因此不必与函数中的变量名相同） 确保：编译器正确处理1，编译器检查2，3 函数参数传递和按值传递 用于接收传递值的变量被称为形参（parameter），传递给函数的值被称为实参（argument）。 值传递：调用函数时，使用的是实参的副本，而不是原来的数据。 在函数中声明的变量（局部变量（自动变量））（包括参数）是该函数私有的，函数调用时：计算机将为这些变量分配内存；函数结束时：计算机将释放这些变量使用的内存。 函数和数组123int sum_arr(int arr[],int n);//arr=arrayname.n=sizeint sum_arr(int arr[],int n);//arr=arrayname.n=size//两者是等价的 const保护数组（输入数组原数据不能改变）void show_array(const double ar[],int n);//声明形参时使用const关键字 该声明表明，指针or指向的是常量数据。这意味着不能使用or修改数据。这并不意味着原始数据必须是常量 如果该函数要修改数组的值，声明ar时不能使用const 1.对于处理数组的C++函数，必须将数组中的 1.数据类型 2.数组的起始位置 3.和数组元素中的数量提交给他 传统的C/C++方法是，将指向数组起始处的指针作为一个参数，将数组长度作为第二个参数（指针指出数组位置和数据类型） 2.第二种方法：指定元素区间（range）通过传递两个指针来完成：一个指针表示数组的开头，另外一个指针表示数组的尾部。例子：12345678910int sum_arr(const int *begun,const int *end){const int *pt;int total=0;for(pt=begin;pt!=end;pt++)total=toatl+*pt;return total;}int cookies[ArSize]= {1,2,4,8,16,32,64,128};int sum=sum_arr(cookies,cookies+ArSize); 函数与C风格字符串假设要将字符串（实际传递的是字符串第一字符的地址）作为参数传递给函数，则表示字符串的方式有三种： 1.char数组 2.用隐含阔气的字符串常量 3.被设置为字符串的地址的char指针。 函数和结构涉及函数时，结构变量的行为更接近基于基本的单值变量 1.按值传递–&gt;如果结构非常大，则复制结构将增加内存要求，且使用的是原始变量的副本 2.传递结构的地址，然后使用指针来访问结构的内容 1234567rect rplace;polar pplace;void rect_to_polar(const rect*pxy,polar*pda){...}rect_to_polar(&amp;rplace,&amp;pplace); 调用函数时，将结构的地址（&amp;pplace）而不是结构本身（pplace）传递给它；将形参声明为指向polar的指针，即polar*类型。由于函数不应该修改结构，因此使用了const修饰符，由于形参是指针不是结构，因此应使用姐姐成员运算符(-&gt;)，而不是成员运算符（.）。 3.按引传递用，传指针和传引用效率都高，一般主张是引用传递代码逻辑更加紧凑清晰。 递归—C++函数有一种有趣的特点–可以调用自己（除了main()）1.包含一个递归调用的递归 1234567void recurs(argumentlist){statement1if(test)recurs(arguments)statement2} 如果调用5次recurs就会运行5次statement1，运行1次statement2. 2.包含多个递归调用的递归 12345678void recurs(argumentlist){if(test)return;statement;recurs(argumentlist1);recurs(argumentlist2);} 3.从1加到n 12345678910class Solution{public:int Sum_Solution(int n){int ans=n;ans&amp;&amp;(ans+=Sum_Solution(n-1));return ans;}};//&amp;&amp;就是逻辑与，逻辑与有个短路特点，前面为假，后面不计算。 函数指针函数也有地址—存储其机器语言代码的内存的开始地址 获取函数的地址，只要使用函数名（后面不跟参数）即可。 例如think()是个函数 1234567891011process(think);//传递的是地址thought(think());//传递的是函数返回值//使用double pam(int);//原始函数声明double (*pf)(int);//函数指针声明pf=pam;//使用指针指向pam函数double x=pam(4);//使用函数名调用pam()double y=(*pf)(5);//使用指针调用pam()//也可以这样使用函数指针double y=pf(5); 进阶下面函数原型的特征表和返回类型相同123456789const double *f1(const double ar[],int n);const double *f2(const dopuble [],int );const double *f3(const double *,int );//声明一个指针可以指向f1，f2，f3const double * (*p1)(const double *,int );//返回类型相同，函数的特征标相同//声明并初始化const double * (*p1)(const double *,int )=f1;//也可以使用自动类型推断auto p2=f2; 使用for循环通过指针依次条用每个函数 例子：声明包含三个函数指针的数组，并初始化 const double * (*pa[3])(const double *,int)={f1,f2,f3}; 问：为什么不使用自动类型推断？auto 答：因为自动类型推断只能用于单值初始化，而不能用初始化列表。 但可以声明相同类型的数组 auto pb=pa; 使用： 123456const double *px=pa[0](av.3);//两种表示法都可以const double *py=pb[1](av.3);//创建指向整个数组的指针。由于数组名pa是指向函数指针的指针auto pc=&amp;pa;//c++11//等价于const double * (*(*pd[3]))(const double *,int)=&amp;pa;//C++98 除了auto外，其他简化声明的工具，typedef进行简化点云库里常常用到,如:typedef pcl::PointNormal PointNT 12typedef const double * (*p_fun)(const double *,int );p_fun p1=f1; 函数探幽C++11新特性 函数内联 按引用传递变量 默认参数值 函数重载（多态） 模板函数 内联函数c++内联函数–&gt;提高程序运行速度：常规函数与内联函数的区别在于,C++编译器如何将它们组合到程序中 常规函数调用过程： 执行到函数调用指令程序在函数调用后立即存储该指令地址，并将函数参数复制到堆栈中(为此保留的代码)， 跳到标记起点内存单元， 执行函数代码（也许将返回值放入寄存器中）， 然后跳回地址被保存的指令处。 来回跳跃并记录跳跃位置意味着以前使用函数时，需要一定的开销。 情况：函数代码执行时间很短—内联调用就可以节省非内联调用的大部分时间（节省时间绝对值并不大） 代价：需要占用更多的内存：如果程序在是个不同地方调用一个内联函数，则该函数将包含该函数代码的10个副本 使用： 在函数声明前加上关键字inline； 在函数定义前加上关键字inline； 通常的做法是省略原型，将整个定义（即函数头和所有代码），放在本应提供原型的地方。 内联函数不能递归 如果函数占用多行（假设没有冗长的标识符），将其作为内联函数不太合适. 内联与宏C语言使用预处理语句#define来提供宏—内联代码的原始实现 1# define SQUARE(X) X*X 这不是通过传递参数实现的,而是通过文本替换实现的—X是”参数”的符号标记。所以宏不能按值传递 故有时候会出现错误 12c=10;d=SQUARE(C++);is replaced by d=C++*c++=11X12=122 按引用传递变量引用变量–&gt;是复合类型int &amp; rodents =rats;其中int &amp;是类型，该声明允许将rats和rodent互换—他们指向相同的值和内存单元。 必须在声明引用变量时进行初始化 引用更接近const指针(指向const数据的指针)，必须在创建时进行初始化，一旦与某个变量关联起来就一直效忠于它。12345int &amp; rodents=rats;//实际上是下述代码的伪装表示int * const pr=&amp;rats;//引用rodents扮演的角色与*pr相同。//*pr值是个地址，且该地址恒等于&amp;rat--&gt;rats的地址 引用的属性与特别之处应该尽可能使用constC++11新增了另外一种引用—右值引用。这种引用可指向右值，是使用&amp;&amp;声明的：第十八章将讨论如何使用右值引用来实现移动语义（move semantics）,以前的引用（使用&amp;声明的引用）现在称为左值引用 右值引用是对临时对象的一种引用，它是在初始化时完成的，但右值引用不代表引用临时对象后，就不能改变右值引用所引用对象的值，仍然可以初始化后改变临时对象的值 右值短暂，右值只能绑定到临时对象。所引用对象将要销毁或没有其他用户 初始化右值引用一定要用一个右值表达式绑定。 例子： 123double &amp;&amp;rref=std::sqrt(36.00);//在左值引用中不成立，即使用&amp;来实现也是不允许的double j=15.0;double&amp;&amp; jref=2.0*j+18.5;//同样使用左值引用是不能实现的。 将引用用于结构引用非常适合用于结构和类(C++用户定义类型)而不是基本的内置类型。 声明函数原型，在函数中将指向该结构的引用作为参数：void set_pc(free_throws &amp; tf);如果不希望函数修改传入的结构。可使用const；void display(free_throws &amp; tf); 返回引用：free_throws &amp;accumlate(free_throws&amp; traget,free_throws&amp; source);为何要返回引用？如果accumlate()返回一个结构，如：dup=accumlate(team,five) 而不是指向结构的引用。这将把整个结构复制到一个临时位置，再将这个拷贝复制给dup。但在返回值为引用时，直接把team复制到dup，其效率更高，复制两次和复制一次的区别。 应避免返回函数终止时，不在存在的内存单元引用。为避免这种问题，最简单的方法是，返回一个作为参数传递给函数的引用。作为参数的引用指向调用函数使用的数据，因此返回引用也将指向这些数据。 1234567free_throws&amp; accumlate(free_throws&amp; traget,free_throws&amp; source){traget.attempts+=source.attempts;traget.mode+=source.mode;set_pc(target);return target;} 另一种方法是用new来分配新的存储空间 1234567const free_throws&amp; clone(&amp;three){free_throws * pt;//创建无名的free_throws结构，并让指针pt指向该结构，因此*pt就是该结构，在不需要new分配的内存时，应使用delete来释放它们。 //auto_ptr模板以及unique_ptr可帮助程序员自动完成释放* pt=ft；return *pt;//实际上返回的是该结构的引用} 将引用用于对象和结构同理 对象继承和引用使得能够将特性从一个类传递给另外一个类的语言被称为继承 ostream–&gt;基类 ofstream–&gt;派生类 基类引用可以指向派生类对象，而无需强制类型转换 时使用引用参数使用引用参数到主要原因有两个： （1）程序员能够修改调用函数中的数据对象。 （2）通过传递引用而不是整个数据对象，可以提高程序的运行速度。 当数据对象较大时（如结构和类对象），第二个原因最重要。这些也是使用指针参数的原因。这是有道理的，因为引用参数实际上是基于指针的代码的另一个接口。那么什么时候应该使用引用，什么时候应该使用指针呢？什么时候应该按值传递呢？下面是一些指导原则： 对于使用传递到值而不做修改到函数： （1）如果数据对象很小，如内置数据类型或小型结构，则按值传递。 （2）如果数据对象是数组，则使用指针，因为这是唯一的选择，并将指针声明为指向const的指针。 （3）如果数据对象是较大的结构，则使用const指针或const引用，以提高程序的效率。这样可以节省复制结构所需要的时间和空间。 （4）如果数据对象是类对象，则使用const引用。类设计的语义常常要求使用引用，这是C++新增这项特性的主要原因。因此，传递类对象参数的标准方式是按引用传递。 对于修改调用函数中数据的函数： （1）如果数据对象是内置数据类型，则使用指针。如果看到诸如fixit(&amp;x)这样的代码（其中x是int），则很明显，该函数将修改x。 （2）如果数据对象是数组，则只能使用指针。 （3）如果数据对象是结构，则使用引用或指针。 （4）如果数据对象是类对象，则使用引用。 当然，这只是一些指导原则，很可能有充分到理由做出其他的选择。例如，对于基本类型，cin使用引用，因此可以使用cin&gt;&gt;n，而不是cin&gt;&gt;&amp;n。 默认参数值—当函数调用中省略了实参时自动使用的一个值如何设置默认值？**必须通过函数原型 char* left(const char* str,int n=1);原型声明 定义长这样 char * left(const char* str,int n){…} 对于带参数列表的函数，必须从左向右添加默认值：下面代码错误，int j应该也设默认值 1int chico(int n,int m=6,int j);//fault 通过默认参数，可以减少要定义的析构函数，方法以及方法重载的数量 函数重载 默认参数让你能够使用不同数目的参数调用的同一个函数。 而函数多态（函数重载）让你能够使用多个同名函数。 仅当函数基本上执行相同的任务，但使用不同形式的数据时，才应用函数重载 C++使用名称修饰（名称矫正）来跟踪每一个重载函数 未经过修饰：long MyFunction(int,float); 名称修饰（内部转换）：?MyFunctionFoo@@YAXH—&gt;将对参数数目和类型进行编码 重载与多态的区别 重载：是指允许存在多个同名方法，而这些方法的参数不同(特征标不同)。重载的实现是：编译器根据方法不同的参数表，对同名方法的名称做修饰，对于编译器而言，这些同名方法就成了不同的方法。他们的调用地址在编译器就绑定了。**重载，是在编译阶段便已确定具体的代码，对同名不同参数的方法调用（静态联编） C++中，子类中若有同名函数则隐藏父类的同名函数，即子类如果有永明函数则不能继承父类的重载。 多态：是指子类重新定义父类的虚方法（virtual,abstract）。当子类重新定义了父类的虚方法后，父类根据赋给它的不同的子类，动态调用属于子类的方法，这样的方法调用在编译期间是无法确定的。（动态联编）。对于多态，只有等到方法调用的那一刻，编译器才会确定所要调用的具体方法。 重载与覆盖的区别 重载要求函数名相同，但是参数列列表必须不不同，返回值可以相同也可以不不同。覆盖要求函数名、参数列列表、返回值必须相同。 在类中重载是同一个类中不同成员函数之间的关系在类中覆盖则是⼦子类和基类之间不同成员函数之间的关系 重载函数的调用是根据参数列表来决定调用哪一个函数 覆盖函数的调用是根据对象类型的不不同决定调用哪一个 在类中对成员函数重载是不不能够实现多态 在子类中对基类虚函数的覆盖可以实现多态 模板函数—通用的函数描述 用于函数参数个数相同的类型不同的情况，如果参数个数不同，则不能那个使用函数模板 函数模板自动完成重载函数的过程。只需要使用泛型和具体算法来定义函数，编译器将为程序使用特定的参数类型生成正确的函数定义 函数模板允许以任意类型的方式来定义函数。例如，可以这样建立一个交换模板 12345678template &lt;typename AnyType&gt;void Swap(AnyType &amp;a,AnyType &amp;a){AnyType temp;temp=a;a=b;b=temp;} 模板不会创建任何函数，而只是告诉编译器如何定义函数 C++98没有关键字typename，使用的是template&lt;class AnyType&gt;void Swap(AnyType &amp;a,AnyType &amp;a){...} 函数模板不能缩短可执行程序，最终仍将由两个独立的函数定义，就像以手工方式定义了这些函数一样。最终的代码不包含任何模板，只包含了为程序生成的实际函。使用模板的寒除湿，它使生成多个函数定义更简单，更可靠更常见的情形是将模板放在头文件中，并在需要使用模板的文件中包含头文件 重载的模板对多个不同类型使用同一种算法（和常规重载一样，被重载的模板的函数特征标必须不同）。 1234template &lt;typename T&gt;void Swap(T&amp; a,T&amp; b);template &lt;typename T&gt;void Swap(T* a,T* b,int n); 模板的局限性：编写的模板很可能无法处理某些类型 如1.T为数组时，a=b不成立；T为结构时a&gt;b不成立 解决方案： C++允许重载运算符，以便能够将其用于特定的结构或类 为特定类型提供具体化的模板定义 显式具体化（explicit specialization）提供一个具体化函数定义，其中包含所需的代码，当编译器找到与函数调用匹配的具体化定义时，将使用该定义，不再寻找模板。 该内容在代码重用中有不再重复。 重载解析(overloading resolution)—编译器选择哪个版本的函数对于函数重载，函数模板和函数模板重载，C++需要一个定义良好的策略，来决定为函数调用哪一个函数定义，尤其是有多个参数时 过程： 创建候选函数列表。其中包含与被调用函数的名称相同的函数和模板函数。 使用候选函数列表创建可行函数列表。这些都是参数数目正确的函数，为此有一个隐式的转换序列，其中包括实参类型与相应的形参类型完全匹配的情况。例如，使用float参数的函数调用可以将该参数转换为double，从而与double形参匹配，而模板可以为float生成一个实例。 确定是否有最佳的可行函数。如果有，则使用它，否则该函数调用出错。 最佳到最差的顺序： 完全匹配，但常规函数优先于模板 提升转换（例如，char和shorts自动转换为int ,float自动转换为double）。 标准转换（例如，int转换为char,long转换为double）。 用户定义的转换，如类声明中定义的转换。 完全匹配：完全匹配允许的无关紧要转换 从实参到形参 到实参 Type Type &amp; Type &amp; Type Type[] * Type Type(argument-list) Type( * )(argument-list) Type const Type Type volatile Type Type* const Type Type* volatile Type *** # 9内存模型和名称空间（4） 原来的程序分为三个部分 1. 头文件：包含结构声明和使用这些结构的函数的原型//结构声明与函数原型 2. 源代码文件：包含与结构有关的函数代码 //函数 3. 源代码文件：包含调用与结构相关的函数的代码 //调用函数 这种组织方式也与oop方式一致。 一个文件（头文件）包含用户定义类型的定义； 另外一个文件包含操纵用户定义类型的函数代码； 这两个文件组成了一个软件包，可用于各种程序中。 请不要将函数定义或变量声明放在头文件中，如果其他文件都包含这个头文件，那么同一个函数就会有多次定义，变量也同理，会出错。 头文件中常包含的内容： 函数原型。 使用#define或const定义的符号常量（头文件中不可以创建变量） 结构声明=&gt;因为它们不创建变量 模板声明=&gt;模板声明不是将被编译的代码，他们指示编译器如何生成源代码中的函数调用相匹配的函数定义。 内联函数–&gt;只有它可以在头文件定义函数。 被声明为const的数据和内联函数有特殊的链接属性 注意：在IDE中 不要将头文件加入到项目列表中 也不要在源代码文件中使用#include来包含其他源代码文件 在同一文件中只能将同一个头文件包含一次。–&gt;使用预编译指令 1234#ifndef COORDIN_H_...#endif 但是这种方法并不能防止编译器将头文件包含两次，而只是让它忽略第一次包含之外的所有内容。大多数标注C和C++头文件都是用各种防护(guarding)方案。否则，可能在一个文件中定义同一个结构两次，这将导致编译错误。 编译在UNIX系统中编译由多个文件组成的C++程序 编译两个源代码文件的UNIX命令： CC file1.cpp file2.cpp 预处理将包含的文件与源代码文件合并： 临时文件： temp1.cpp temp2.cpp 编译器创建每个源代码文件的目标代码文件：file1.o file2.o 链接程序将目标代码文件(file1.o file2.o)、库代码(Library code)和启动代码(startup code)合并，生成可执行文件：a.out多个库的链接 由不同编译器创建的二进制模块（对象代码文件）很可能无法正确地链接。 原因：两个编译器为同一个函数生成不同的名称修饰 名称的不同将使链接器无法将一个编译器生成的函数调用与另外一个编译器生成的函数定义匹配。在链接编译模块时，请确保所有对象文件或库都是由同一编译器生成的。 链接错误解决的方法：如果有源代码，通常可以用自己的编译器重新编译来消除错误。存储持续性，作用域与和链接性C++中的四种存储方案 自动存储持续性 :在函数定义中声明的变量（包括函数参数）的存储持续性为自动的。它们在程序开始执行其所属的函数或代码块时被创建，在执行完函数或代码块时，它们使用的内存被释放。 静态存储持续性 :在函数定义外定义的变量和使用关键字static定义的变量的存储持续性都为静态。（请注意）它们在整个运行过程中都存在。 线程存储持续性(C++11) :当前，多核处理器很常见，这些CPU可同时处理多个执行任务。这让程序能够将计算放在可并行处理的不同线程中。如果变量是使用关键字thread_local声明的，则其生命周期与所属的线程一样长。 动态存储持续性 :用new运算符分配的内存将一直存在，直到使用delete运算符将其释放或程序结束为止。这种内存的存储持续性为动态，有时被称为自由存储(free store)或堆(heap)。 作用域和链接性 作用域(scope) 描述了名称在文件的多大范围内可见。例如，函数中定义的变量可在该函数中使用，但不能在其他函数中使用；而在文件中的函数定义之前定义的变量则可在所有函数中使用。 作用域：局部与全局–&gt;(代码块/文件) 作用域为局部的变量只在定义它的代码块中可用。（代码块：由花括号括起的一系列语句，比如：函数体） 做英语为全局（也叫文件作用域）的变量在定义位置到文件结尾都可以用。 链接性(linkage) 描述了名称如何在不同单元间共享。链接性为外部的名称可在文件间共享，链接性为内部的名称只能由一个文件中的函数共享，自动变量的名称没有链接性，因为它们不能共享。 C++内存空间分布1.命令行参数和环境变量 shell在执行程序的时候调用exec函数将命令行参数传递给要执行的程序。 使程序了解进程环境，在执行时分配空间。 2.bss段（Block Start by Symbol） 存放未初始化的全局变量或者静态变量。 3.data段 存放具有明确初始值的全局变量或者静态变量。 存在于程序镜像文件中，由 exec 函数从程序镜像文件中读入内存。 4.text段 CPU执行的机器指令。 堆栈简要概述栈：系统自动开辟空间，自动分配自动回收，在作用域运行完成后（函数返回时）就会被回收。 堆：由程序员自己申请空间，释放空间，不释放会出现内存泄漏。 栈 1.栈是连续的向下扩展的数据结构，总共只有1M或者2M的空间。空间不足就会异常提示栈溢出。 2.存储自动变量, 函数调用者信息, 包括函数参数(可变参数列表的压栈方向是从右向左), 函数内局部变量, 函数返回值, 函数调用时的返回地址。 堆 1.堆是不连续的向上扩展的数据结构，大小受限于计算机系统虚拟内存的大小。 2.操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。 对于大多数系统，会在这块内存空间中的首地址处（一般为一个字节的大小）记录本次分配的大小，这样，代码中的 delete语句才能正确的释放本内存空间。 由于找到的堆结点的空间大小可能大于申请的大小，系统会自动的将多余的那部分（即内存碎片）重新放入空闲链表中。这就涉及到申请效率的问题。 引入名称空间之前下面列出5种变量存储方式（引用名称空间之前） 存储描述 持续性 作用域 链接性 如何声明 自动 自动 代码块 无 在代码块中 寄存器 自动 代码块 无 在代码块中，使用关键字register 静态,无链接性 静态 代码块 无 在代码块中，使用关键字static 静态,外部链接性 静态 文件 外部 不在任何函数内 静态,内部链接性 静态 文件 内部 不在任何函数内，使用关键字static 自动存储持续性 在默认情况下，在函数中声明的函数参数和变量的存储持续性为自动，作用域为局部，没有链接性（自动变量不能共享）。 自动变量的初始化：可以使用任何声明时其值已知的表达式来初始化自动变量int x=5;int y=2*x; 自动变量和栈：自动变量的数目随函数的开始和结束而增减，因此程序必须在运行是对自动变量进行管理。常用方法是流出一段内存，并将其视为栈。程序使用两个指针来跟踪栈，一个指向栈底，栈的开始位置。另外一个指针指向栈顶，下一个可用内存单元。栈是LIFO（后进先出）的，即最后加入到栈中的变量首先被弹出。 寄存器变量–&gt;旨在提高访问变量的速度 关键字register最初由C语言引入的，它建议编译器使用CPU寄存器来存储自动变量 1register int count_fast;//request for a register variable 鉴于关键字register只能用于原来就是自动的变量，使用它的唯一原因是，指出程序员想使用一个自动变量，这个变量名可能与外部变量相同 静态持续变量 C++也为静态存储持续性提供了三种链接性 1.外部链接性（可在其他文件中访问） 2.内部链接性（只能在当前文件中访问） 3.无链接性（只能在当前函数或代码块中访问） 这三种链接性都在整个程序执行期间一直存在，与自动变量相比，他们的寿命更长。由于静态变量的数目在程序运行期间是不变的，因此程序不需要使用特殊的装置（如栈）来管理它们，编译器将分配固定的内存块来存储所有的静态变量，这些变量在整个程序执行期间一直存在。另外，如果没有显示地初始化静态变量，编译器将把它设置为0。在默认情况下，静态数组和结构将每个元素或成员的所有位都设置为0。被称为0初始化 例子：123456789101112int NUM_ZDS_GLOBAL = 80; //#1static int NUM_ZDS_ONEFILE = 50; //#2int main(){…}void fun1(int n){static int nCount = 0; //#3int nNum = 0; //#4}void fun2(int q){ …} #1、#2、#3在整个程序运行期间都存在。在fun1中声明的#3的作用域为局部，没有链接性，这意味着只能在fun1函数中使用它，就像自动变量#4一样。但是，与#4不同的是，即使在fun1没有被执行的时候，#3也保留在内存中。 静态变量初始化 123456#include&lt;cmath&gt;int x; //零初始化 int y=5; //常量表达式初始化long z=13*13; //常量表达式初始化const double pi=4.0*atan(1.0);//动态初始化，要初始化pi，必须调用函数atan()，这需要等到函数被链接上且程序执行时。（这也是常量表达式初始化）//C++新增关键字constexpr，这增加了创建常量表达是的方式 1.静态持续性，外部链接性==&gt;普通全局变量链接性为外部的变量通常称为外部变量，它们的存储持续性为静态，作用域为整个文件。 外部变量是函数外部定义的，因此对所有函数而言都是外部的。 例如，可以在main()前面或头文件中定义他们。可以在文件中位于外部定义后面的任何函数中使用它。 因此外部变量也称为全局变量。 全局变量是在所有函数体的外部定义的，程序的所在部分（甚至其它文件中的代码）都可以使用。全局变量不受作用域的影响（也就是说，全局变量的生命期一直到程序的结束）。如果在一个文件中使用extern关键字来声明另一个文件中存在的全局变量，那么这个文件可以使用这个数据。 单定义规则一方面，在每个使用外部变量的文件中，都必须声明它；另外一方面，C++有“单定义规则”，该规则指出，变量只有一次定义。 为满足这种需求，C++提供了两种变量声明。 一种是定义声明（defining declaration）或简称为定义（definition），它给变量分配存储空间。 一种是引用声明（referencing declaration）或简称为声明（declaration），它不给内存变量分配存储空间。 引用声明使用关键字extern，且不进行初始化；否则，声明未定义，导致分配内存空间：例 123double up;//definition,up is 0 定义extern int bllem;//blem defined elsewhere 声明，blem变量在某处定义了extern char gr = 'z';//definition because initialized 定义 注意： 单定义规则并非意味着不能有多个变量名称相同 如果函数中声明了一个与外部变量同名的变量，结果将如何呢？12345678910111213141516//external1.cpp 文件1double warning=0.3;//warning defined 定义//support.cpp 文件2extern double warning;//use warning from another file 使用外部定义的变量warning......void update(double dt){extern double warning;//optional redeclaration......}void local(){//定义域全局变量名相同的局部变量都，局部变量将隐藏全局变量double warning=0.8;//new variable hides external one......} 通常情况下，应使用局部变量，然而全局变量也有它们的用处。例如，可以让多个函数可以使用同一个数据块（如月份，名数组或原子量数组）。外部存储尤其适用于表示常量数据，因为这样可以使用关键字const来防止数据修改。 2.静态持续性，内部链接性==&gt;Static全局变量 全局变量（外部变量）的说明之前再冠以static就构成了静态的全局变量。全局变量本身就是静态存储方式，静态全局变量当然也是静态存储方式。 这两者在存储方式上并无不同。这两者的区别在于非静态全局变量的作用域是整个源程序，当一个源程序由多个原文件组成时，非静态的全局变量在各个源文件中都是有效的。而静态全局变量则限制了其作用域，即只在定义该变量的源文件内有效，在同一源程序的其它源文件中不能使用它。 由于静态全局变量的作用域限于一个源文件内，只能为该源文件内的函数公用，因此可以避免在其他源文件中引起错误。 static全局变量与普通的全局变量的区别是static全局变量只初始化一次，防止在其他文件单元被引用。 3.静态持续性，无链接性==&gt;静态局部变量这种变量是这样创建的，将static限定符用于代码块中定义的变量。 在两次函数调用之间，静态局部变量的值将保持不变，它同时拥有静态变量和局部变量的特性，即： 编译时自动初始化 会被放到静态内存的静态区 只能在局部被访问作用：有时候我们需要在两次调用之间对变量进行保存，通常的想法是定义一个全局变量来实现。但这样一来变量就不属于函数本身了，而受全局变量的控制。静态局部变量正好可以解决这个问题，静态局部变量保存在全局数据区，而不是保存在栈中，每次的值保持到下一次调用，直到下一次赋新值 说明符和限定符存储说明符(storage class specifier) auto(在C++11中不再是说明符)：在C++11之前，可以在声明中使用关键字auto来指出变量为自动变量；但在C++11中，auto用于自动类型推断。 register：用于在声明中指示寄存器存储，在C++11中，它只是显式地指出变量是自动的。 static:关键字static被用在作用域为整个文件的声明中时，表示内部链接性；被用于局部声明中，表示局部变量的存储持续性为静态的。 thread_local(C++11新增)：可以用static或extern结合使用，关键字thread_local指出变量持续性与其所属的持续性相同。thread_local变量之于线程，由于常规静态变量至于整个程序。 mutable：关键字mutable的含义根据const来解释 mutable:可以用来指出，即使结构（或类）变量为const，其某个成员也可以被修改。 12345678910struct data{char name[30];mutable int accesses;...}const data veep={\"claybourne clodde\",0,...};strcpy(veep.name,\"ytttt\"); //not allowedveep.accessses++; //allowed CV限定符（cv-qualifier） const:它表明，内存被初始化后，程序便不能再对他进行修改。 volatile: volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问 再谈const const限定对默认存储类型稍有影响。在默认情况下，全局变量的链接性为外部的，但const全局变量的链接性为内部的 1234const int fingers = 10;//same as static const init fingers=10;int main(){...} 原因：C++这样子修改了常量类型的规则，让程序员更轻松 假如，假设将一组常量放在头文件中，并在同一程序的多个文件中使用该头文件。那么预处理器将头文件中的内容包含到每个源文件后，所有的源文件都将包含类似下面的定义： 12const int fingers=10;const char* warning =\"wak!\"; 如果全局const声明的链接性像常规变量那样是外部的，则根据单定义规则，这将出错（二义性）。也就是说只能有一个文件可以包含前面的声明，而其他文件必须使用extern关键字来提供引用声明。另外只有未使用extern关键字的生命才能进行初始化。 然而，由于外部定义的const数据的链接性为内部的，因此可以在所有文件中使用相同的声明。 内部链接性意味着每个文件都有自己一组常量，而不是所有文件共享一组常量。每个定义都是其所属文件所私有的，这就是能够将常量定义放在头文件中的原因。 函数和链接性 和C语言一样，C++不允许在一个函数中定义另外一个函数=&gt;因此所有函数的存储持续性都自动为静态的，即整个程序执行期间都一直存在。 在默认情况喜爱，函数的链接性为外部的，即可以在文件间共享。 实际上可以使用extern关键字来指出函数是在另外一个文件中定义的，不过这是可选的。 使用关键字static将函数链接性改为内部链接性，使其只能在本文件中使用，必须在原型和函数定义中同时使用该关键字。 单定义规则也适用于非内联函数，因此对于每个非内联函数，程序只能包含一个定义。对于链接性味外部的函数来说，这意味着在多文件程序中，只能有一个文件包含该函数的定义，但使用该函数的每个文件都应包含其函数原型。 内联函数不受这种规则的约束，这允许程序员能够将内联函数的定义放在头文件中，这样包含了头文件的每个文件都有内联函数的定义。然而，C++要求同一个函数的所有内联定义都必须相同。 C++在哪里寻找函数？假设在程序的某个文件中调用一个函数，C++将到哪里寻找函数定义？ 如果该文件中的函数原型指出该函数是静态的，则编译器将只在该文件中查找函数定义； 否则，编译器（包括链接程序）将在所有文件中查找。 如果在程序文件中找不到，编译器将在库中搜索。这意味着，如果定义了一个与库函数同名的函数，编译器将使用程序员定义的版本，而不是库函数。 语言链接性链接程序要求每个不同的函数都有不同的符号名。在C语言中，一个名词只对应一个函数，因此这很容易实现。为满足内部需要，C语言编译器可能将spiff这样的函数名翻译为_spiff。这种方法称为C语言链接性（C language linkage）。但在C++中，同一个名称可能对应多个函数，必须将这些函数翻译为不同的符号名称。因此，C++编译器执行名称纠正或名称修饰，为重载函数生成不同的符号名称。例如，spiff（int）转换为—_spiff_i，而将spiff(double, double)转换为_spiff_d_d。这种方法称为C++语言的链接性（C++ language linkage）。 如果要在C++程序中使用C语言预编译的函数，将出现什么情况呢？例如，假设有如下代码：spiff(22);它在C库文件中的符号名称为_spiff,但对于我们的C++链接程序来说，C++查询约定是查找符号民称_spiff_i。为解决这样的问题，可以用函数原型来指出要使用何种约定： 123extern “C” void spiff(int);//使用C语言链接性extern void spoff(int);//使用C++语言的链接性(通过默认方式指出)extern “C++” void spaff(int);//使用C++语言的链接性（通过显式指出） C和C++链接性是C++标准制定的说明符，但实现可以提供其他语言链接性说明符。 存储方案和动态分配使用C++运算符new（或C函数malloc()）分配的内存，这种内存被称为动态内存，动态内存由运算符new和delete控制，而不是由作用域和链接性规则控制。因此，可以在一个函数中分配动态内存，而在另外一个函数中将其释放。其分配方式要取决于new和delete在何时以何种方式被使用。通常编译器使用三块独立的内存： 一块用于静态变量（可能再细分） 一块用于自动变量 另外一块用于动态存储 虽然存储方案概念不是用于动态内存，但适用于用来跟踪动态内存的自动和静态指针变量（自动指针变量，静态指针变量），指针变量还是有作用域和链接性的 new运算符如果要为内置的标量类型（int、double）分配存储空间并初始化，可在类型名后面加上初始值，并将其用括号括起。 1int *pi = new int(6); 要初始化常规结构或数组，需要使用大括号的列表初始化，这要求编译器支持C++11。 123struct where{double x, double y, double z};where *one = new where{2.5, 5.3, 7.2};int *ar = new int[4] {2, 4, 7, 6}; 在C++11中，还可将初始化列表用于单值变量： 1int *pin = new int {6}; new失败时 在最初的10年中，C++让new失败时返回空指针，但现在将引发std::bad_alloc异常。new：运算符、函数和替换函数运算符与函数：1234567891011//分配函数（allcation function）；void *operator new(std::size_t);//函数void *operator new[](std::size_t);//函数//释放函数（deallocation function）；void *operator delete(void *);//函数void *operator delete[](void *);//函数int *pi=new int;//运算符int *pi=new(sizeof(int));//函数int *pi=new int[40];//运算符int *pi=new(40*sizeof(int));//函数 替换函数： 有趣的是，C++将这些函数（分配函数，释放函数）称为可替换的（replaceable）。这意味着如果您有足够的知识和意愿，可为new和delete提供替换函数，并根据需要对其进行定制。例如，可定义作用域为类的替换函数，并对其进行定制，以满足该类的内存分配需求。在代码中，仍将使用new运算符，但它将调用您定义的new()函数。 定位new运算符通常，new负责在堆（heap）中找到一个足以能够满足要求的内存块。new运算符还有另一种变体，被称为定位（placement）new运算符，它让您能够指定要使用的位置。程序员可能使用这种特性来设置其内存管理规程、处理需要通过特定地址进行访问的硬件或在特定位置创建对象。 要使用定位new特性，首先需要包含头文件new，它提供了这种版本的new运算符的原型；然后将new运算符用于提供了所需地址的参数。除需要指定参数外，句法与常规new运算符相同。具体地说，使用定位new运算符时，变量后面可以有方括号，也可以没有。下面的代码段演示了new运算符的4种用法： 1234567891011121314#include &lt;new&gt;char buffer1[50];//静态数组char buffer2[500];struct chaff{char dross[20];int slag;};chaff *p1, *p2;int *p3, *p4;p1=new chaff; //place structure in heapp3=new int[20]; //place int array in heapp2=new (buffer1) chaff; //place structure in buffer1p4=new (buffer2) int[20]; //place int array in buffer2 上述代码从buffer1中分配空间给结构chaff，从buffer2中分配空间给一个包含20个元素的int数组。 定位new运算符的其他形式就像常规new调用一个接受一个参数的new函数一样，标准定位new调用一个接收两个参数的new函数。 123int * p1=new int;//调用 new(sizeof(int))int * p2=new(buffer) int;//调用 new(sizeof(int),buffer)int * p3=new(buffer) int[40];//调用new(40*sizeof(int),buffer) 定位new运算符不可替换，但可重载。至少需要接收两个参数，其中第一个总是std::size_t，指定了请求的字节数。这样的重载函数都被定义为new。 名称空间在C++中，名称可以是变量，函数，结构，枚举，类以及类的结构成员 两个概念：声明区域、潜在作用域声明区域(declaration region) 可以在其中进行声明的区域 在函数外面声明全局变量=&gt;对这种变量，其声明区域为其声明所在的文件。对于在函数声明的变量=&gt;其声明区域为其声明所在的代码块。 潜在作用域（potential scope） 变量潜在作用域从声明点开始，到其声明区域的结尾。因此潜在作用域比声明区域小，这是由于变量必须定义后才能使用。 变量并非在其潜在作用域的任何位置都是可见的。 例如，它可能被另外一个嵌套声明区域中声明的同名变量隐藏 例如，在函数声明的局部变量（对于这种变量，声明区域为整个函数）将隐藏在同一文件中声明的全局变量（对于这种变量，声明区域为整个文件）。 变量对程序而言可见的范围被称为作用域（scope）。新的名称空间(命名的名称空间)即通过定义一种新的声明区域来创建命名的名称空间，这样做的目的之一是提供一个声明名称的区域。一个名称空间中的名称不会和另一个名称空间中的名称发生冲突，同时允许程序的其他部分使用该名称空间中声明的东西。 关键字namespace 名称空间可以是全局的，也可以位于另一个名称空间中，但是不能位于代码块中。因此在默认情况下，在名称空间中声明的名称的链接性为外部的（除非它引用了常量）。 除用户定义的名称空间，还存在另外一个名称空间全局名称空间(global namespace)。它对应文件级声明区域，因此前面所说的全局变量现在被描述为位于全局名称空间中 using 声明和using编译指令 using声明使特定的标识符可用: 1 using std::cout;//将cout添加到它所属的声明区域中，即使得cout能够在main函数中直接使用 using编译指令使整个名称空间可用： 1 using namespace std;//使得std空间中所有的名称都可以直接使用 using编译指令和using声明之比较 使用using声明时，就好像声明了相应的名称一样，如果某个名称已经在函数中声明了，则不能用using声明导入相同的名称。 然而，使用using编译指令时，将进行名称解析，就像在包含using声明和名称空间本身的最小声明区域中声明了名称一样。如果使用using编译指令倒入一个已经在函数中声明的名称，则局部名称将隐藏名称空间名，就像隐藏同名的全局变量一样。 一般来说，使用using声明要比使用using编译指令更加安全，这是由于它只能导入指定的名称，如果该名称与局部名称发生冲突，编译器将发出指示。 using编译指令导入所有的名称，包括可能并不需要的名称，如果与局部名称发生冲突，则局部名称将覆盖名称空间版本而编译器不发出警告！ 另外，名称空间的开放性意味着名称空间的名称可能分散在多个地方，这使得难以准确知道添加了哪些名称。所以我们平时自己写程序时先怼一个using namespace std;上去可能并不是一个很好的决定。 10对象和类 类声明：以数据成员的方式描述数据部分，以成员函数（被称为方法）的方式描述公有接口–&gt;C++程序员将接口（类定义）放在头文件中 类方法定义：描述如何实现成员函数–&gt;并将实现（类方法代码）放在源代码文件中 细节： 使用#ifndef等来访问多次包含同一个文件 将类的首字母大写 控制访问关键字：private public protected C++对结构进行了扩展，使之具有与类相同的特性。他们之间唯一的区别是：结构的默认访问类型是public，类为private 通常，数据成员被放在私有部分中=&gt;数据隐藏；成员函数被放在公有部分中=&gt;公有接口实现类成员方法成员函数两个特殊的特征： 定义类成员函数时。使用作用域解析符（::）来标识函数所属的类； 类方法可以访问类的private组件。 123456789101112131415161718class Stock{ private: char company[30]; int shares; double share_val; double total_val; void set_tot(){total_val = shares * share_val;} public: Stock(); Stock(const char * co , int n = 0 , double pr = 0.0); ~Stock(){} void buy(int num , double price); void sell(int num , double price); void update(double price); void show() const; const Stock &amp; topval(const Stock &amp; s) const;}; set_tot()只是实现代码的一种方式，而不是公有接口的组成部分，因此这个类将其声明为私有成员函数（即编写这个类的人可以使用它，但编写带来来使用这个类的人不能使用）。 内联方法， 其定义位于类声明中的函数都将自动成为内联函数。因此Stock::set_tot()是一个内联函数。 在类声明之外定义内联函数 1234567891011class Stock{private:...void set_tot();public:...};inline void Stock::set_tot(){total_val = shares * share_val;} 内联函数有特殊规则，要求每个使用它们的文件都对其进行定义。确保内联定义对多个文件程序中的所有文件都可用的最简便方法是：将内联定义放在头文件中 如何将类方法应用于对象？（对象，数据和成员函数）所创建的每个新对象都有自己的存储空间，用于存储其内部变量和类成员。但同一个类的所有对象共享一组类方法，即每种方法只有一个副本。 要使用类，要创建类对象，可以声明类变量，也可以使用new为类对象分配存储空间。 实现了一个使用stock00接口和实现文件的程序后，将其与stock00.cpp一起编译，并确保stock00.h位于当前文件夹中 类成员函数(方法)可通过类对象来调用。为此，需要使用成员运算符句点。 类的构造函数和析构函数构造函数原因：数据部分的访问状态是私有的，这意味着程序不能直接访问数据成员（私有部分数据）。程序只能通过成员函数来访问数据成员，因此需要设计合适的成员函数才能将对象初始化。—类构造函数 声明和定义构造函数12//construtor prototype with some default argumentStock(const string &amp;co,long n=0,double pr=0.0);//原型 原型声明位于类声明的公有部分。 构造函数可能的一种定义 1234567891011121314Stock::Stock(const string &amp;co,long n,double pr){company = co;if(n&gt;0){std::cerr&lt;&lt;\"Number of shares can't be negative;\" &lt;&lt; company &lt;&lt;\" shares set to 0.\\n\"; shares = 0;}elseshares=n;share_val=pr;set_tot();} 注意“参数名co，n，pr不能与类成员相同.构造函数的参数表示不是类成员，而是赋给类成员的值。 区分参数名和类成员：一种常见的做法是在数据成员名中使用m_前缀 string m_company;;另外一种常见的做法是，在成员名中使用后缀_ string company_;使用构造函数 显式调用 1Stock food = Stock1(\"World cabbage\",250,1.25); 隐式调用 123Stock garment(\"Furry Mason\",50,2.5);//等价于Stock garment= Stock(\"Furry Mason\",50,2.5); 每次创建类对象（甚至使用new动态分配内存）时，C++都是用类结构函数。 1Stock *pstock= new Stock(\"Electroshock Games\",18,19.0);//对象没有名称，但可以使用指针来管理对象 默认构造函数未提供显示初始值是，用来创建对象的构造函数。例: 1Stock fluffy_the_cat;//use the default constructor 当且今当没有定义任何构造函数时，编译器才会提供默认构造函数。 为类定义了构造函数后，程序员就必须为它提供默认构造函数 如果提供了非默认构造函数（如Stock(const string &amp;co,long n,double pr);），但没有提供构造函数，下面声明将出错（禁止创建未初始化对象）1Stock stock1; 如何定义默认构造函数：方法1：给已有构造函数函数的所有参数提供默认值 1Stock(const string &amp;co=\"Error\",int n=0,double pr=0.0); 方法2：通过函数重载来定义另外一个构造函数—一个没有参数的构造函数 1Stock(); 为Stock类提供一个默认构造函数： 12345678//隐式初始化所有对象，提供初始值Stock::Stock(){company = \"no name\";shares = 0;share_val = 0.0;total_val = 0.0;} 使用默认构造函数： 123Stock first;//隐式地调用默认的构造函数Stock first = Stock();//显式地Stock * prelief=new Stock;//隐式地 然而不要被废默认构造函数的隐式形式所误导： 123Stock first(\"Concrete Conglomerate\");//调用构造函数Stcok second(); //声明一个函数Stock third； //调用默认构造函数 析构函数 对象过期是，程序将自动调用该特殊的成员函数。析构函数完成清理工作 如果构造函数使用new来分配内存，则析构函数将使用delete来释放这些内存。 什么时候调用析构函数？这由编译器决定，不应在代码中显示地调用析构函数 如果创建的是静态存储类对象，其析构函数将在程序结束时自动被调用。2 .如果创建的是自动存储类对象，则其析构函数将在程序执行完代码块时（该对象是在其中定义的）自动被调用。 如果对象是通过new创建的，则它将驻留在栈内存或自由存储区中，当使用delete来释放内存时，其析构函数将自动被调用。程序可以创建临时变量对象来完成特定操作，在这种情况下，程序将在结束对该对象的使用时自动调用其析构函数。 总的来说：类对象过期时（需要被销毁时），析构函数将自动被调用。因此必须有一个析构函数。如果程序员没有提供析构函数，编译器将隐式地声明一个默认构造函数。 C++列表初始化只要提供与某个构造函数的参数列表匹配的内容，并用大括号将它们括起。 123Stock hot_tip = {\"Derivatives Plus Plus\",100 ,45.0};//构造函数Stock jock {\"Sport Age Storage,Inc\"};//构造函数Stock temp{};//默认构造函数 前两个声明中，用大括号括起的列表与下面的构造函数匹配： 1Stock(const string &amp;co,long n=0,double pr=0.0);//原型 因此，用该构造函数来创建这两个对象。创建对象jock时，第二和第三个参数将默认值为0和0.0。第三个声明与默认构造函数匹配，因此将使用该构造函数创建对象temp。 const成员函数1void Stock::show() const;//promises not to change invoking object 以这种方式声明和定义的类成员函数被称为const成员函数。就像应景可能将const引用和指针作函数参数一样，只要类方法不修改调用对象，就应该将其声明为const this指针有的方法可能涉及两个对象，在这种情况下需要使用C++的this指针（比如运算符重载） 提出问题：如何实现：定义一个成员函数，查看两个Stocl对象，并返回股价高的那个对象的引用。 最直接的方法是，返回一个引用，该引用指向股价总值较高的对象，因此，用于比较的方法原型如下：1const Stock &amp; topval(const Stock &amp; s) const;//该函数隐式地访问一个对象，并返回其中一个对象 第一个const：由于返回函数返回两个const对象之一的引用，因此返回类型也应为const引用 第二个const：表明该函数不会修改被显式访问的对象 第三个const：表明该函数不会修改被隐式访问的对象 调用： 1top = stock1.topval(stock2);//隐式访问stock1，显式访问stock2 this 指针用来指向调用成员函数的对象（this被作为隐藏参数传递给方法）。 每个成员函数（包括构造函数和析构函数）都有一个this指针。this指针指向调用对象 如果方法需要引用整个调用对象，可一个使用表达式*this。 实现： 1234567const Stock &amp; topval(const Stock &amp; s) const{if(s.total_val&gt;total_val)return s;elsereturn *this;} 创建对象数组123456Stock stocks[4]={ Stock(\"NanoSmart\",12,20.0), Stock(\"Boffo Objects\",200,2.0), Stock(\"Monolothic Obelisks\",130,3.25), Stock(\"Fleep Enterprises\",60,6.5)}; 类作用域回顾： 全局（文件）作用域，局部（代码块）作用域 可以在全局变量所属的任何地方使用它，而局部变量只能在其所属的代码块中使用。函数名称的作用域也可以是全局的，但不能是局部的。 类作用域 在类中定义的名称（如类数据成员和类成员函数名）的作用域为整个类。 类作用域意味着不能从外部直接访问类成员，公有函数也是如此。也就是说，要用调用公有成员函数，必须通过对象。 使用类成员名时，必须根据上下文使用，直接成员运算符（.），间接成员运算符（-&gt;）或者作用域解析符（::） 作用域为类的常量下面是错误代码 123456class Bakery{private:const int Months=12;//错误代码double cots[Months];} 这是行不通的，因为声明类只是描述了对象的形式，并没有创建对象。因此在创建对象之前，并没有用于存储值的空间。 解决： 方法一：使用枚举123456class Bakery{private:enum{Months=12};double costs[Months];} 这种方式声明枚举并不会创建类数据成员。也就是说，所有对象都不包含枚举。另外，Months只是一个符号名称，在作用域为整个类的代码中遇到他时，编译器将用12来替换它。 方法二：使用关键字static123456class Bakery{private:static const int Months=12；double costs[Months];} 这将创建一个名为Months的常量，该常量与其他静态变量存储在一起，而不是存储在对象中。因此，只有一个Months常量，被所有Bakery对象共享。 作用域内枚举（C++11）传统的枚举存在一些问题，其中之一是两个枚举定义的枚举量可能发生冲突。 12enum egg{Small，Medium,Large，XLarge};enum t_shirt{Small,Medium,Large,Xlarge}; 这将无法通过编译因为egg Small和t_shirt Small位于相同的作用域内，他们将发生冲突。 新枚举12enum class egg{Small，Medium,Large，XLarge};enum class t_shirt{Small,Medium,Large,Xlarge}; 作用域为类后，不同枚举定义的枚举量就不会发生冲突了。 class也可以用关键字struct来代替 使用： 12egg choice = egg::Large;t_shirt Floyd=t_shirt::Large; 注意：作用域内枚举不能隐式地转换为整型，下面代码错误 1int ring = Floyd;//错误 但是必要时可以进行显式转换 1int Floyd = int(t_shirt::Small); 抽象数据类型ADT(Abstract Data Type) 以抽象的方式描述数据类型，而没有引入语言和细节 11使用类运算符重载 运算符重载或函数多态—定义多个名称相同但特征标（参数列表）不同的函数 运算符重载—允许赋予运算符多种含义 运算符函数：operator op(argument-list)示例： 1234567891011//有类方法：Time Sum(const Time &amp;t)const;//定义：Time Time::Sum(const Time &amp; t)const{Time sum;sum.minutes = minutes + t.minutes;sum.hours = hours + t.hours + sum.minutes/60;sum.minutes%=60;retrun sum;} 返回值是函数创建一个新的Time对象（sum），但由于sum对象是局部变量，在函数结束时将被删除，因此引用指向一个不存在的对象，返回类型Time意味着程序将在删除sum之前构造他的拷贝，调用函数将得到该拷贝 运算符重载，只需把上述函数名修改即可Sum()的名称改为operator+()1234567//调用：total=coding.Sum(fixing);//运算符重载后调用1. total=coding.operator+(fixing);2. total=coding+fixing;//t1,t2,t3,t4都是Time对象t4=t1+t2+t3; 重载限制下面是可重载的运算符列表： 运算符 分别 双目算术运算符 + (加)，-(减)，*(乘)，/(除)，% (取模) 关系运算符 ==(等于)，!= (不等于)，&lt; (小于)，&gt; (大于&gt;，&lt;=(小于等于)，&gt;=(大于等于) 逻辑运算符 ||(逻辑或)，&amp;&amp;(逻辑与)，!(逻辑非) 单目运算符 + (正)，-(负)，*(指针)，&amp;(取地址) 自增自减运算符 ++(自增)，–(自减) 位运算符 | (按位或)，&amp; (按位与)，~(按位取反)，^(按位异或),，&lt;&lt; (左移)，&gt;&gt;(右移) 赋值运算符 =, +=, -=, *=, /= , % = , &amp;=, |=, ^=, &lt;&lt;=, &gt;&gt;= 空间申请与释放 new, delete, new[ ] , delete[] 其他运算符 ()(函数调用)，-&gt;(成员访问)，,(逗号)，[](下标) 下面是不可重载的运算符列表： .：成员访问运算符 .*, -&gt;*：成员指针访问运算符 ::：域运算符 sizeof：长度运算符 ?:：条件运算符 重载的运算符(有些例外情况)不必是成员函数,但必须至少有一个操作数是用户定义的类型.这防止用户标准类型重载运算符 使用运算符时不能违反运算符原来的语句法则,例如,不恩那个将秋末运算符(%)重载成一个操作数。 不能创建新的运算符 不能重载下面的运算符 sizeof：sizeof运算符 .：成员运算符 ::：作用域解析运算符 ？:：条件运算符 typeid：一个RTTI运算符 const_cast：强制类型转换运算符 dynamic_cast：强制类型转换运算符 static_cast：强制类型转换运算符 reinterpret_cast：强制类型转换运算符 下面运算符只能通过成员运算符函数进行重载 =：赋值运算符 ()：函数调用运算符 []：下标运算符 -&gt;：通过指针访问类成员的运算符 友元函数C++控制类对象私有部分的访问。通常，公有方法提供唯一的访问途径。 C++提供了另外一种形式的访问权限：友元 友元函数 友元类（15章） 友元成员函数（15章） 友元函数：通过让函数成为类的友元，可以赋予该函数与类成员函数相同的访问权限。 问：为何需要友元？为类重载二元运算符是（带两个参数的运算符）常常需要友元函数。将Time对象乘以实数就属于这种情况之前我们有运算符重载： A = B * 2.75;//Time operator*(double n)const; 如果要实现 A=2.75 * B;//不对应成员函数 cannot correspond to a member function 因为2.75不是TIme类型的对象。左侧炒作书应是调用对象 解决： 告知每个人（包括程序员自己），只能按 B * 2.75这种格式编写。 非成员函数（非成员函数来重载运算符），非成员函数不是由对象调用的，它所使用的所有值（包括对象）都是显式参数。 有函数原型： 1Time operator * (double m,const Time &amp;t); 使用： 1A=2.75 * B;或 A=operator *(2.75,B); 问题：非成员函数不能访问类的私有数据，至少常规非成员函数不能访问 解决：友元函数（非成员函数，但其访问权限与成员函数相同。）创建友元函数 将其原型放在类声明中，并在原型声明前加上关键字friend* 声明：friend Time operator * (double m,const Time &amp; t);。该原型声明意味着下面两点： 虽然，operator* ()函数是在类中声明的，但它不是成员函数，因此不能使用成员运算符来调用； 虽然，operator* ()函数不是成员函数，但它与成员函数的访问权限相同。 定义：不要使用Time::限定符，不要再定义中使用关键字friend 12345678Time operator*(double m,const Time &amp; t){Time result;long totalminutes=t.hours*mult*60+t.minutes*mult;resut.hours = totalminutes/60;result.minutes=totalminutes%60;return result;} 注：不必是友元函数（不访问数据成员也能完成功能) 1234Time operator * (double m,const Time &amp; t){return t*m;//调用了Time operator*(double n)const} 重载&lt;&lt;运算符常用友元：重载座左移运算符 第一种重载版本 使用一个Time成员函数重载&lt;&lt; 1trip&lt;&lt;cout;//（trip是Time对象）这样会让人困惑 通过使用友元函数，可以像下面这样重载运算符： 1234void operator&lt;&lt;(ostream &amp; os,const Time&amp; t){os&lt;&lt;t.hours&lt;&lt;\"hours\"&lt;&lt;t.minutes&lt;&lt;\"minute\";} 该函数成为Time类的一个友元函数（operator&lt;&lt;()直接访问Time对象的私有成员），但不是ostream类的友元（从始至终都将ostream对象作为一个整体来使用）第二种重载版本按照上面的定义，下面语句会出错：1cout&lt;&lt;\"Trip Time:\"&lt;&lt;trip&lt;&lt;\"(Tuesday)\\n\"//不能这么做 应该修改友元函数返回ostream对象的引用即可： 12345ostream&amp; operator&lt;&lt;(ostream &amp; os,const Time&amp; t){os&lt;&lt;t.hours&lt;&lt;\"hours\"&lt;&lt;t.minutes&lt;&lt;\"minute\";return os;} 按照上面的定义，下面可以正常运行： 1cout&lt;&lt;\"Trip Time:\"&lt;&lt;trip&lt;&lt;\"(Tuesday)\\n\"//正常运行 类继承属性让ostream引用能指向ostream对象和ofstream对象12345#include&lt;fstream&gt;ofstram fout;fout.open(\"Savetime.txt\");Time trip(12,40);fout&lt;&lt;trip;//等价于operator&lt;&lt;(fout,trip); 类的自动类型转换和强制转换有构造函数Stonewt(double lbs);可以编写下列代码： 12stonewt mycat;//创建一个对象mycat=19.6；//使用了Stonewt(double lbs)构造函数创意了一个临时对象 上面使用了一个Stonewt(double lbs)构造函数创建了一个临时对象，然后将该对象内容复制到了mycat中，这一过程（19.6利用构造函数变成类对象）需要隐式转换，因为是自动进行的，而不需要显式强制转换。 —&gt;只接受一个参数类型的构造函数定义了从参数类型到类类型的转换 注意：只有接受一个参数的构造函数才能作为转换函数，然而，如果第二个参数提供默认值，它便可用于转换int 1Stonewt(int stn,double lbs=0); explicit这种自动特性并非总是合乎需要的，因为会导致意外的类型转换。 新增关键字explicit，用于关闭这种自动特性，也就是说，可以这样声明构造函数：1234567explicit Stonewt(double lbs);//关闭了上面的隐式转换，但允许显式转换，即显式强制类型转换Stonewt mycat;mycat =19.6;//错误代码mycat = Stonewt(19.6);//这里是调用构造函数mycat =(Stonewt)19.6;//这里是前置类型转换 总结 当构造函数只接受一个参数是，可以使用下面的格式来初始化类对象。1Stonewt incognito=2.75; 这等价于前面介绍过的另外两种格式：(这两种格式可用于接收多个参数的构造函数)Stonewt incognito(2.75);Stonewt incognito = Stonewt(2.75); 下面函数中，Stonewt和Stonewt&amp;形参都与Stonewt实参匹配 12345678void display(const Stonewt &amp; st,int n){for(int=0;i&lt;n;i++){cout&lt;&lt;\"WOW!\";st&gt;show_stn();}} 语句display(422,2);中 编译器先查找自动类型转换中42转Stone的构造函数Stonewt(int) 不存在Stonewt(int)的话，Stonewt(double)构造函数满足这种要求因为，编译器将int转换为double 类的转换函数 构造函数只用于某种类型到类类型的转换，要进行相反的转换，必须用到特殊的C++运算符—转换函数 转换函数必定是类方法 用户定义的强制类型转换，可以向使用强制类型转换那样使用它们。 123Stonewt wolf(285,7);double host = double(wolfe);//格式1double thinker=(double)wolfe;//格式2 也可以让编译器来决定如何做： 12Stonewt wolf(20,3);double star =wells;//隐式转换 创建转换函数opeator typeName(); 转换函数必定是类方法 转换函数不能指定返回类型 转换函数不能有参数 例如：转换函数为double类型的原型如下 1operator double();//不要返回类型也不要参数 如何定义 头文件中声明： 12operator int() const;operator double() const; cpp文件中定义： 123456789Stonewt::opeator int() const{return int (pounds+0.5);//四舍五入}Stonewt::opeator double() const{return pounds;//四舍五入} 二义性C++中，int和double值都可以被赋值给long变量，下面语句被编译器认为有二义性而拒绝了。 1234long gone = poppins;//注：poppins是Stonewt对象//但是还是可以进行强制类型转换long gone = (double)poppins;long gone =int (poppins); 避免隐式转换 方法1：C++98中，关键字explicit不能用于转换函数，但C++11消除了这种限制。因此，在C++11中，可将转换运算符声明为显示的：1234567class Stonewr{...//conversion functionsexplicit operator int() const;explicit operator double() const;}; 有了这些声明后，需要前置转换时，将调用这些运算符。 方法2：用一个功能相同的非转换函数替换转换函数即可，但仅在被显式调用时，该函数才会执行。也就是说，可以将：1Stonewt::operator int(){return int(pounds+0.5);} 替换为 1int Stonewt stone_to_int(){return int(pounds+0.5);} 这样下面语句为非法的： 1int plb=popins; 需要转换时只能调用stone_to_int()： 1int plb =poppins.stone_to_int(); 12类和动态内存分配 动态内存和类 –&gt;让程序运行时决定内存分配，而不是在编译时决定。 —-&gt;使用new和delete运算符来动态控制内存 ——&gt;在类中使用这些运算符将导致许多新的编程问题。这种情况下，析构函数将是必不可少的，而不再是可有可无的。 ——–&gt;有时候还必须重载赋值运算符。 C++为类自动提供了下面这些成员函数 1.默认构造函数，如果没有定义构造函数；记得自己定义了构造函数时，编译器不会再提供默认构造函数，记得自己再定义一个默认构造函数。带参数的构造函数也可以是默认构造函数，只要所有参数都有默认值。 2.默认析构函数，如果没有定义；用于销毁对象 3.复制（拷贝）构造函数，如果没有定义；用于将一个对象赋值到新创建的对象中（将一个对象初始化为另外一个对象）。用于初始化的过程中，而不是常规的赋值过程。 每当程序生成对象副本时（函数按值传递对象，函数返回对象时），编译器都将使用复制构造函数 编译器生成临时对象是，也将使用复制构造函数默认的复制构造函数的功能---&gt;逐个复制非静态成员（成员复制也叫浅复制,给两个对象的成员划上等号），复制的是成员的值；如果成员本身就是类对象，则将使用这个类的复制构造函数复制成员对象,静态成员变量不受影响，因为它们属于整个类，而不是各个对象 浅复制面对指针时会出现错误，在复制构造函数中浅复制的等价于sailor.len=sport.len;sailor.str=sport.str;前一个语句正确，后一个语句错误，因为成员char* str是指针，得到的是指向同一字符串的指针！！！ 当出现动态内存分配时，要定义一个现实复制构造函数—&gt;进行深度复制(deep copy) 123456StringBad::StringBad(const StringBad &amp; st){len=st.len;str=new char[len+1];std::strcpy(str,st.str);} 4.赋值运算符，如果没有定义；赋值运算符只能由类成员函数重载的运算符之一。将已有的对象赋值给另外一个对象时（将一个对象复制给另外一个对象），使用赋值运算符。原型：class_name &amp; class_name::operator==(const class_name &amp;);接受并返回一个指向类对象的引用。 与复制构造函数相似，赋值运算符的隐式实现也对成员进行逐个复制 解决：提供赋值运算符（进行深度复制）定义，其实现业余复制构造函数相似，但有一些差别 123456789101112131415161718192021222324//代码1：先申请内存，再deleteCMyString&amp; CMyString::operator=(const CMyString&amp; str){if(this==str){char *temp_pData=new char[strlen(str.m_pData)+1)];delete[]m_pData;m_pData=temp_pData;strcpy(m_pData,str.m_pData);}return *this;}//代码2：调用复制构造函数CMyString&amp; CMyString::operator=(const CMyString&amp; str){if(this==str){CMyString strTemp(str);//复制构造函数创建临时对象，临时对象失效时会自动调用析构函数char* pTemp=strTemp.m_pData;//创建一个指针指向临时对象的数据成员m_pDatastrTemp.m_pData=m_pData;//交换m_pData=pTemp;//交换}return *this;} 5.地址运算符，如果没有定义； 6.移动构造函数(move construtor)，如果没有定义； 7.移动赋值运算符(move assignment operator)。 静态类成员函数 1.静态函数：静态函数与普通函数不同，它只能在声明它的文件中可以见，不能被其他文件使用。定义静态函数的好处：静态函数不会被其他文件使用。其他文件中可以定义相同名字的函数，不会发生冲突。 2.静态类成员函数:与静态成员数据一样，我们可以创建一个静态成员函数，它为类的全部服务，而不是为某一个类的具体对象服务。静态成员函数与静态成员数据一样，都是在类的内部实现，属于类定义的一部分。普通成员函数一般都隐藏了一个this指针，this指针指向类的对象本身。 3.静态成员函数由于不是与任何对象相联系，因此不具有this指针，从这个意义上讲，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函数，它只能调用其余的静态成员函数静态成员函数总结： 1.出现在类体外的函数不能指定关键字static； 2.静态成员之间可以互相访问，包括静态成员函数访问静态数据成员和访问静态成员函数； 3.非静态成员函数可以任意地访问静态成员函数和静态数据成员； 4.静态成员函数不能访问非静态成员函数和非静态数据成员 5.由于没有this指针的额外开销，因此静态成员函数与类的全局函数相比，速度上会有少许的增长 6.调用静态成员函数，可以用成员访问操作符(.)和(-&gt;)为一个类的对象或指向类对象的指调用静态成员函数。 构造函数中使用new时应注意的事项 1.如果构造函数中使用new来初始化指针成员，则应在析构函数中使用delete。 2.new和delete必须相互兼容，new对应于delete，new[]对应于delete[] 3.如果有多个构造函数，则必须以相同的方式使用new，要么中括号，要么都不带。因为只有一个析构函数，所有的构造函数都必须与它兼容。然而，可以在一个构造函数中使用new来初始化指针，而在另外一个构造函数中初始化为空（0或nullptr），这是因为delete（无论是带括号，还是不带括号）可以用于空指针。 4.应定义一个复制构造函数，通过深度复制将一个对象初始化为另外一个对象。 5.应当定义一个赋值运算符，通过深度复制将一个对象复制给另外一个对象。 有关返回对象的引用 1.首先，返回对象将调用复制构造函数（给新创建的临时对象复制（初始化）），而返回引用不会 2.其次，返回引用指向的对象因该在调用函数执行时存在。 3.返回作为参数输入的常量引用，返回类型必须为const，这样才匹配。 使用指向对象的指针Class_name* ptr = new Class_name;调用默认构造函数 定位new运算符/常规new运算符123456789101112131415161718//使用new运算符创建一个512字节的内存缓冲区char* buffer =new char[512];//地址：(void*)buffer=00320AB0//创建两个指针；JustTesting *pc1,*pc2;//给两个指针赋值pc1=new (buffer)JustTesting;//使用了new定位符，pc1指向的内存在缓冲区 地址：pc1=00320AB0pc2=new JustTesting(\"help\",20);//使用了常规new运算符，pc2指向的内存在堆中//创建两个指针；JustTesting *pc3,*pc4;//给两个指针赋值pc3=new (buffer)JustTesting(\"Bad Idea\",6);//使用了new定位符，pc3指向的内存在缓冲区 地址：pc3=00320AB0//创建时，定位new运算符使用一个新对象覆盖pc1指向的内存单元。//问题1：显然，如果类动态地为其成员分配内存，该内存还没有释放，成员就没了，这将引发问题。pc4=new JustTesting(\"help\",10);//使用了常规new运算符，pc4指向的内存在堆中//释放内存delete pc2；//free heap1delete pc4；//free heap2delete[] buffer//free buffer 解决问题1，代码如下： 12pc1=new (buffer)JustTesting;pc3=new (buffer+sizeof(JustTesting))(\"Bad Idea\",6); 问题2： 将delete用于pc2，pc4时，将自动调用为pc2和pc4指向的对象调用析构函数；问题2：然而，将的delete[]用于buffer时，不会为使用定位new运算符创建的对象调用析构函数 解决问题2：显式调用析构函数 12pc3-&gt;~JustTesting;pc1-&gt;~JustTesting; 嵌套结构和类 在类声明的结构、类或枚举被认为是被嵌套在类中，其作用域为整个类 这种声明不会创建数据对象，而是指定了可以在类中使用的类型。 1.如果声明是在类的私有部分进行的，则只能在这个类中使用被声明的类型。 2.如果声明是在公有部分进行的，则可以从类的外部通过作用域解析运算符使用被声明的类型例如，如果Node是在Queue类的公有部分声明的，则可以在外部声明Queue::Node类型的变量。 默认初始化a.内置类型的变量初始化如果定义变量时没有指定初始值，则变量被默认初始化。默认值由变量类型和定义变量的位置决定。 如果是内置类型的变量未被显示初始化，它的值由定义位置决定。定义于任何函数体外的变量被初始化为0。 12//不在块中int i;//正确，i会被值初始化为0，也称为零初始化 定义于函数体内部的内置类型变量将不被初始化（uninitialized）。一个未被初始化的内置类型变量的值是未定义的，如果试图拷贝或其他形式的访问此类型将引发错误 123451 {//在一个块中2 int i;//默认初始化，不可直接使用3 int j=0;//值初始化4 j=1;//赋值5 } b.类类型的对象初始化类通过一个或几个特殊的成员函数来控制其对象的初始化过程，这些函数叫做构造函数（constructor）。构造函数的任务是初始化类对象的数据成员。由编译器提供的构造函数叫（合成的默认构造函数）。合成的默认构造函数将按照如下规则初始化类的数据成员。 如果存在类内初始值（C++11新特性），用它来初始化成员。 12345678class CC{public: CC() {} ~CC() {}private: int a = 7; // 类内初始化，C++11 可用} 否则，没有初始值的成员将被默认初始化。 成员列表初始化 使用成员初始化列表的构造函数将覆盖相应的类内初始化 对于简单数据成员，使用成员初始化列表和在函数体中使用复制没什么区别 对于本身就是类对象的成员来说，使用成员初始化列表的效率更高 如果Classy是一个类，而mem1，mem2，mem3都是这个类的数据成员，则类构造函数可以使用如下的语法来初始化数据成员。 1234Classy::Classy(int n,intm):mem1(n),mem2(0),men3(n*m+2){//...} 1.这种格式只能用于构造函数 2.必须用这种格式来初始化非静态const数据成员（至少在C++之前是这样的）； 3.必须用这种格式来初始化引用数据成员 数据成员被初始化顺序与它们出现在类声明中的顺序相同，与初始化器中的排列顺序无关 13类继承基类和派生类的特殊关系 1.派生类对象可以使用非私有的基类方法 2.基类指针（引用）可以在不进行显示转换的情况下指向（引用）派生类对象（反过来不行）；基类指针或引用只能用来调用基类方法，不能用来调用派生类方法。 3.不可以将基类对象和地址赋给派生类对象引用和指针。 派生类构造函数要点1.首先创建基类对象；2.派生类构造函数应通过成员初始化列表将基类信息传递给基类构造函数。3.派生类构造函数应初始化新增的数据成员。注意：可以通过初始化列表语法知名指明要使用的基类构造函数，否则使用默认的基类构造函数。派生类对象过期时，程序将首先调用派生类的析构函数，然后在调用基类的析构函数。 1234RetedPlayer::RetedPlayer(unsigned int r,const string &amp; fn,const string &amp;ln, bool ht)//:TableTennisPlayer()等价于调用默认构造函数{rating = r;} 虚方法 经常在基类中将派生类会重新定义的方法声明为虚方法。方法在基类中被声明为虚的后。它在派生类中将自动生成虚方法。然而，在派生类中使用关键字virtual来指出哪些函数是虚函数也不失为一个好方法。 如果要在派生类中重新定义基类的方法，通常将基类方法声明为虚。这样，程序根据对象类型而不是引用或指针类型来选择方法版本，为基类声明一个虚的析构函数也是一种惯例，为了确保释放派生类对象时，按正确的顺序调用析构函数。 虚函数的作用：基类指针（引用）指向（引用）派生类对象，会发生自动向上类型转换，即派生类升级为父类，虽然子类转换成了它的父类型，但却可正确调用属于子类而不属于父类的成员函数。这是虚函数的功劳。 派生类方法可以调用公有的基类方法在派生类方法中，标准技术是使用作用域解析运算符来调用基类方法，如果没有使用作用域解析符，有可能创建一个不会终止的递归函数。如果派生类没有重新定义基类方法，那么代码不必对该方法是用作用域解析符（即该方法只有在基类中有）。 静态联编和动态联编函数名联编（binding）：将代码中的函数调用解释为执行特定的代码块。 在C语言中，这非常简单，因为每个函数名都对应一个不同的函数。 在C++中，由于函数重载的缘故，这个任务更繁杂，编译器必须查看函数参数以及函数名才能确定使用哪个函数。 静态联编(static binding) 在编译过程中进行联编，又称为早期联编 动态联编(dynamic binding) 编译器在程序运行时确定将要调用的函数，又称为晚期联编什么时候使用静态联编，什么时候使用动态联编？ 编译器对虚方法使用静态联编，因为方法是非虚的，可以根据指针类型关联到方法。 编译器对虚方法使用动态联编，因为方法是虚的，程序运行时才知道指针指向的对象类型，才来选择方法。（引用同理）效率：为使程序能够在运行阶段进行决策，必须采取一些方法来跟踪基类指针和指向引用对象的对象类型，这增加了额外的处理开销 例如，如果类不会用作基类，则不需要动态联编。 同样，如果派生类不重新定义基类的任何方法，也不需要动态联编。 通常，编译器处理函数的方法是：给每个对象添加一个隐藏成员–指向函数地址数组的指针(vptr) 使用虚函数时，在内存和执行速度上有一定的成本，包括：a.每个对象为存储地址的空间；b.对于每个类，比那一期都将创建一个虚函数地址表（数组）vtbl；c.对于每个函数调用，都需要执行一项额外的操作，到表中查找地址。虽然非虚函数的效率比虚函数稍高，但不具有动态联编的功能 总结： 在基类方法的声明中使用关键字virtual可使该方法在基类以及所有的派生类（包括从派生类派生出来的类）中是虚的。 如果使用指向对象的引用或指针来调用虚方法，程序将使用为对象类型定义的方法，而不是用为引用或者指针类型定义的方法。这个成为动态联编或者晚期联编。这种行为非常重要。因为这样基类指针或引用可以指向派生类对象。 如果定义的类将被用作基类，则应该将那些在派生类中重新定义的类方法生命为虚的。 虚函数细节 1.构造函数不能是虚函数，派生类不能继承基类的构造函数，将类构造函数声明为虚没什么意义。 2.析构函数应当是虚函数，除非类不用作基类。 1.当子类指针指向子类是，析构函数会先调用子类析构再调用父类析构，释放所有内存。2.当父类指针指向子类时，只会调用父类析构函数，子类析构函数不会被调用，会造成内存泄漏。（基类析构函数声明为虚，可以使得父类指针能够调用子类虚的析构函数）所以我们需要虚析构函数，将父类的析构函数定位为虚，那么父类指针会先调用子类的析构函数，再调用父类析构，使得内存得到释放。 3.友元不能是虚函数，因为友元不是类成员，只有类成员才是虚函数。 4.如果派生类没有重新定义函数。将使用该函数的基类版本。 5.重新定义将隐藏方法不会生成函数的两个重载版本，而是隐藏基类版本。如果派生类位于派生链中，则使用最新的虚函数版本，例外的情况是基类版本是隐藏的。总之，重新定义基本的方法并不是重载。如果重新定义派生类中的函数，将不只是使用相同的函数参数列表覆盖其基类声明，无论参数列表是否相同，该操作将隐藏所有的同名方法。 两条经验规则 1.如果重新定义继承的方法，应确保与原来的原型完全相同，但是如果返回类型是积累的引用或指针，则可以修改为指向派生类的引用或指针（只适用于返回值而不适用于参数），这种例外是新出现的。这种特性被称为返回类型协变（convariance of return type），因此返回类型是随类类型变化的。 123456789101112//基类class Dwelling{public:virtual Dwelling &amp; build(int n);}//派生类class Hovel:public Dwelling{public:virtual Hovel &amp; build(int n);} 2.如果基类声明被重载了，则应该在派生类中重新定义所有基类版本。 123456789101112131415161718//基类class Dwelling{public://三个重载版本的showperksvirtual void showperks（int a）const；virtual void showperks（double a）const；virtual void showperks（ ）const；}//派生类class Hovel:public Dwelling{public://三个重新定义的的showperksvirtual void showperks（int a）const；virtual void showperks（double a）const；virtual void showperks（ ）const；} 如果只重新定义一个版本，则另外两个版本将被隐藏，派生类对象将无法使用它们，注意，如果不需要修改，则新定义可知调用基类版本： 1234void Hovel::showperk()const{Dwelling::showperks();} 访问控制：protected 1.关键字protected与private相似，在类外，只能用公有类成员来访问protected部分中的类成员。 2.private和protected之间只有在基类派生的类才会表现出来。派生类的成员可以直接访问基类的保护成员，但是不能直接访问基类的私有成员。提示： 1.最好对类的数据成员采用私有访问控制，不要使用保护访问控制。 2.对于成员函数来说，保护访问控制很有用，它让派生类能够访问公众不能使用的内部函数。 抽象基类（abstract base class）ABC-&gt;至少包含一个纯虚函数 在一个虚函数的声明语句的分号前加上 =0 ；就可以将一个虚函数变成纯虚函数，其中，=0只能出现在类内部的虚函数声明语句处。 纯虚函数只用声明，而不用定义，其存在就是为了提供接口，含有纯虚函数的类是抽象基类。我们不能直接创建一个抽象基类的对象，但可以创建其指针或者引用。 值得注意的是，你也可以为纯虚函数提供定义，不过函数体必须定义在类的外部。但此时哪怕在外部定义了，也是纯虚函数，不能构建对象。 派生类构造函数只直接初始化它的直接基类。多继承的虚继承除外。 抽象类应该注意的地方 抽象类不能实例化，所以抽象类中不能有构造函数。 纯虚函数应该在派生类中重写，否则派生类也是抽象类，不能实例化。 抽象基类的作用 C++通过使用纯虚函数（pure virtual function）提供未实现的函数。纯虚函数声明的结尾处为=0， 1virtual double Area() const=0;//=0指出类是一个抽象基类，在类中可以不定义该函数 可以将ABC看作是一种必须的接口。ABC要求具体派生类覆盖其纯虚函数—迫使派生类遵顼ABC设置的接口规则。简单来说是：因为在派生类中必须重写纯虚函数，否则不能实例化该派生类。所以，派生类中必定会有重新定义的该函数的接口。 从两个类(具体类concrete)（如：Ellipse和Circle类）中抽象出他们的共性，将这些特性放到一个ABC中。然后从该ABC派生出的Ellipse和Circle类。 这样，便可以使用基类指针数组同时管理Ellipse和Circle对象，即可以使用多态方法* 友元 就像友元关系不能传递一样，友元关系同样不能继承，基类的友元在访问派生类成员时不具有特殊性，类似的，派生类的友元也不能随意访问基类的成员。 继承和动态内存分配(todo) 只有当一个类被用来做基类的时候才会把析构函数写成虚函数。 当基类和派生类都采用动态内存分配是，派生类的析构函数，复制构造函数，赋值运算符都必须使用相应的基类方法来处理基类 14C++中的代码重用（公有继承，包含对象的类，私有继承，多重继承，类模板）包含（containment）：包含对象成员的类本身是另外一个类的对象。这种方法称为包含（containment），组合（composition），或层次化（laying） 私有继承（还是has-a关系）基类的公有成员和保护成员都将成为派生类的私有成员。和公有继承一样，基类的私有成员是会被派生类继承但是不能被派生类访问。基类方法将不会成为派生类对象公有接口的一部分，但可以在派生类中使用它们。 1.初始化基类组件 和包含不同，对于继承类的新版本的构造函数将使用成员初始化列表语法，它使用类名（std::string，std::valarry）而不是成员名来表示构造函数 1234567891011121314//Student类私有继承两个类派生而来,本来包含的时候两个基类分别是name和scoreclass Student:private std::string,private std::valarry&lt;double&gt;{public:......};//如果是包含的构造函数Student(const char *str,const double *pd,int n):name(str),score(pd,n){}//继承类的构造函数 Student(const char *str,const double *pd,int n):std::string(str),std::valarry&lt;double&gt;(pd,n){} 2.访问基类的方法 a.包含书用对象（对象名）来调用方法 b.私有继承时，将使用类名和作用域解析运算符来调用方法 1234567double Student::Average() const{if(ArrayDb::size()&gt;0）//ArrayDb typedef为std::valarry&lt;double&gt; return ArrayDb::sum()/ArrayDb::size();else return 0;} 3.访问基类对象 使用私有继承时，该string对象没有名称。那么，student类的代码如何访问内部string对象呢？ 强制类型转换! 本来子到父自动类型提升,不需要强制类型转换。父到子才需要强制类型转换。但是下面是强制类型转换，原因在第4点那里写着。 由于Student类是从string类派生而来的，因此可以通过强制类型转换，将Student对象转换为S=string对象 123456//成员方法：打印出学生的名字//因为不是包含，只能通过强制类型转换const string &amp; Student::Name()const{retrun (const string &amp;) *this;} 4.访问基类友的元函数 用类名显式地限定函数名不适合友元函数，因为友元不属于类。不能通过这种方法访问基类。 解决：通过显示地转换为基类来调用正确的函数 1234osstream &amp; operator&lt;&lt;(ostream &amp; os,const Student &amp; stu){os &lt;&lt; \"Score for \"&lt;&lt;(const String &amp;) stu &lt;&lt;\":\\n\";//显式地将stu转换为string对象引用，进而调用基类方法} 引用不会自动转换为string引用原因： a.在私有继承中，未进行显示类型转换的派生类引用或指针，无法赋值给基类的引用或指针。 b.即使这个例子使用的是公有继承，也必须使用显示类型转换。原因之一是，如果不使用类型转换，下述代码将无法与函数原型匹配从而导致递归调用，os&lt;&lt;stu c.由于这个类使用的是多重继承，编译器将无法确定应转换成哪个基类，如果两个基类都提供函数operator&lt;&lt;()。 5.使用包含还是私有继承？通常，应使用包含来建立has-a关系；如果新需要访问原有的保护成员，或重新定义虚函数，则应使用私有继承。 6.保护继承 基类的公有成员和保护成员都将成为派生类的保护成员。 共同点：和私有继承一样，基类的接口在派生类中也是可用的，但在继承和结构之外是不可用的。 区别：使用私有继承时，第三代类将不能使用基类的接口，这是因为公有方法在派生类中将变成私有方法；使用保护继承时，基类的公有方法在第二代将变成保护的，因此第三代派生类可以使用它们。 特征 公有继承 保护继承 私有继承 公有成员变成 派生类的公有成员 派生类的保护成员 派生类的私有成员 保护成员变成 派生类的保护成员 派生类的保护成员 派生类的私有成员 私有成员变成 只能通过基类接口访问 只能通过基类接口访问 只能通过基类接口访问 能否隐式向上转换 是 是（但只能在派生类中） 否 7.使用using重新定义访问权限使用派生或私有派生时，基类的公有成员将成为保护成员或私有成员，假设要让基类方法在派生类外面可用 方法1，定义一个使用该基类方法的派生类方法 1234double Student::sum() const{return std::valarray&lt;double&gt;::sum();} 方法2，将函数调用包装在另外一个函数调用中，即使用一个using声明（就像空间名称一样） 1234567class Student::private std::string,private std::valarray&lt;double&gt;{...public: using std::valarray&lt;double&gt;::min; using std::valarray&lt;double&gt;::max;} //using声明只适用于继承，而不适用于包含//using声明只使用成员名—没有圆括号，函数特征表和返回类型 多重继承必须使用关键字public来限定每一个基类，这是因为，除非特别指出，否则编译器将认为是私有派生。（class 默认访问类型是私有，strcut默认访问类型是公有） 多重继承带来的两个主要问题： 1.从两个不同的基类继承同名方法。 2.从两个或更多相关的基类那里继承同一个类的多个实例。 123class Singer:public Worker{...};class Waiter:public Worker{...};class SingerWaiter:public Singer,public Waiter{...}; Singer和Waiter都继承一个Worker组件，因此SingerWaiter将包含两份Worker的拷贝–&gt;通常可以将派生来对象的地址赋给基类指针，但是现在将出现二义性。（基类指针调用基类方法时不知道调用哪个基类方法），第二个问题：比如worker类中有一个对象成员，那么就会出现 虚基类（virtual base class） 虚基类使得从多个类（他们的基类相同）派生出的对象只继承一个基类对象。1234class Singer:virtual public Worker{...};//virtual可以和public调换位置class Waiter:public virtual Worker{...;//然后将SingingWaiter定义为class SingingWaiter：public Singer,public Waiter{...}; 现在,SingingWaiter对象只包含Worker对象的一个副本 为什么不抛弃将基类声明为虚的这种方式，使虚行为成为MI的准则呢？（为什么不讲虚行为设为默认，而要手动设置） 第一，一些情况下，可能需要基类的多个拷贝； 第二，将基类作为虚的要求程序完成额外的计算，为不需要的工具付出代价是不应当的； 第三，这样做是有缺点的，为了使虚基类能够工作，需要对C++规则进行调整，必须以不同的方式编写一些代码。另外，使用虚基类还可能需要修改已有的代码 虚基类的构造函数（需要修改） 对于非虚基类，唯一可以出现在初始化列表的构造函数是即是基类构造函数。 对于虚基类，需要对类构造函数采用一种新的方法。 基类是虚的时候,禁止信息通过中间类自动传递给基类,因此向下面构造函数将初始化成员panache和voice，但wk参数中的信息将不会传递给子对象Waiter。然而，编译器必须在构造派生对象之前构造基类对象组件；在下面情况下，编译器将使用Worker的默认构造函数（即类型为Worker的参数没有用！而且调用了Worker的默认构造函数） 1SingingWaiter(const Worker &amp;wk,int p=0;int v=Singer:other):Waiter(wk,p),Singer(wk,v){}//flawed 如果不希望默认构造函数来构造虚基类对象，则需要显式地调用所需的基类构造函数。 1SingingWaiter(const Worker &amp;wk,int p=0;int v=Singer:other):Worker(wk),Waiter(wk,p),Singer(wk,v){} 上述代码将显式地调用构造函数worker(const Worker&amp;)。请注意，这种调用是合法的，对于虚基类，必须这样做；但对于非虚基类，则是非法的。 有关MI的问题 多重继承可能导致函数调用的二义性。 假如每个祖先（Singer，waiter）都有Show()函数。那么如何调用 1.可以使用作用域解析符来澄清编程者的意图： 12SingingWaiter newhire(\"Elise Hawks\",2005,6,soprano);newhire.Singer::Show();//using Singer Version 2.然而，更好的方法是在SingingWaiter中重新定义Show(),并指出要使用哪个show。 1P559～P560 1.混合使用虚基类和非虚基类 如果基类是虚基类，派生类将包含基类的一个子对象； 如果基类不是虚基类，派生类将包含多个子对象 当虚基类和非虚基类混合是，情况将如何呢？123456//有下面情况class C:virtual public B{...};//B为虚基类class D:virtual public B{...};//B为虚基类class X: public B{...}; //B为非虚基类class Y: public B{...}; //B为非虚基类class M:public C,public D,public X,public Y{...}; 这种情况下，类M从虚派生祖先C和D那里共继承了一个B类子对象，并从每一个非虚派生祖先X和Y分别继承了一个B类子对象。因此它(M)包含三个B类子对象。 当类通过多条虚途径和非虚途径继承了某个特定的基类时，该类包含一个表示所有的虚途径的基类子对象和分别表示各条非虚途径的多个基类子对象。(本例子中是1+2=3) 2.虚基类和支配(使用虚基类将改变C++解释二义性的方式) 使用非虚基类是，规则很简单，如果类从不同的类那里继承了两个或更多的同名函数（数据或方法），则使用该成员名是，如果没有用类名进行限定，将导致二义性。 但如果使用的是虚基类，则这样做不一定会导致二义性。这种情况下，如果某个名称优先于（dominates）其他所有名称，则使用它时，即使不使用限定符，也不会导致二义性。12345678910111213141516171819202122232425262728293031class B{public:short q();...};class C:virtual public B{public:long q();int omg();...};class D:public C{...}class E:virtual public B{private:int omg();...};class F: public D,public E{...}; 1.类C中的q()定义优先于类B中的q()定义，因为类C是从类B派生而来的。因此F中的方法可以使用q()来表示C::q().（父子类之间有优先级，子类大于父类） 2.任何一个omg()定义都不优先于其他omg()定义，因为C和E都不是对方的基类。所以，在F中使用非限定的omg()将导致二义性。 3.虚二义性规则与访问规则（pravite,public,protected）无关，也就是说即使E::omg是私有的，不能在F类中直接访问，但使用omg()仍将导致二义性。 类模板类模板 类模板和模板函数都是以template开头（当然也可以使用class），后跟类型参数；类型参数不能为空，多个类型参数用逗号隔开。 1234template &lt;typename 类型参数1，typename 类型参数2，typename 类型参数3&gt;class 类名{//TODO} 类模板中定义的类型参数可以用在函数声明和函数定义中， 类模板中定义的类型参数可以用在类型类声明和类实现中， 类模板的目的同样是将数据的类型参数化。 12345678910111213141516template &lt;class Type&gt;class Stack{private: enum {MAX=10}; Type items[MAX]; int top;public: Stack(); ……}template &lt;class Type&gt;Stack&lt;Type&gt;::Stack(){ top=0;} Type:泛型标识符，这里的type被称为类型参数。这意味着它们类似于变量，但赋给它们的不是数字，而只能是类型 相比于函数模板，类模板必须显式的提供所需的类型。 模板不是函数，它们不能单独编译。模板必须与特定的模板实例化(instantiation)请求一起使用,为此，最简单的方法是将所有模板信息放在一个文件中，并在要使用这些模板的文件中包含该头文件。 123//类声明Stack&lt;int&gt;将使用int替换模板中所有的TypeStack&lt;int&gt;kernels;Stack&lt;string&gt;colonels; 深入探讨模板模板具体化（instantiation）和实例化（specialization） 模板以泛型的方式描述类，而具体化是使用具体的类型生成类声明。 类模板具体化生成类声明 类实例化生成类对象 1.隐式实例化(implicit instantiation)他们声明一个或多个对象，指出所需的类型，而编译器使用通用模板提供的处方生成具体的类定义； 12345Array&lt;int,100&gt;stuff;//隐式实例化//在编译器处理对象之间，不会生成隐式实例化，如下Array&lt;double,30&gt;*pt;//a pointer,no object needed yet//下面语句导致编译器生成类定义，并根据该定义创建一个对象昂pt=new Array&lt;double,30&gt;; 2.显式实例化(explicit instantiation) 当使用关键字template并指出所需类型来声明类时，编译器将生成类声明的实例化 1template class ArrayTP&lt;string,100&gt;; 这种情况下，虽然没有指出创建或提及类对象，编译器也将生成类声明（包含方法定义）。和隐式实例化也将根据通用模板来生成具体化。 3.显式具体化(explicit specialization)—是特定类型（用于替换模板中的泛型）的定义格式：template&lt;&gt;class Classname{…};有时候，可能需要在特殊类型实例化是，对模板进行修改，使其行为不同。在这种情况下，可以创建显式实例化。 12345//原来的类模板template &lt;typename T&gt;class sortedArray{...//details omitted}; 当具体化模板和通用模板都与实例化请求匹配时，编译器将使用具体化版本。 12345//新的表示法提供一个专供const char*类型使用的SortedArray模板template&lt;&gt;class SortedArray&lt;const char*&gt;{...//details omitted}; 4.部分具体化(partical specialization) 部分限制模板的通用性 1234//general template 一般模板 template&lt;class T1,class T2&gt;class Pair{...};//specialization with T2 set to int部分具体化 template&lt;class T1&gt;class Pair&lt;T1,int&gt;{...}; 如果有多个模板可供选择，编译器将使用具体化程度最高的模板 123Pair&lt;double,double&gt;p1;//使用了一般的Pair类模板Pair&lt;double,int&gt;p2;//使用了部分具体化Pair&lt;T1,int&gt;Pair&lt;int,int&gt;p3//使用了显式实例化Pair&lt;int,int&gt; 也可以通过为指针提供特殊版本来部分具体化现有模板： 1234template&lt;class T&gt;class Feen{...};//一般版本的类模板template&lt;class T*&gt;class Feen{...};//部分具体化 将模板用作参数template&lt;template&lt;typename T&gt;class Thing&gt;class Crab 模板类和友元 模板类声明也可以有友元。模板的友元分为3类： 非模板友元： 约束(bound)模板友元，即友元的类型取决于类被实例化时的类型； 非约束(unbund)模板友元，即友元的所有具体化都是类的每一个具体化的友元。 模板类的非模板友元函数 在模板类中奖一个常规函数声明为友元：1234567template &lt;class T&gt;class HasFriend{public:friend void counts();...}; 上述声明指定counts()函数称为模板所有实例化的友元 counts()函数不是通过对象调用（它是友元不是成员函数），也没有对象参数，那么如何访问HasFriend对象？ 1.它可以访问全局对象 2.它可以使用全局指针访问非全局对象 3.可以创建自己的对象 4.可以访问独立于对象的模板类的静态成员函数 模板类的约束模板友元 1.首先，在类定义的前面声明每个模板函数 templatevoid counts();templatevoid report(T &amp;); 2.然后，在函数中再次将模板声明为友元。这些语句根据类模板参数的类型声明 1234567template&lt;typename TT&gt;class HasFriendT{...friend coid counts&lt;TT&gt;();friend coid report&lt;&gt;(HasFriendT&lt;TT&gt; &amp;);}; 3.为友元提供模板定义 模板类的非约束模板友元函数 前一节中的约束模板友元函数在类外面声明的模板的具体化。int类具体化获得int函数具体化，依此类推。通过类内部声明模板，可以创建非约束友元函数，即每个函数具体化都是每个类具体化的友元。对于非约束友元，友元模板类型参数与模板类类型参数是不同的：123456template&lt;typename T&gt;class ManyFriend{...template&lt;typename C,typename D&gt;friend void show2(C &amp;,D &amp;);}; 模板别名(C++11) 1.如果能为类型指定别名，浙江爱你个很方便，在模板设计中尤为如此。可使用typedef为模板具体化指定别名 1234567typedef std::array&lt;double,12&gt; arrd;typedef std::array&lt;int,12&gt; arri;typedef std::array&lt;std::string,12&gt; arrst;//使用arrd gallones；arri days;arrst months; 2.C++11新增了一项功能—使用模板提供一系列别名 12template&lt;typename T&gt;using arrtype=std::array&lt;T,12&gt;;//template aliases 这将arrtype定义为一个模板别名，可以用它来指定类型 123arrtype&lt;double&gt; gallones;arrtype&lt;int&gt; days;arrtype&lt;std::string&gt; months; C++11允许将语法using=用于非模板。用于非模板是，这种语法与常规typedef等价：12typedef const char *pc1; //typedef syntax/ 常规typedef语法using pc2=const char*; //using = syntax/ using =语法 可变参数模板(variadic template)18章 15友元、异常和其他友元类例子：模拟电视机和遥控器的简单程序 公有继承is-a关系并不适用。遥控器可以改变电视机的状态，这表明应将Remove类作为TV类的一个友元 友元声明 friend class Remote；—&gt;友元声明可以位于公有、私有或保护部分，其所在的位置无关紧要。该声明让整个类成为友元并不需要前向（实现）声明，因为友元语句本身已经指出Remote是一个类。 友元Remove可以使用TV类的所有成员 大多类方法都被定义为内联。代码中，除构造函数外，所有Remove方法都将一个TV对象引用作为参数，这表明遥控器必须针对特定的电视机 同一个遥控器可以控制不同的电视机 12345TV S42；TV S58(TV::ON);Remote grey;grey.set_chan(S42,10);grey.set_chan(S58,28); 友元成员函数 某一个类的成员函数作为另外一个类的友元函数 例子：将TV成员中Remote方法Remote::set_chan()，成为另外一个类的成员 12345class TV{friend void Remote::set_chan(TV&amp; t,int c);...}; 问题1：在编译器在TV类声明中看到Remote的一个方法被声明为TV类的友元之前，应先看到Remote类的声明和set_chan()方法的声明。 1234//排列次序应如下：class TV;//forward declarationclass Remote{...};class TV{...}; 问题2：Remote声明包含内联代码，例如：void onoff(TV &amp; t){t.onoff();}由于这将调用TV的一个方法，所以编译器此时必须看到一个TV的类声明，解决：使Remote声明中只包含方法声明，并将实际的定义放在TV类之后 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include&lt;iostream&gt; class B{public : B() { myValue=2; std::cout&lt;&lt;\"B init\"&lt;&lt;std::endl; } ~B() { std::cout&lt;&lt;\"B end\"&lt;&lt;std::endl; } //这样做可以 /*B operator+(const B av) { B a; a.myValue=myValue+av.myValue; return a; }*/ //也可以这么做 friend B operator+(const B b1,const B b2); //------------------------------------------------ int GetMyValue() { return myValue; } //重载&lt;&lt; friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os,B);private : int myValue;};B operator+(const B b1,const B b2){ B a; a.myValue=b1.myValue+b2.myValue; return a;}std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os,B b){ return os&lt;&lt;\"重载实现：\"&lt;&lt;b.myValue&lt;&lt;std::endl;}int main(){ B b1; std::cout&lt;&lt;b1; B b2; B b3=b1+b2; std::cout&lt;&lt;b3&lt;&lt;std::endl; std::cin.get(); return 0;} 内联函数的链接性是内部的，这意味着函数定义必须在使用函数的文件中，这个例子中内联定义位于头文件中，因此在使用函数的文件中包含头文件可确保将定义放在正确的地方。这可以将定义放在实现文件中，但必须删除关键字inline这样函数的链接性将是外部的 嵌套类 在另外一个类中声明的类被称为嵌套类（nested class） 包含类的成员函数可以创建和使用被嵌套的对象。而仅当声明位于公有部分，才能在包含类外面使用嵌套类，而且必须使用作用域解析运算符 访问权限：嵌套类、结构和美剧的作用域特征（三者相同） 声明位置 包含它的类是否可以使用它 从包含它的类派生而来的类是否可以使用它 在外部是否可以使用 私有部分 是 否 否 保护部分 是 是 否 公有部分 是 是 是，可以通过类限定符来使用 * 访问控制 1.类声明的位置决定了类的作用域或可见性 2.类可见后，访问控制规则（公有，保护，私有，友元）将决定程序对嵌套类成员的访问权限。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596//在下面的程序中，我们创建了一个模板类用于实现Queue容器的部分功能，并且在模板类中潜逃使用了一个Node类。// queuetp.h -- queue template with a nested class#ifndef QUEUETP_H_#define QUEUETP_H_template &lt;class Item&gt;class QueueTP{private: enum {Q_SIZE = 10}; // Node is a nested class definition class Node { public: Item item; Node * next; Node(const Item &amp; i) : item(i), next(0) {} }; Node * front; // pointer to front of Queue Node * rear; // pointer to rear of Queue int items; // current number of items in Queue const int qsize; // maximum number of items in Queue QueueTP(const QueueTP &amp; q) : qsize(0) {} QueueTP &amp; operator=(const QueueTP &amp; q) { return *this; }public: QueueTP(int qs = Q_SIZE); ~QueueTP(); bool isempty() const { return items == 0; } bool isfull() const { return items == qsize; } int queuecount() const { return items; } bool enqueue(const Item &amp;item); // add item to end bool dequeue(Item &amp;item); // remove item from front};// QueueTP methodstemplate &lt;class Item&gt;QueueTP&lt;Item&gt;::QueueTP(int qs) : qsize(qs){ front = rear = 0; items = 0;}template &lt;class Item&gt;QueueTP&lt;Item&gt;::~QueueTP(){ Node * temp; while (front != 0) // while queue is not yet empty { temp = front; front = front-&gt;next; delete temp; }}// Add item to queuetemplate &lt;class Item&gt;bool QueueTP&lt;Item&gt;::enqueue(const Item &amp; item){ if (isfull()) return false; Node * add = new Node(item); // create node // on failure, new throws std::bad_alloc exception items ++; if (front == 0) // if queue is empty front = add; // place item at front else rear-&gt;next = add; // else place at rear rear = add; return true;}// Place front item into item variable and remove from queuetemplate &lt;class Item&gt;bool QueueTP&lt;Item&gt;::dequeue(Item &amp; item){ if (front == 0) return false; item = front-&gt;item; // set item to first item in queue items --; Node * temp = front; // save location of first item front = front-&gt;next; // reset front to next item delete temp; // delete former first item if (items == 0) rear = 0; return true;}#endif // QUEUETP_H_ 异常 意外情况 1.程序可能会试图打开一个不可用的文件2.请求过多内存3.遭遇不能容忍的值 1.调用abort()–原型在cstdlib（或stdlib.h）中 其典型实现是向标准错误流（即cerr使用的错误流）发送信息abnormalprogram termination（程序异常中止），然后终止程序。它返回一个随实现而异的值，告诉操作系统，处理失败。 调用abort()将直接终止程序（调用时，不进行任何清理工作） 使用方法：1.判断触发异常的条件 2.满足条件时调用abort() 1.exit():在调用时，会做大部分清理工作，但是决不会销毁局部对象，因为没有stack unwinding。会进行的清理工作包括：销毁所有static和global对象，清空所有缓冲区，关闭所有I／O通道。终止前会调用经由atexit()登录的函数，atexit如果抛出异常，则调用terminate()。 2.abort():调用时，不进行任何清理工作。直接终止程序。 3.retrun:调用时，进行stack unwinding，调用局部对象析构函数，清理局部对象。如果在main中，则之后再交由系统调用exit()。 return返回，可析构main或函数中的局部变量，尤其要注意局部对象，如不析构可能造成内存泄露。exit返回不析构main或函数中的局部变量，但执行收工函数，故可析构全局变量（对象）。abort不析构main或函数中的局部变量，也不执行收工函数，故全局和局部对象都不析构。所以，用return更能避免内存泄露，在C++中用abort和exit都不是好习惯。 2.返回错误代码一种比异常终止更灵活的方法是，使用函数的返回值来指出问题 3.异常机制 C++异常是对程序运行过程中发生的异常情况（例如被0除）的一种响应。异常提供了将控制权从程序的一个部分传递到另外一部分的途径 异常机制由三个部分组成1.引发异常123456double hmean(double a,double b){if(a==-b)throw \"bad heam() arguments:a=-b not allowed\";//throw关键字表示引发异常（实际上是跳转）return 2.0*a*b/(a+b);} 2.使用异常处理程序（exception handler）来捕获异常3.使用try块：try块标识其中特定异常可能会被激活的代码，它后面跟一个或多个的catch块 例子：12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt; using std::cout;using std::cin;using std::cerr; int fun(int &amp; a, int &amp; b){if(b == 0){ throw \"hello there have zero sorry\\n\"; //引发异常}return a / b;} int main(){ int a; int b; while(true) { cin &gt;&gt; a; cin &gt;&gt; b; try //try里面是可能引发异常代码块 { cout &lt;&lt; \" a / b = \"&lt;&lt; fun(a,b) &lt;&lt; \"\\n\"; } catch(const char *str) 接收异常,处理异常 { cout &lt;&lt; str; cerr &lt;&lt;\"除数为0\\n\"; //cerr不会到输出缓冲中 这样在紧急情况下也可以使用 } } system(\"pause\"); return 1;} 1.try:try块标识符其中特定的异常可能被激活的代码块,他后面跟一个或者多个catch块. 2.catch:类似于函数定义,但并不是函数定义,关键字catch表明这是给一个处理程序,里面的const cahr* str会接受throw传过来错误信息. 3.throw:抛出异常信息,类似于执行返回语句,因为它将终止函数的执行,但是它不是将控制权交给调用程序,而是导致程序沿着函数调用序列后退,知道找到包含try块的函数. 注意： 1.如果程序在try块外面调用fun(),将无法处理异常。 2.throw出的异常类型可以是字符串，或其他C++类型：通常为类类型 3.执行throw语句类似于执行返回语句，因为它也将终止函数的执行。 4.执行完try中的语句后，如果没有引发任何异常，则程序跳过try块后面的catch块，直接执行后面的第一条语句。 5.如果函数引发了异常，而没有try块或没有匹配处理程序时，将会发生什么情况。在默认情况下，程序最终调用abort()函数！ 4.将对象用作异常类型 P6225.栈解开（栈解退）stack unwind C++如何处理函数调用和返回的？ 1.程序将调用函数的地址（返回地址）放入到栈中。当被调用的函数执行完毕后，程序将使用该地址来确定从哪里开始执行。 2.函数调用将函数参数放入到栈中。在栈中，这些函数参数被视为自动变量。如果被调用的函数创建的自动变量，则这些自动变量也将被添加到栈中 3.如果被调用的函数调用了另外一个函数，则后者的信息将被添加到栈中，依此类推。 假设函数出现异常（而不是返回）而终止，则程序也将释放栈中的内存，但不会释放栈中的第一个地址后停止，而是继续释放，直到找到一个位于try块中的返回地址。随后，控制权将转到块尾的异常处理程序，而不是函数调用后的第一条语句，这个过程被称为栈解退。 exception类（头文件exception.h/except.h第一了exception类）C++可以把它用作其他异常类的基类 1.stdexcept 异常类（头文件stdexcept定义了其他几个异常类。） 该文件定义了1.logic_error类 2.runtime_error类他们都是以公有的方式从exception派生而来的。 1.logic_error类错误类型（domain_error、invalid_argument、length_error、out_of_bounds）。每个类都有一个类似于logic_error的构造函数，让您能够提供一个供方法what()返回的字符串。 2.runtime_error类错误类型（range_error、overflow_error、underflow_error）。每个类都有一个类似于runtime_error的构造函数，让您能够提供一个供方法what()返回的字符串。 2.bad-alloc异常和new(头文件new) 对于使用new导致的内存分配问题，C++的最新处理方式是让new引发bad_alloc异常。头文件new包含bad_alloc类的生命，他是从exception类公有派生而来的。但在以前，当无法分配请求的内存量时，new返回一个空指针。 3.异常类和继承 1.可以像标准C++库所做的那样，从一个异常类派生出另外一个。 2.可以在类定义中嵌套异常类声明类组合异常。 3.这种嵌套声明本身可被继承，还可用作基类。 RTTI(运行阶段类型识别)(Run-Time Type Identification) 旨在为程序运行阶段确定对象的类型提供一种标准方式 RTTI的工作原理 C++有三个支持RTTI的元素 1.如果可能的话，dynamic_cast运算符将使用一个指向基类的指针来生成指向派生类的指针；否则，该运算符返回0—空指针。 2.typeid运算符返回指出对象类型的值 3.type_info结构存储了有关特定类型的信息。 1.dynamic_cast运算符是最常用的RTTI组件 他不能回答“指针指向的是哪类对象”这样的问题，但能回答“是否可以安全地将对象的地址赋给特定类型的指针”这样的问题 用法：Superb* pm = dynamic_cast&lt;Super*&gt;(pg);其中pg指向一个对象 提出这样的问题：指针pg类型是否可被安全地转换为Super* ?如果可以返回对象地址，否则返回一个空指针。 2.typeid运算符和type_info类。 typeid运算符使得能够确定两个对象是否为同类型,使用：如果pg指向的是一个Magnification对象，则下述表达式的结果为bool值true，否则为false； 12345typeid(Magnification)==typeid(*pg)type_info类的实现岁厂商而异，但包含一个name()成员，该函数返回一个随实现而异的字符串；通常（但并非一定）是类的名称。例如下面的语句想爱你是指针pg指向的对象所属的类定义的字符串：​```C++cout&lt;&lt;\"Now Processing type\"&lt;&lt;typeid(*pg).name()&lt;&lt;\".\\n\"; 类型转换运算符 4个类型转换运算符:dynamic_cast\\const_cast\\static_cast\\reinterpret_cast 1.dynamic_cast(expression) 该运算符的用途是，使得能够在类层次结构中进行向上转换（由于is-a关系，这样的类型转换是安全的），不允许其他转换。 2.const_cast(expression) 该运算符用于执行只有一种用途的类型转换，即改变之const或volatile其语法与dynamic_cast运算符相同。 3.static_cast(expression) 4.reinterpret_cast(expression) 用于天生危险的类型转换。","link":"/2019/05/23/C++/C++11/C++Notes/"},{"title":"算法性能时间记录","text":"本机计算机硬件参数 处理器：Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz 2.59 GHz 显卡：NVIDIA GeForce RTX 2060 机带RAM：16.0 GB 操作系统：window 64 位操作系统, 基于 x64 的处理器 测试内容： 一、从硬盘加载点云数据 二、CUDA-ICP算法表现 一、加载点云数据 方法 数据量 时间 LoadData（自己写的加载txt点云时间） 32469（ASCII码txt文件） 463ms pcl::io::loadPCDFile() 32469（二进制pcd文件） 2ms PCL加载ascii码 32469（ASCII码pcd文件） 452ms utilityCore::safeGetline(this-&gt;fp_in, line);（自己写的加载txt点云时间） 32469（ASCII码txt文件） 304ms 二、迭代最近点ICP 方法 数据量 kdtree构建时间为 迭代次数 平均迭代时间（不算kdtree构建） 时间 自己写的ICP（由于里面多了一些多余的复制操作导致比pcl的慢？） target:32469/source:24183 4ms 38 118.8ms 4516ms pcl::IterativeClosestPoint&lt;pcl::PointXYZ, pcl::PointXYZ&gt; target:32469/source:24183 ？ 38 82.4ms 3134ms 自己写的cudaicp target:32469/source:24183 61ms（与CPU版本的kdtree不同） 43 1.186ms 112.112ms 自己写的cudaicp target:600343/source:5992673 1207ms 59 4.755ms 1487.55ms","link":"/2021/04/02/Perfromance/AlgorithmTime/"}],"tags":[{"name":"图像","slug":"图像","link":"/tags/图像/"},{"name":"ObjectDetection","slug":"ObjectDetection","link":"/tags/ObjectDetection/"},{"name":"PoseEstimation","slug":"PoseEstimation","link":"/tags/PoseEstimation/"},{"name":"CV-Source","slug":"CV-Source","link":"/tags/CV-Source/"},{"name":"SFM","slug":"SFM","link":"/tags/SFM/"},{"name":"books","slug":"books","link":"/tags/books/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"Hash Map","slug":"Hash-Map","link":"/tags/Hash-Map/"},{"name":"STL","slug":"STL","link":"/tags/STL/"},{"name":"std","slug":"std","link":"/tags/std/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"Segmentation","slug":"Segmentation","link":"/tags/Segmentation/"},{"name":"OpenGL","slug":"OpenGL","link":"/tags/OpenGL/"},{"name":"glfw","slug":"glfw","link":"/tags/glfw/"},{"name":"PCL","slug":"PCL","link":"/tags/PCL/"},{"name":"Despriptors","slug":"Despriptors","link":"/tags/Despriptors/"},{"name":"keypoints","slug":"keypoints","link":"/tags/keypoints/"},{"name":"CUDA","slug":"CUDA","link":"/tags/CUDA/"},{"name":"ICP","slug":"ICP","link":"/tags/ICP/"},{"name":"Registration","slug":"Registration","link":"/tags/Registration/"},{"name":"Efficient Sparse ICP","slug":"Efficient-Sparse-ICP","link":"/tags/Efficient-Sparse-ICP/"},{"name":"Sparse ICP","slug":"Sparse-ICP","link":"/tags/Sparse-ICP/"},{"name":"4PCS","slug":"4PCS","link":"/tags/4PCS/"},{"name":"Super4PCS","slug":"Super4PCS","link":"/tags/Super4PCS/"},{"name":"GOICP","slug":"GOICP","link":"/tags/GOICP/"},{"name":"Generalized-ICP","slug":"Generalized-ICP","link":"/tags/Generalized-ICP/"},{"name":"mv-LM-ICP","slug":"mv-LM-ICP","link":"/tags/mv-LM-ICP/"},{"name":"NDT","slug":"NDT","link":"/tags/NDT/"},{"name":"Reconstruction","slug":"Reconstruction","link":"/tags/Reconstruction/"},{"name":"3D scene Reconstruction","slug":"3D-scene-Reconstruction","link":"/tags/3D-scene-Reconstruction/"},{"name":"3D Reconstruction","slug":"3D-Reconstruction","link":"/tags/3D-Reconstruction/"},{"name":"surface Reconstruction","slug":"surface-Reconstruction","link":"/tags/surface-Reconstruction/"},{"name":"SSE","slug":"SSE","link":"/tags/SSE/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"tools","slug":"tools","link":"/tags/tools/"},{"name":"编程知识与VS错误","slug":"编程知识与VS错误","link":"/tags/编程知识与VS错误/"},{"name":"RANSAC","slug":"RANSAC","link":"/tags/RANSAC/"},{"name":"SAC-IA","slug":"SAC-IA","link":"/tags/SAC-IA/"},{"name":"SVD","slug":"SVD","link":"/tags/SVD/"},{"name":"LM","slug":"LM","link":"/tags/LM/"},{"name":"FastICP","slug":"FastICP","link":"/tags/FastICP/"},{"name":"Memory Management","slug":"Memory-Management","link":"/tags/Memory-Management/"},{"name":"Generic Programming","slug":"Generic-Programming","link":"/tags/Generic-Programming/"},{"name":"Performance","slug":"Performance","link":"/tags/Performance/"}],"categories":[{"name":"图像","slug":"图像","link":"/categories/图像/"},{"name":"ObjectDetection and PoseEstimation","slug":"ObjectDetection-and-PoseEstimation","link":"/categories/ObjectDetection-and-PoseEstimation/"},{"name":"CV-Source","slug":"CV-Source","link":"/categories/CV-Source/"},{"name":"用到的opencv接口记录","slug":"图像/用到的opencv接口记录","link":"/categories/图像/用到的opencv接口记录/"},{"name":"2Dimage知识","slug":"图像/2Dimage知识","link":"/categories/图像/2Dimage知识/"},{"name":"编程","slug":"编程","link":"/categories/编程/"},{"name":"1.localDescriptors+Hough","slug":"ObjectDetection-and-PoseEstimation/1-localDescriptors-Hough","link":"/categories/ObjectDetection-and-PoseEstimation/1-localDescriptors-Hough/"},{"name":"3.SFM","slug":"CV-Source/3-SFM","link":"/categories/CV-Source/3-SFM/"},{"name":"机器学习与深度学习","slug":"机器学习与深度学习","link":"/categories/机器学习与深度学习/"},{"name":"Mobile Robot","slug":"Mobile-Robot","link":"/categories/Mobile-Robot/"},{"name":"可视化","slug":"可视化","link":"/categories/可视化/"},{"name":"1.books","slug":"CV-Source/1-books","link":"/categories/CV-Source/1-books/"},{"name":"PCL","slug":"PCL","link":"/categories/PCL/"},{"name":"0.CV-Source","slug":"CV-Source/0-CV-Source","link":"/categories/CV-Source/0-CV-Source/"},{"name":"2.SLAM","slug":"CV-Source/2-SLAM","link":"/categories/CV-Source/2-SLAM/"},{"name":"Registration","slug":"Registration","link":"/categories/Registration/"},{"name":"Hash Map","slug":"编程/Hash-Map","link":"/categories/编程/Hash-Map/"},{"name":"算法与数据结构","slug":"编程/算法与数据结构","link":"/categories/编程/算法与数据结构/"},{"name":"Reconstruction","slug":"Reconstruction","link":"/categories/Reconstruction/"},{"name":"Deep Learning Notes","slug":"机器学习与深度学习/Deep-Learning-Notes","link":"/categories/机器学习与深度学习/Deep-Learning-Notes/"},{"name":"SSE","slug":"编程/SSE","link":"/categories/编程/SSE/"},{"name":"CUDA","slug":"编程/CUDA","link":"/categories/编程/CUDA/"},{"name":"sparse pointcloud segemntation","slug":"Mobile-Robot/sparse-pointcloud-segemntation","link":"/categories/Mobile-Robot/sparse-pointcloud-segemntation/"},{"name":"learn OpenGL","slug":"可视化/learn-OpenGL","link":"/categories/可视化/learn-OpenGL/"},{"name":"cuda FQA","slug":"编程/cuda-FQA","link":"/categories/编程/cuda-FQA/"},{"name":"cuda","slug":"编程/cuda","link":"/categories/编程/cuda/"},{"name":"glfw学习文档","slug":"可视化/glfw学习文档","link":"/categories/可视化/glfw学习文档/"},{"name":"learn CUDA","slug":"编程/learn-CUDA","link":"/categories/编程/learn-CUDA/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"6.Algorithm Time","slug":"PCL/6-Algorithm-Time","link":"/categories/PCL/6-Algorithm-Time/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"4.descriptors","slug":"PCL/4-descriptors","link":"/categories/PCL/4-descriptors/"},{"name":"其他","slug":"其他","link":"/categories/其他/"},{"name":"3.keypoints","slug":"PCL/3-keypoints","link":"/categories/PCL/3-keypoints/"},{"name":"1.configuration","slug":"PCL/1-configuration","link":"/categories/PCL/1-configuration/"},{"name":"0.tutorial","slug":"PCL/0-tutorial","link":"/categories/PCL/0-tutorial/"},{"name":"4.normal estimation","slug":"PCL/4-normal-estimation","link":"/categories/PCL/4-normal-estimation/"},{"name":"5.Region Growing Segmentation","slug":"PCL/5-Region-Growing-Segmentation","link":"/categories/PCL/5-Region-Growing-Segmentation/"},{"name":"1.ICP","slug":"Registration/1-ICP","link":"/categories/Registration/1-ICP/"},{"name":"3.Efficient Sparse ICP","slug":"Registration/3-Efficient-Sparse-ICP","link":"/categories/Registration/3-Efficient-Sparse-ICP/"},{"name":"3.Sparse ICP","slug":"Registration/3-Sparse-ICP","link":"/categories/Registration/3-Sparse-ICP/"},{"name":"6.Super4PCS","slug":"Registration/6-Super4PCS","link":"/categories/Registration/6-Super4PCS/"},{"name":"5.GOICP","slug":"Registration/5-GOICP","link":"/categories/Registration/5-GOICP/"},{"name":"6.mv-LM-ICP","slug":"Registration/6-mv-LM-ICP","link":"/categories/Registration/6-mv-LM-ICP/"},{"name":"NDT","slug":"Registration/NDT","link":"/categories/Registration/NDT/"},{"name":"3.3D scene Reconstruction","slug":"Reconstruction/3-3D-scene-Reconstruction","link":"/categories/Reconstruction/3-3D-scene-Reconstruction/"},{"name":"1.3D Reconstruction2","slug":"Reconstruction/1-3D-Reconstruction2","link":"/categories/Reconstruction/1-3D-Reconstruction2/"},{"name":"2.surface Reconstruction","slug":"Reconstruction/2-surface-Reconstruction","link":"/categories/Reconstruction/2-surface-Reconstruction/"},{"name":"SIMD","slug":"编程/SSE/SIMD","link":"/categories/编程/SSE/SIMD/"},{"name":"3.3D Reconstruction3","slug":"Reconstruction/3-3D-Reconstruction3","link":"/categories/Reconstruction/3-3D-Reconstruction3/"},{"name":"好用的工具","slug":"其他/好用的工具","link":"/categories/其他/好用的工具/"},{"name":"0.tutorial","slug":"ObjectDetection-and-PoseEstimation/0-tutorial","link":"/categories/ObjectDetection-and-PoseEstimation/0-tutorial/"},{"name":"编程知识与VS错误","slug":"编程/编程知识与VS错误","link":"/categories/编程/编程知识与VS错误/"},{"name":"2.pcl samples","slug":"PCL/2-pcl-samples","link":"/categories/PCL/2-pcl-samples/"},{"name":"0.SAC-IA","slug":"Registration/0-SAC-IA","link":"/categories/Registration/0-SAC-IA/"},{"name":"1.3D Reconstruction","slug":"Reconstruction/1-3D-Reconstruction","link":"/categories/Reconstruction/1-3D-Reconstruction/"},{"name":"glfw和cuda","slug":"可视化/glfw和cuda","link":"/categories/可视化/glfw和cuda/"},{"name":"0.compute transform","slug":"Registration/0-compute-transform","link":"/categories/Registration/0-compute-transform/"},{"name":"2.FastICP","slug":"Registration/2-FastICP","link":"/categories/Registration/2-FastICP/"},{"name":"4.Generalized-ICP","slug":"Registration/4-Generalized-ICP","link":"/categories/Registration/4-Generalized-ICP/"},{"name":"5.2018PPF-MEAM","slug":"ObjectDetection-and-PoseEstimation/5-2018PPF-MEAM","link":"/categories/ObjectDetection-and-PoseEstimation/5-2018PPF-MEAM/"},{"name":"C++ FQA","slug":"编程/C-FQA","link":"/categories/编程/C-FQA/"},{"name":"Memory Management","slug":"编程/Memory-Management","link":"/categories/编程/Memory-Management/"},{"name":"STL","slug":"编程/STL","link":"/categories/编程/STL/"},{"name":"Generic Programming","slug":"编程/Generic-Programming","link":"/categories/编程/Generic-Programming/"},{"name":"2.2010HoughvotePPF","slug":"ObjectDetection-and-PoseEstimation/2-2010HoughvotePPF","link":"/categories/ObjectDetection-and-PoseEstimation/2-2010HoughvotePPF/"},{"name":"3.2016HinterstoisserPPF","slug":"ObjectDetection-and-PoseEstimation/3-2016HinterstoisserPPF","link":"/categories/ObjectDetection-and-PoseEstimation/3-2016HinterstoisserPPF/"},{"name":"C++","slug":"编程/C","link":"/categories/编程/C/"},{"name":"Performance","slug":"Performance","link":"/categories/Performance/"}]}